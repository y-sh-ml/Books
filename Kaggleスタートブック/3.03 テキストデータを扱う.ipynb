{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b677b221",
   "metadata": {},
   "source": [
    "## 3.3　テキストデータを扱う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f7359ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models import word2vec\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6330a4",
   "metadata": {},
   "source": [
    "### 3.3.2　テーブルデータと共通する・異なる部分"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b760256f",
   "metadata": {},
   "source": [
    "#### Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc8b3414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I like kaggle very much</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I do not like kaggle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I do really love machine learning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                text\n",
       "0            I like kaggle very much\n",
       "1               I do not like kaggle\n",
       "2  I do really love machine learning"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'text': [\n",
    "    'I like kaggle very much',\n",
    "    'I do not like kaggle',\n",
    "    'I do really love machine learning'\n",
    "]})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fb7ff13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1],\n",
       "       [1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0],\n",
       "       [1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(token_pattern=u'(?u)\\\\b\\\\w+\\\\b')\n",
    "bag = vectorizer.fit_transform(df['text'])\n",
    "bag.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ef7b89e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'i': 1,\n",
       " 'like': 4,\n",
       " 'kaggle': 2,\n",
       " 'very': 10,\n",
       " 'much': 7,\n",
       " 'do': 0,\n",
       " 'not': 8,\n",
       " 'really': 9,\n",
       " 'love': 5,\n",
       " 'machine': 6,\n",
       " 'learning': 3}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0593cd93",
   "metadata": {},
   "source": [
    "#### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1252707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.31544415 0.40619178 0.         0.40619178 0.\n",
      "  0.         0.53409337 0.         0.         0.53409337]\n",
      " [0.43306685 0.33631504 0.43306685 0.         0.43306685 0.\n",
      "  0.         0.         0.56943086 0.         0.        ]\n",
      " [0.34261996 0.26607496 0.         0.45050407 0.         0.45050407\n",
      "  0.45050407 0.         0.         0.45050407 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(token_pattern=u'(?u)\\\\b\\\\w+\\\\b')\n",
    "transformer = TfidfTransformer()\n",
    "\n",
    "tf = vectorizer.fit_transform(df['text'])\n",
    "tfidf = transformer.fit_transform(tf)\n",
    "print(tfidf.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82145763",
   "metadata": {},
   "source": [
    "#### Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9169f0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [d.split() for d in df['text']]\n",
    "model = word2vec.Word2Vec(sentences, vector_size=10, min_count=1, window=2, seed=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ceffad14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01650858,  0.01069946,  0.00188946,  0.09910005,  0.06153275,\n",
       "        0.05853238,  0.04005488,  0.02443584, -0.03179482,  0.09779203],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['like']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af435f80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 0.4254004955291748),\n",
       " ('machine', 0.36355969309806824),\n",
       " ('not', 0.311229407787323),\n",
       " ('kaggle', -0.004140505567193031),\n",
       " ('much', -0.11530754715204239),\n",
       " ('do', -0.1529017835855484),\n",
       " ('love', -0.25542783737182617),\n",
       " ('really', -0.4161785840988159),\n",
       " ('learning', -0.44330498576164246),\n",
       " ('very', -0.4433840215206146)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('like')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95134908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'like', 'kaggle', 'very', 'much']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][0].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80a8f97c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.08898099,  0.02501909,  0.03683598,  0.07944275,  0.01565849,\n",
       "         0.05513714,  0.0667302 , -0.05495857, -0.08889369, -0.03996675],\n",
       "       [ 0.01650858,  0.01069946,  0.00188946,  0.09910005,  0.06153275,\n",
       "         0.05853238,  0.04005488,  0.02443584, -0.03179482,  0.09779203],\n",
       "       [ 0.06329302, -0.03939352, -0.03167932, -0.04431488,  0.04389417,\n",
       "        -0.04902608,  0.09809195, -0.01098474, -0.00437022,  0.00090965],\n",
       "       [ 0.03720424, -0.02774719,  0.02864924,  0.01963681, -0.07835456,\n",
       "        -0.08814968,  0.03203132, -0.02247364,  0.01966591, -0.03539274],\n",
       "       [-0.09157717,  0.04835419, -0.00529734, -0.08170088, -0.05110302,\n",
       "         0.00822875,  0.04535742,  0.00155444,  0.02258943,  0.07426786]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec = np.array([model.wv[word] for word in df['text'][0].split()])\n",
    "word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cdd0cf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.02288193,  0.00338641,  0.0060796 ,  0.01443277, -0.00167443,\n",
       "       -0.0030555 ,  0.05645315, -0.01248533, -0.01656068,  0.01952201],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(word2vec, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ad22094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08898099, 0.04835419, 0.03683598, 0.09910005, 0.06153275,\n",
       "       0.05853238, 0.09809195, 0.02443584, 0.02258943, 0.09779203],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(word2vec, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75be0abd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-29 16:24:52,704 : INFO : collecting all words and their counts\n",
      "2024-05-29 16:24:52,706 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-29 16:24:55,886 : INFO : collected 290811 word types from a corpus of 16900026 raw words and 1691 sentences\n",
      "2024-05-29 16:24:55,886 : INFO : Creating a fresh vocabulary\n",
      "2024-05-29 16:24:56,043 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 75187 unique words (25.85% of original 290811, drops 215624)', 'datetime': '2024-05-29T16:24:56.043322', 'gensim': '4.3.0', 'python': '3.11.5 (main, Sep 11 2023, 08:31:25) [Clang 14.0.6 ]', 'platform': 'macOS-14.5-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-05-29 16:24:56,043 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 16577418 word corpus (98.09% of original 16900026, drops 322608)', 'datetime': '2024-05-29T16:24:56.043748', 'gensim': '4.3.0', 'python': '3.11.5 (main, Sep 11 2023, 08:31:25) [Clang 14.0.6 ]', 'platform': 'macOS-14.5-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-05-29 16:24:56,239 : INFO : deleting the raw counts dictionary of 290811 items\n",
      "2024-05-29 16:24:56,244 : INFO : sample=0.001 downsamples 34 most-common words\n",
      "2024-05-29 16:24:56,244 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 11431523.681113321 word corpus (69.0%% of prior 16577418)', 'datetime': '2024-05-29T16:24:56.244972', 'gensim': '4.3.0', 'python': '3.11.5 (main, Sep 11 2023, 08:31:25) [Clang 14.0.6 ]', 'platform': 'macOS-14.5-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-05-29 16:24:56,587 : INFO : estimated required memory for 75187 words and 200 dimensions: 157892700 bytes\n",
      "2024-05-29 16:24:56,587 : INFO : resetting layer weights\n",
      "2024-05-29 16:24:56,658 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-29T16:24:56.658567', 'gensim': '4.3.0', 'python': '3.11.5 (main, Sep 11 2023, 08:31:25) [Clang 14.0.6 ]', 'platform': 'macOS-14.5-arm64-arm-64bit', 'event': 'build_vocab'}\n",
      "2024-05-29 16:24:56,659 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 75187 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-29T16:24:56.659020', 'gensim': '4.3.0', 'python': '3.11.5 (main, Sep 11 2023, 08:31:25) [Clang 14.0.6 ]', 'platform': 'macOS-14.5-arm64-arm-64bit', 'event': 'train'}\n",
      "2024-05-29 16:24:57,672 : INFO : EPOCH 0 - PROGRESS: at 7.75% examples, 876169 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-29 16:24:58,681 : INFO : EPOCH 0 - PROGRESS: at 15.73% examples, 890088 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-29 16:24:59,686 : INFO : EPOCH 0 - PROGRESS: at 23.36% examples, 883026 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-29 16:25:00,701 : INFO : EPOCH 0 - PROGRESS: at 31.52% examples, 891733 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-29 16:25:01,717 : INFO : EPOCH 0 - PROGRESS: at 39.86% examples, 901195 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-29 16:25:02,718 : INFO : EPOCH 0 - PROGRESS: at 48.14% examples, 908270 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-29 16:25:03,732 : INFO : EPOCH 0 - PROGRESS: at 56.36% examples, 911228 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-29 16:25:04,732 : INFO : EPOCH 0 - PROGRESS: at 64.64% examples, 915681 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-29 16:25:05,743 : INFO : EPOCH 0 - PROGRESS: at 72.86% examples, 917560 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-29 16:25:06,757 : INFO : EPOCH 0 - PROGRESS: at 81.19% examples, 919668 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-29 16:25:07,771 : INFO : EPOCH 0 - PROGRESS: at 89.53% examples, 921489 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-29 16:25:08,773 : INFO : EPOCH 0 - PROGRESS: at 97.75% examples, 922910 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-29 16:25:09,034 : INFO : EPOCH 0: training on 16900026 raw words (11432414 effective words) took 12.4s, 923863 effective words/s\n",
      "2024-05-29 16:25:10,047 : INFO : EPOCH 1 - PROGRESS: at 8.22% examples, 929401 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-29 16:25:11,060 : INFO : EPOCH 1 - PROGRESS: at 16.56% examples, 935625 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-29 16:25:12,071 : INFO : EPOCH 1 - PROGRESS: at 24.90% examples, 937953 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-29 16:25:13,081 : INFO : EPOCH 1 - PROGRESS: at 33.23% examples, 939005 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-29 16:25:14,087 : INFO : EPOCH 1 - PROGRESS: at 41.40% examples, 936754 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-29 16:25:15,097 : INFO : EPOCH 1 - PROGRESS: at 49.20% examples, 927832 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-29 16:25:16,098 : INFO : EPOCH 1 - PROGRESS: at 56.95% examples, 921752 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-29 16:25:17,101 : INFO : EPOCH 1 - PROGRESS: at 64.93% examples, 920515 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-29 16:25:18,104 : INFO : EPOCH 1 - PROGRESS: at 72.74% examples, 917343 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-29 16:25:19,113 : INFO : EPOCH 1 - PROGRESS: at 80.60% examples, 914469 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-29 16:25:20,130 : INFO : EPOCH 1 - PROGRESS: at 88.05% examples, 907452 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-29 16:25:21,134 : INFO : EPOCH 1 - PROGRESS: at 94.97% examples, 897643 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-29 16:25:21,734 : INFO : EPOCH 1: training on 16900026 raw words (11429370 effective words) took 12.7s, 899967 effective words/s\n",
      "2024-05-29 16:25:22,751 : INFO : EPOCH 2 - PROGRESS: at 8.28% examples, 934155 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-29 16:25:23,759 : INFO : EPOCH 2 - PROGRESS: at 16.62% examples, 939833 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-29 16:25:24,771 : INFO : EPOCH 2 - PROGRESS: at 24.96% examples, 940799 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-29 16:25:25,780 : INFO : EPOCH 2 - PROGRESS: at 33.29% examples, 941300 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-29 16:25:26,797 : INFO : EPOCH 2 - PROGRESS: at 41.63% examples, 940712 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-29 16:25:27,798 : INFO : EPOCH 2 - PROGRESS: at 49.32% examples, 930112 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-29 16:25:28,799 : INFO : EPOCH 2 - PROGRESS: at 57.48% examples, 930474 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-29 16:25:29,799 : INFO : EPOCH 2 - PROGRESS: at 65.58% examples, 930123 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-29 16:25:30,799 : INFO : EPOCH 2 - PROGRESS: at 73.74% examples, 930689 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-29 16:25:31,801 : INFO : EPOCH 2 - PROGRESS: at 81.96% examples, 931305 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-29 16:25:32,802 : INFO : EPOCH 2 - PROGRESS: at 90.12% examples, 931334 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-29 16:25:33,817 : INFO : EPOCH 2 - PROGRESS: at 97.87% examples, 926535 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-29 16:25:34,059 : INFO : EPOCH 2: training on 16900026 raw words (11431522 effective words) took 12.3s, 927686 effective words/s\n",
      "2024-05-29 16:25:35,062 : INFO : EPOCH 3 - PROGRESS: at 7.81% examples, 892423 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-29 16:25:36,077 : INFO : EPOCH 3 - PROGRESS: at 15.67% examples, 887943 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-29 16:25:37,077 : INFO : EPOCH 3 - PROGRESS: at 23.30% examples, 882930 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-29 16:25:38,081 : INFO : EPOCH 3 - PROGRESS: at 31.28% examples, 889097 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-29 16:25:39,083 : INFO : EPOCH 3 - PROGRESS: at 39.50% examples, 898931 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-29 16:25:40,090 : INFO : EPOCH 3 - PROGRESS: at 47.78% examples, 905760 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-29 16:25:41,097 : INFO : EPOCH 3 - PROGRESS: at 55.94% examples, 908922 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-29 16:25:42,108 : INFO : EPOCH 3 - PROGRESS: at 64.10% examples, 910793 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-29 16:25:43,122 : INFO : EPOCH 3 - PROGRESS: at 72.26% examples, 912102 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-29 16:25:44,136 : INFO : EPOCH 3 - PROGRESS: at 80.60% examples, 914730 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-29 16:25:45,152 : INFO : EPOCH 3 - PROGRESS: at 88.94% examples, 916925 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-29 16:25:46,162 : INFO : EPOCH 3 - PROGRESS: at 97.28% examples, 919144 words/s, in_qsize 5, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-29 16:25:46,484 : INFO : EPOCH 3: training on 16900026 raw words (11430752 effective words) took 12.4s, 919984 effective words/s\n",
      "2024-05-29 16:25:47,497 : INFO : EPOCH 4 - PROGRESS: at 8.28% examples, 936710 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-29 16:25:48,508 : INFO : EPOCH 4 - PROGRESS: at 16.62% examples, 939644 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-29 16:25:49,522 : INFO : EPOCH 4 - PROGRESS: at 24.96% examples, 939994 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-29 16:25:50,524 : INFO : EPOCH 4 - PROGRESS: at 33.23% examples, 940900 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-29 16:25:51,530 : INFO : EPOCH 4 - PROGRESS: at 41.45% examples, 939608 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-29 16:25:52,542 : INFO : EPOCH 4 - PROGRESS: at 49.79% examples, 939694 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-29 16:25:53,553 : INFO : EPOCH 4 - PROGRESS: at 58.13% examples, 940320 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-29 16:25:54,568 : INFO : EPOCH 4 - PROGRESS: at 66.47% examples, 940373 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-29 16:25:55,582 : INFO : EPOCH 4 - PROGRESS: at 74.81% examples, 940389 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-29 16:25:56,595 : INFO : EPOCH 4 - PROGRESS: at 83.15% examples, 940464 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-29 16:25:57,608 : INFO : EPOCH 4 - PROGRESS: at 91.48% examples, 940520 words/s, in_qsize 5, out_qsize 0\n",
      "2024-05-29 16:25:58,623 : INFO : EPOCH 4 - PROGRESS: at 99.82% examples, 940639 words/s, in_qsize 3, out_qsize 0\n",
      "2024-05-29 16:25:58,627 : INFO : EPOCH 4: training on 16900026 raw words (11430716 effective words) took 12.1s, 941462 effective words/s\n",
      "2024-05-29 16:25:58,627 : INFO : Word2Vec lifecycle event {'msg': 'training on 84500130 raw words (57154774 effective words) took 62.0s, 922304 effective words/s', 'datetime': '2024-05-29T16:25:58.627711', 'gensim': '4.3.0', 'python': '3.11.5 (main, Sep 11 2023, 08:31:25) [Clang 14.0.6 ]', 'platform': 'macOS-14.5-arm64-arm-64bit', 'event': 'train'}\n",
      "2024-05-29 16:25:58,628 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=75187, vector_size=200, alpha=0.025>', 'datetime': '2024-05-29T16:25:58.628093', 'gensim': '4.3.0', 'python': '3.11.5 (main, Sep 11 2023, 08:31:25) [Clang 14.0.6 ]', 'platform': 'macOS-14.5-arm64-arm-64bit', 'event': 'created'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('財政', 0.6993507146835327),\n",
       " ('政策', 0.675098180770874),\n",
       " ('社会', 0.6717209815979004),\n",
       " ('対外', 0.6704453229904175),\n",
       " ('産業', 0.638647735118866),\n",
       " ('金融', 0.6264115571975708),\n",
       " ('政治', 0.6170356273651123),\n",
       " ('格差', 0.6139470934867859),\n",
       " ('資本', 0.612656831741333),\n",
       " ('農業', 0.5940402150154114)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import word2vec\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "sentences = word2vec.Text8Corpus('ja.text8')\n",
    "model = word2vec.Word2Vec(sentences, vector_size=200)\n",
    "model.wv.most_similar(['経済'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
