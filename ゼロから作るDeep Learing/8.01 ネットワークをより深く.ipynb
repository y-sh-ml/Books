{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "beca3f23",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.005741,
     "end_time": "2022-06-01T05:41:22.715773",
     "exception": false,
     "start_time": "2022-06-01T05:41:22.710032",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 8.1 ネットワークをより深く"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "595f23ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-01T05:41:22.730774Z",
     "iopub.status.busy": "2022-06-01T05:41:22.729790Z",
     "iopub.status.idle": "2022-06-01T05:41:22.745433Z",
     "shell.execute_reply": "2022-06-01T05:41:22.744186Z"
    },
    "papermill": {
     "duration": 0.024976,
     "end_time": "2022-06-01T05:41:22.748380",
     "exception": false,
     "start_time": "2022-06-01T05:41:22.723404",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a26a56b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/yuta.shimizu/Downloads/Machine Learning/deep-learning-from-scratch-master/ch08')\n",
    "sys.path.append(os.pardir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33bf6edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_convnet import DeepConvNet\n",
    "from collections import OrderedDict\n",
    "from common.layers import *\n",
    "from dataset.mnist import load_mnist\n",
    "from common.trainer import Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c361cb",
   "metadata": {},
   "source": [
    "### 実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9603e0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepConvNet:\n",
    "    \n",
    "    def __init__(\n",
    "        self, input_dim=(1, 28, 28),\n",
    "        conv_param_1 = {'filter_num': 16, 'filter_size': 3, 'pad':1, 'stride':1},\n",
    "        conv_param_2 = {'filter_num': 16, 'filter_size': 3, 'pad':1, 'stride':1},\n",
    "        conv_param_3 = {'filter_num': 32, 'filter_size': 3, 'pad':1, 'stride':1},\n",
    "        conv_param_4 = {'filter_num': 32, 'filter_size': 3, 'pad':2, 'stride':1},\n",
    "        conv_param_5 = {'filter_num': 64, 'filter_size': 3, 'pad':1, 'stride':1},\n",
    "        conv_param_6 = {'filter_num': 64, 'filter_size': 3, 'pad':1, 'stride':1},\n",
    "        hidden_size=50, output_size=10\n",
    "    ):\n",
    "    \n",
    "        pre_node_nums = np.array([1*3*3, 16*3*3, 16*3*3, 32*3*3, 32*3*3, 64*3*3, 64*4*4, hidden_size])\n",
    "        weight_init_scales = np.sqrt(2.0 / pre_node_nums)\n",
    "        \n",
    "        self.params = {}\n",
    "        pre_channel_num = input_dim[0]\n",
    "        \n",
    "        for idx, conv_param in enumerate([conv_param_1, conv_param_2, conv_param_3, conv_param_4, conv_param_5, conv_param_6]):\n",
    "            self.params['W' + str(idx+1)] = weight_init_scales[idx] * np.random.randn(\n",
    "                conv_param['filter_num'], pre_channel_num, conv_param['filter_size'], conv_param['filter_size']\n",
    "            )\n",
    "            self.params['b' + str(idx+1)] = np.zeros(conv_param['filter_num'])\n",
    "            pre_channel_num = conv_param['filter_num']\n",
    "        \n",
    "        self.params['W7'] = weight_init_scales[6] * np.random.randn(64*4*4, hidden_size)\n",
    "        self.params['b7'] = np.zeros(hidden_size)\n",
    "        self.params['W8'] = weight_init_scales[7] * np.random.randn(hidden_size, output_size)\n",
    "        self.params['b8'] = np.zeros(output_size)\n",
    "        \n",
    "        self.layers = []\n",
    "        self.layers.append(Convolution(self.params['W1'], self.params['b1'], conv_param_1['stride'], conv_param_1['pad']))\n",
    "        self.layers.append(Relu())\n",
    "        \n",
    "        self.layers.append(Convolution(self.params['W2'], self.params['b2'], conv_param_2['stride'], conv_param_2['pad']))\n",
    "        self.layers.append(Relu())\n",
    "        self.layers.append(Pooling(pool_h=2, pool_w=2, stride=2))\n",
    "        \n",
    "        self.layers.append(Convolution(self.params['W3'], self.params['b3'], conv_param_3['stride'], conv_param_3['pad']))\n",
    "        self.layers.append(Relu())\n",
    "        \n",
    "        self.layers.append(Convolution(self.params['W4'], self.params['b4'], conv_param_4['stride'], conv_param_4['pad']))\n",
    "        self.layers.append(Relu())\n",
    "        self.layers.append(Pooling(pool_h=2, pool_w=2, stride=2))\n",
    "        \n",
    "        self.layers.append(Convolution(self.params['W5'], self.params['b5'], conv_param_5['stride'], conv_param_5['pad']))\n",
    "        self.layers.append(Relu())\n",
    "        \n",
    "        self.layers.append(Convolution(self.params['W6'], self.params['b6'], conv_param_6['stride'], conv_param_6['pad']))\n",
    "        self.layers.append(Relu())\n",
    "        self.layers.append(Pooling(pool_h=2, pool_w=2, stride=2))\n",
    "        \n",
    "        self.layers.append(Affine(self.params['W7'], self.params['b7']))\n",
    "        self.layers.append(Relu())\n",
    "        self.layers.append(Dropout(0.5))\n",
    "        \n",
    "        self.layers.append(Affine(self.params['W8'], self.params['b8']))\n",
    "        self.layers.append(Dropout(0.5))\n",
    "        \n",
    "        self.last_layer = SoftmaxWithLoss()\n",
    "        \n",
    "    def predict(self, x, train_flg=False):\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, Dropout):\n",
    "                x = layer.forward(x, train_flg)\n",
    "            else:\n",
    "                x = layer.forward(x)\n",
    "        return x\n",
    "    \n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x, train_flg=True)\n",
    "        return self.last_layer.forward(y, t)\n",
    "    \n",
    "    def accuracy(self, x, t, batch_size=100):\n",
    "        if t.ndim != 1:\n",
    "            t = np.argmax(t, axis=1)\n",
    "            \n",
    "        acc = 0.0\n",
    "        \n",
    "        for i in range(int(x.shape[0] / batch_size)):\n",
    "            tx = x[i*batch_size:(i+1)*batch_size]\n",
    "            tt = t[i*batch_size:(i+1)*batch_size]\n",
    "            y = self.predict(tx, train_flg=False)\n",
    "            y = np.argmax(y, axis=1)\n",
    "            acc += np.sum(y == tt)\n",
    "            \n",
    "        return acc / x.shape[0]\n",
    "    \n",
    "    def gradient(self, x, t):\n",
    "        self.loss(x, t)\n",
    "        \n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)\n",
    "        \n",
    "        tmp_layers = self.layers.copy()\n",
    "        tmp_layers.reverse()\n",
    "        for layer in tmp_layers:\n",
    "            dout = layer.backward(dout)\n",
    "            \n",
    "        grads = {}\n",
    "        for i, layer_idx in enumerate((0, 2, 5, 7, 10, 12, 15, 18)):\n",
    "            grads['W' + str(i+1)] = self.layers[layer_idx].dW\n",
    "            grads['b' + str(i+1)] = self.layers[layer_idx].db\n",
    "            \n",
    "        return grads\n",
    "        \n",
    "    def save_params(self, file_name='params.pkl'):\n",
    "        params = {}\n",
    "        for key, val in self.params.items():\n",
    "            params[key] = val\n",
    "        with open(file_name, 'wb') as f:\n",
    "            pickle.dump(params, f)\n",
    "            \n",
    "    def load_params(self, file_name='params.pkl'):\n",
    "        with open(file_name, 'rb') as f:\n",
    "            params = pickle.load(f)\n",
    "        for key, val in params.items():\n",
    "            self.params[key] = val\n",
    "        \n",
    "        for i, layer_idx in enumerate((0, 2, 5, 7, 10, 12, 15, 18)):\n",
    "            self.layers[layer_idx].W = self.params['W' + str(i+1)]\n",
    "            self.layers[layer_idx].b = self.params['b' + str(i+1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfa2f87",
   "metadata": {},
   "source": [
    "`np.random.randn` は、行列の各次元を引数にとっている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa7786b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.19682237, -0.49356639, -0.66541329],\n",
       "       [ 1.29621773,  0.20940981,  2.07949145],\n",
       "       [-0.97495517, -0.47047955, -0.45910464]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randn(3, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc0db01",
   "metadata": {},
   "source": [
    "`layer_idx` は、`self.layers` に格納された Conv のインデックスを指定している。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c34c5d9",
   "metadata": {},
   "source": [
    "### 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e44a9683",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.357024600117992\n",
      "=== epoch:1, train acc:0.108, test acc:0.114 ===\n",
      "train loss:2.3565978978238373\n",
      "train loss:2.2837450887762305\n",
      "train loss:2.274793375367765\n",
      "train loss:2.285169250587435\n",
      "train loss:2.26923548142803\n",
      "train loss:2.2864202221507015\n",
      "train loss:2.25572972728607\n",
      "train loss:2.225601584099485\n",
      "train loss:2.228667828662848\n",
      "train loss:2.234840127486413\n",
      "train loss:2.285592357971904\n",
      "train loss:2.2162907144535797\n",
      "train loss:2.2195429493766827\n",
      "train loss:2.199444758830077\n",
      "train loss:2.174498514001645\n",
      "train loss:2.261666374433676\n",
      "train loss:2.119572230641124\n",
      "train loss:2.1681419817301792\n",
      "train loss:2.1472401316780787\n",
      "train loss:2.070446587104757\n",
      "train loss:2.064546749946911\n",
      "train loss:2.090399933717764\n",
      "train loss:2.031705803463345\n",
      "train loss:2.067486990508267\n",
      "train loss:2.006243749594706\n",
      "train loss:2.1062286216290147\n",
      "train loss:1.9447357735585111\n",
      "train loss:2.069473282466495\n",
      "train loss:2.089439539596811\n",
      "train loss:1.951545402121392\n",
      "train loss:2.019738626503189\n",
      "train loss:1.958152986817995\n",
      "train loss:2.0723578769445785\n",
      "train loss:1.8853780897252705\n",
      "train loss:1.9644322116685613\n",
      "train loss:1.8202271789761886\n",
      "train loss:1.9447598773400712\n",
      "train loss:1.7997528532129987\n",
      "train loss:1.8246721991689725\n",
      "train loss:2.01133190753267\n",
      "train loss:1.903791905776468\n",
      "train loss:1.8056906517851232\n",
      "train loss:1.8743372080622132\n",
      "train loss:1.766669682284758\n",
      "train loss:1.7886461968086182\n",
      "train loss:1.711856524190773\n",
      "train loss:1.8171047163833876\n",
      "train loss:1.793770484032775\n",
      "train loss:1.8361419166498216\n",
      "train loss:1.8481130117687659\n",
      "train loss:1.8273562447079041\n",
      "train loss:1.9137468278565648\n",
      "train loss:1.7357706499965595\n",
      "train loss:1.7336317000294799\n",
      "train loss:1.6694858064442701\n",
      "train loss:1.6429545832093775\n",
      "train loss:1.772065306325476\n",
      "train loss:1.9317877026119306\n",
      "train loss:1.7316230170897637\n",
      "train loss:1.718771038733708\n",
      "train loss:1.7661282765925725\n",
      "train loss:1.7023992580165301\n",
      "train loss:1.819842383189207\n",
      "train loss:1.8411514132255398\n",
      "train loss:1.7398731138417287\n",
      "train loss:1.7044554948398403\n",
      "train loss:1.6231267861745886\n",
      "train loss:1.7271614890090057\n",
      "train loss:1.7895955582078253\n",
      "train loss:1.4314769518965096\n",
      "train loss:1.6772274367501745\n",
      "train loss:1.7301761695310658\n",
      "train loss:1.7112108774852954\n",
      "train loss:1.4855262616255691\n",
      "train loss:1.8053486487193309\n",
      "train loss:1.6250970463035788\n",
      "train loss:1.6034797842015842\n",
      "train loss:1.5129050435175377\n",
      "train loss:1.5934890205496077\n",
      "train loss:1.5340685796918208\n",
      "train loss:1.529966725259479\n",
      "train loss:1.691843418794302\n",
      "train loss:1.5476960355279346\n",
      "train loss:1.6442799834188404\n",
      "train loss:1.585413244148118\n",
      "train loss:1.5431281421170928\n",
      "train loss:1.6074127874372641\n",
      "train loss:1.6485140774452807\n",
      "train loss:1.657874401714819\n",
      "train loss:1.6356181321748482\n",
      "train loss:1.6750534775054535\n",
      "train loss:1.5437289768619467\n",
      "train loss:1.4559507801704377\n",
      "train loss:1.674687426607338\n",
      "train loss:1.6628234706818381\n",
      "train loss:1.7576375571963896\n",
      "train loss:1.6520485873022255\n",
      "train loss:1.509891786195997\n",
      "train loss:1.5432676774646117\n",
      "train loss:1.51926351879688\n",
      "train loss:1.5924912357551961\n",
      "train loss:1.5491066187233715\n",
      "train loss:1.7810661755572361\n",
      "train loss:1.4803098782237702\n",
      "train loss:1.5604392756338488\n",
      "train loss:1.4902700490973728\n",
      "train loss:1.5135206248586186\n",
      "train loss:1.4306686217023665\n",
      "train loss:1.4497804729377735\n",
      "train loss:1.654505908777174\n",
      "train loss:1.4101442707788754\n",
      "train loss:1.5043247338589063\n",
      "train loss:1.5780708635371292\n",
      "train loss:1.5642051818597338\n",
      "train loss:1.316088684785811\n",
      "train loss:1.5556372450174556\n",
      "train loss:1.7609650822548104\n",
      "train loss:1.4590392322923609\n",
      "train loss:1.3363850478466464\n",
      "train loss:1.5792012162912759\n",
      "train loss:1.5657378188235478\n",
      "train loss:1.6451829575033798\n",
      "train loss:1.443776882936108\n",
      "train loss:1.6593732950501172\n",
      "train loss:1.4017403832504858\n",
      "train loss:1.2889786119469195\n",
      "train loss:1.669772767779517\n",
      "train loss:1.5572143516057009\n",
      "train loss:1.2864913755217904\n",
      "train loss:1.5784846856835621\n",
      "train loss:1.4853439063633431\n",
      "train loss:1.4504494650244655\n",
      "train loss:1.5057471220547132\n",
      "train loss:1.530769424898419\n",
      "train loss:1.5134062418862584\n",
      "train loss:1.3269186574677991\n",
      "train loss:1.4608427411141582\n",
      "train loss:1.380255511244527\n",
      "train loss:1.6448743752544082\n",
      "train loss:1.4627618188243665\n",
      "train loss:1.464533259257534\n",
      "train loss:1.3290280933486474\n",
      "train loss:1.3794319281719425\n",
      "train loss:1.5021000676990994\n",
      "train loss:1.4858451484034212\n",
      "train loss:1.500577283511025\n",
      "train loss:1.3485214635933156\n",
      "train loss:1.5711660783928156\n",
      "train loss:1.489807079882573\n",
      "train loss:1.521698081138638\n",
      "train loss:1.3347948078516712\n",
      "train loss:1.571798766714165\n",
      "train loss:1.417865954264341\n",
      "train loss:1.4361188298435557\n",
      "train loss:1.2592130618817945\n",
      "train loss:1.449490934732362\n",
      "train loss:1.459031159848499\n",
      "train loss:1.3572026957839476\n",
      "train loss:1.4581824829533112\n",
      "train loss:1.485185010986696\n",
      "train loss:1.2974841337011604\n",
      "train loss:1.5369411561323423\n",
      "train loss:1.418718851893706\n",
      "train loss:1.5051824458860708\n",
      "train loss:1.42343894484142\n",
      "train loss:1.376399069867381\n",
      "train loss:1.4394752802924256\n",
      "train loss:1.406185762670874\n",
      "train loss:1.4060276626347357\n",
      "train loss:1.2643979102915586\n",
      "train loss:1.4622156638763644\n",
      "train loss:1.3415527259900435\n",
      "train loss:1.5208870191113966\n",
      "train loss:1.4022365787493285\n",
      "train loss:1.26262162921958\n",
      "train loss:1.533817031740253\n",
      "train loss:1.4848826216390127\n",
      "train loss:1.4470428698429203\n",
      "train loss:1.4397591963810878\n",
      "train loss:1.4812901070205766\n",
      "train loss:1.5384304230357404\n",
      "train loss:1.2732425898569917\n",
      "train loss:1.3463088858968262\n",
      "train loss:1.226808257177686\n",
      "train loss:1.5541727385153303\n",
      "train loss:1.594274011980132\n",
      "train loss:1.4515259931078226\n",
      "train loss:1.2952683843086021\n",
      "train loss:1.3306221118810158\n",
      "train loss:1.3439503431314095\n",
      "train loss:1.2010866445088553\n",
      "train loss:1.4230249581731655\n",
      "train loss:1.3127672504008414\n",
      "train loss:1.3649762592341301\n",
      "train loss:1.4990855170930917\n",
      "train loss:1.2398436730554059\n",
      "train loss:1.3913873313485525\n",
      "train loss:1.339639080439482\n",
      "train loss:1.4140159579108518\n",
      "train loss:1.358840006520641\n",
      "train loss:1.2730642362271027\n",
      "train loss:1.3814407046184716\n",
      "train loss:1.2434577487880814\n",
      "train loss:1.5115343945573108\n",
      "train loss:1.4208800483374326\n",
      "train loss:1.3330959736968482\n",
      "train loss:1.3055417694768374\n",
      "train loss:1.4203003754777412\n",
      "train loss:1.334262587363242\n",
      "train loss:1.2121244961303552\n",
      "train loss:1.3802317745931239\n",
      "train loss:1.405415626896604\n",
      "train loss:1.2587995851020528\n",
      "train loss:1.2680129999388665\n",
      "train loss:1.3090369685908032\n",
      "train loss:1.4685529350524404\n",
      "train loss:1.3707905738236124\n",
      "train loss:1.326825832571114\n",
      "train loss:1.4268796563155244\n",
      "train loss:1.2861827100328467\n",
      "train loss:1.3672143191181203\n",
      "train loss:1.2902984379746323\n",
      "train loss:1.4938959709843807\n",
      "train loss:1.2871231963197856\n",
      "train loss:1.3418290638604737\n",
      "train loss:1.4560366781922296\n",
      "train loss:1.4188375854991324\n",
      "train loss:1.362399492890195\n",
      "train loss:1.0212930935978717\n",
      "train loss:1.2265896208937916\n",
      "train loss:1.2731589017899536\n",
      "train loss:1.2945488084620138\n",
      "train loss:1.2157095938064206\n",
      "train loss:1.2390966516274409\n",
      "train loss:1.329808533289051\n",
      "train loss:1.1998218990472538\n",
      "train loss:1.4508177959743165\n",
      "train loss:1.4478429508875252\n",
      "train loss:1.285790819243085\n",
      "train loss:1.4081095504402321\n",
      "train loss:1.4299751487615309\n",
      "train loss:1.5462181211960422\n",
      "train loss:1.5714815010323073\n",
      "train loss:1.433803069222081\n",
      "train loss:1.2252652437072762\n",
      "train loss:1.4810712250371674\n",
      "train loss:1.384421428818648\n",
      "train loss:1.4300139220582313\n",
      "train loss:1.2087947942180515\n",
      "train loss:1.179054848429375\n",
      "train loss:1.2675906837524422\n",
      "train loss:1.2399268326269353\n",
      "train loss:1.4317073063734105\n",
      "train loss:1.586928089408959\n",
      "train loss:1.2509205076706056\n",
      "train loss:1.379993396394333\n",
      "train loss:1.2181594601676782\n",
      "train loss:1.2307154101390203\n",
      "train loss:1.2022293008078848\n",
      "train loss:1.4256733922494496\n",
      "train loss:1.3226938554682597\n",
      "train loss:1.1867672292979699\n",
      "train loss:1.1900428907122844\n",
      "train loss:1.2186740186847524\n",
      "train loss:1.242164643106421\n",
      "train loss:1.4592256601770464\n",
      "train loss:1.318298406813753\n",
      "train loss:1.1831360490177134\n",
      "train loss:1.209315218676317\n",
      "train loss:1.2666909884651998\n",
      "train loss:1.3442611950320824\n",
      "train loss:1.3390885452155408\n",
      "train loss:1.1243337046262352\n",
      "train loss:1.1486315823255753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:1.2167370069635672\n",
      "train loss:1.3001688537670837\n",
      "train loss:1.2806353479227968\n",
      "train loss:1.291937672524081\n",
      "train loss:1.3713032241402763\n",
      "train loss:1.3339134696942614\n",
      "train loss:1.2781719501888567\n",
      "train loss:1.3951612585273625\n",
      "train loss:1.3015350267907335\n",
      "train loss:1.3206830417229214\n",
      "train loss:1.1819855936143706\n",
      "train loss:1.292188548967698\n",
      "train loss:1.2317345856671509\n",
      "train loss:1.3870873607670686\n",
      "train loss:1.1987474470623622\n",
      "train loss:1.3319948923228395\n",
      "train loss:1.2778671521705904\n",
      "train loss:1.2506044955862095\n",
      "train loss:1.4905279566923486\n",
      "train loss:1.0718198309083697\n",
      "train loss:1.59393064871886\n",
      "train loss:1.2688630840748756\n",
      "train loss:1.0945890903929978\n",
      "train loss:1.3374266704501165\n",
      "train loss:1.3428336241917602\n",
      "train loss:1.2195816845917384\n",
      "train loss:1.1963792948323877\n",
      "train loss:1.3043199816817752\n",
      "train loss:1.3141312596759431\n",
      "train loss:1.2660269675559563\n",
      "train loss:1.357193071958157\n",
      "train loss:1.3838145625844638\n",
      "train loss:1.2049824958173918\n",
      "train loss:1.2930540474713943\n",
      "train loss:1.3878494401105348\n",
      "train loss:1.4410940128506409\n",
      "train loss:1.2954156366039\n",
      "train loss:1.2806461393905963\n",
      "train loss:1.140756266558677\n",
      "train loss:1.2076005092617907\n",
      "train loss:1.255032962316112\n",
      "train loss:1.2633911170185668\n",
      "train loss:1.2427526217654654\n",
      "train loss:1.1407262564139011\n",
      "train loss:1.199575353756532\n",
      "train loss:1.3727562780524112\n",
      "train loss:1.2722926617738741\n",
      "train loss:1.1471416213925711\n",
      "train loss:1.324624969558164\n",
      "train loss:1.2146126648415194\n",
      "train loss:1.256568146458404\n",
      "train loss:1.0916070404743285\n",
      "train loss:1.267882490488646\n",
      "train loss:1.3570179224767978\n",
      "train loss:1.213375890439269\n",
      "train loss:1.1995123932378644\n",
      "train loss:1.3337629478113877\n",
      "train loss:1.2130061381456474\n",
      "train loss:1.2910166121762543\n",
      "train loss:1.256798871782076\n",
      "train loss:1.2293097005235283\n",
      "train loss:1.2796036782330955\n",
      "train loss:1.3301726334512969\n",
      "train loss:1.3949222946047153\n",
      "train loss:1.1689510878455998\n",
      "train loss:1.1974501495494014\n",
      "train loss:1.2310621454118493\n",
      "train loss:0.9545917186897648\n",
      "train loss:1.069434961361952\n",
      "train loss:1.327715427658444\n",
      "train loss:1.3287262495758236\n",
      "train loss:1.152243636327419\n",
      "train loss:1.132977367430025\n",
      "train loss:1.2859191641036734\n",
      "train loss:1.1631544908595581\n",
      "train loss:1.2239206016360986\n",
      "train loss:1.23839759070511\n",
      "train loss:1.351877046215898\n",
      "train loss:1.1588330164884133\n",
      "train loss:1.2237817261604624\n",
      "train loss:1.238435280533073\n",
      "train loss:1.1034116939448735\n",
      "train loss:1.3508745454441058\n",
      "train loss:1.2362718939347257\n",
      "train loss:1.0811857270786323\n",
      "train loss:1.343968771595233\n",
      "train loss:1.325788284668373\n",
      "train loss:1.2997334039369823\n",
      "train loss:1.2960089143953868\n",
      "train loss:1.1193791423872055\n",
      "train loss:1.3163433980229706\n",
      "train loss:1.054281030152912\n",
      "train loss:1.1755273042537038\n",
      "train loss:1.1775053541202412\n",
      "train loss:1.246208301171614\n",
      "train loss:1.3772455143842026\n",
      "train loss:1.254964621779627\n",
      "train loss:1.3275783798533303\n",
      "train loss:1.2640770148870688\n",
      "train loss:1.1414298341095295\n",
      "train loss:0.9700473198847479\n",
      "train loss:1.5641312948492234\n",
      "train loss:1.0924925846330238\n",
      "train loss:1.2733095212503918\n",
      "train loss:1.246066267579544\n",
      "train loss:1.3765159868503547\n",
      "train loss:1.160592585009294\n",
      "train loss:1.207735443442096\n",
      "train loss:1.1809236894132156\n",
      "train loss:1.191722285453453\n",
      "train loss:1.1208236321801934\n",
      "train loss:1.1179652430393978\n",
      "train loss:1.243634123650999\n",
      "train loss:1.0857088695155697\n",
      "train loss:1.188233663781064\n",
      "train loss:1.0458594783035675\n",
      "train loss:1.3462916441834185\n",
      "train loss:1.075710759421202\n",
      "train loss:1.233018337378068\n",
      "train loss:1.3040765526287288\n",
      "train loss:1.3302825449869509\n",
      "train loss:1.1516174426065597\n",
      "train loss:1.0711945103669398\n",
      "train loss:1.3661481282593104\n",
      "train loss:1.1982406228766052\n",
      "train loss:1.0461840395743\n",
      "train loss:1.1364383507877727\n",
      "train loss:1.2502150034439807\n",
      "train loss:1.1632482731756888\n",
      "train loss:1.1479356050307439\n",
      "train loss:0.963034761367151\n",
      "train loss:1.0421968174815062\n",
      "train loss:1.194288060129447\n",
      "train loss:1.0827434405659522\n",
      "train loss:1.15963981648465\n",
      "train loss:1.2561481942001524\n",
      "train loss:0.9743322441260623\n",
      "train loss:1.1526323660100184\n",
      "train loss:1.1384306737548424\n",
      "train loss:1.204822249811622\n",
      "train loss:1.0515783090990707\n",
      "train loss:1.0573775779788537\n",
      "train loss:1.2005910762411809\n",
      "train loss:1.1259751816305312\n",
      "train loss:1.0544483072096957\n",
      "train loss:1.3350152494794845\n",
      "train loss:1.2055831787665894\n",
      "train loss:1.2908399015352023\n",
      "train loss:1.1561836084089694\n",
      "train loss:1.355634281597643\n",
      "train loss:1.2950038275884495\n",
      "train loss:1.3407607131395591\n",
      "train loss:0.9649539941376429\n",
      "train loss:1.222260431347929\n",
      "train loss:1.2799512234940746\n",
      "train loss:1.2874698473693913\n",
      "train loss:1.2520462664867014\n",
      "train loss:1.2410247735293702\n",
      "train loss:1.0877258988501577\n",
      "train loss:1.0201984258197796\n",
      "train loss:1.1033098768589005\n",
      "train loss:1.0775863446783551\n",
      "train loss:1.1293812496113678\n",
      "train loss:1.232650329845458\n",
      "train loss:1.3051676950975883\n",
      "train loss:1.3955063709144175\n",
      "train loss:1.1396399661956433\n",
      "train loss:0.9388189006722135\n",
      "train loss:1.0504025223641438\n",
      "train loss:1.2672997724750135\n",
      "train loss:1.1766543122665096\n",
      "train loss:1.1375961291777936\n",
      "train loss:1.1009821450994466\n",
      "train loss:0.9790638764336689\n",
      "train loss:1.2112527147283203\n",
      "train loss:1.1940347545512382\n",
      "train loss:1.095365082873184\n",
      "train loss:0.9708685220254758\n",
      "train loss:1.2070229973926012\n",
      "train loss:1.233307149394607\n",
      "train loss:1.071107652021083\n",
      "train loss:1.0942704879757779\n",
      "train loss:1.0336630470502362\n",
      "train loss:1.2774749499293336\n",
      "train loss:1.1109696407038507\n",
      "train loss:1.0470189368604905\n",
      "train loss:1.0912804066741946\n",
      "train loss:1.213210385780238\n",
      "train loss:1.1946166930528288\n",
      "train loss:1.0245718349375617\n",
      "train loss:1.23670008726699\n",
      "train loss:1.232010700333011\n",
      "train loss:0.9614982707579061\n",
      "train loss:1.2556988986716757\n",
      "train loss:1.0869772554138502\n",
      "train loss:1.0506082627049462\n",
      "train loss:1.1091324715072255\n",
      "train loss:1.1022324273189872\n",
      "train loss:1.1934412289041807\n",
      "train loss:1.0112939802533463\n",
      "train loss:1.1532348197737878\n",
      "train loss:1.217080801128044\n",
      "train loss:1.2677236226396156\n",
      "train loss:0.9985093617738103\n",
      "train loss:1.3090715201155902\n",
      "train loss:1.3795410442205567\n",
      "train loss:1.193453326607663\n",
      "train loss:1.1191972434633504\n",
      "train loss:1.1354512291546828\n",
      "train loss:1.1458672493597728\n",
      "train loss:1.124717296040291\n",
      "train loss:1.2633651100575336\n",
      "train loss:1.0584885212933566\n",
      "train loss:1.0694362333711973\n",
      "train loss:1.1994921133213496\n",
      "train loss:1.0308037215641663\n",
      "train loss:1.1792583340084852\n",
      "train loss:1.1392844230017942\n",
      "train loss:1.2394243199161674\n",
      "train loss:1.0589950093071945\n",
      "train loss:1.079287878974082\n",
      "train loss:1.0463019727437552\n",
      "train loss:1.1157073221662248\n",
      "train loss:1.2139102105400144\n",
      "train loss:1.0250383024730165\n",
      "train loss:1.0830311474843328\n",
      "train loss:1.196624038745883\n",
      "train loss:1.0208593924108456\n",
      "train loss:1.0138521950965176\n",
      "train loss:1.3036637653191117\n",
      "train loss:1.1041916854031344\n",
      "train loss:1.1826718833577166\n",
      "train loss:1.154662068564056\n",
      "train loss:1.3022769965381\n",
      "train loss:1.2786427503321007\n",
      "train loss:1.185332864334815\n",
      "train loss:1.2171102889017569\n",
      "train loss:1.2199308965585614\n",
      "train loss:1.1496227743356346\n",
      "train loss:1.1449478993636106\n",
      "train loss:0.9290728482324441\n",
      "train loss:1.1188620157477425\n",
      "train loss:1.2356475318237077\n",
      "train loss:1.256703254510744\n",
      "train loss:1.0757858423481348\n",
      "train loss:1.1856972815595495\n",
      "train loss:1.0754522975109921\n",
      "train loss:0.9565087610021559\n",
      "train loss:1.3358393679482146\n",
      "train loss:1.1783555967017083\n",
      "train loss:1.1728411029910724\n",
      "train loss:1.0586806150496748\n",
      "train loss:1.1850985538222158\n",
      "train loss:1.0604725437005065\n",
      "train loss:1.0950222693390448\n",
      "train loss:1.0779933245077193\n",
      "train loss:1.2492316695789265\n",
      "train loss:1.255241549317757\n",
      "train loss:1.2662587833225993\n",
      "train loss:1.0831897943424218\n",
      "train loss:1.0519932589383523\n",
      "train loss:1.0627639372564355\n",
      "train loss:1.300368961473074\n",
      "train loss:1.0747111909421987\n",
      "train loss:1.0452178312893807\n",
      "train loss:1.1007466949504643\n",
      "train loss:1.2154443539979451\n",
      "train loss:1.2591188497897179\n",
      "train loss:1.179972173693222\n",
      "train loss:1.3647832464127734\n",
      "train loss:0.9489381211516923\n",
      "train loss:1.039277311275092\n",
      "train loss:0.994453491757296\n",
      "train loss:1.1350946564240596\n",
      "train loss:1.1244998033347076\n",
      "train loss:1.1654747809278565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:1.097913672072802\n",
      "train loss:1.29724620119826\n",
      "train loss:1.047697260096883\n",
      "train loss:1.1725309466329188\n",
      "train loss:1.0502111732523212\n",
      "train loss:1.0491263071814456\n",
      "train loss:1.219371315491473\n",
      "train loss:1.0126794461811994\n",
      "train loss:0.977672284472296\n",
      "train loss:1.13732087679456\n",
      "train loss:1.2154246252998082\n",
      "train loss:1.091647967134896\n",
      "train loss:1.0532119298741682\n",
      "train loss:1.1649745270073966\n",
      "train loss:1.0427876460693353\n",
      "train loss:1.0904079558311683\n",
      "train loss:1.0642143491161413\n",
      "train loss:1.0618753885187748\n",
      "train loss:1.1759196523320765\n",
      "train loss:1.1268154780587003\n",
      "train loss:1.0721077805410835\n",
      "train loss:1.2340812273375692\n",
      "train loss:1.0444424977716198\n",
      "train loss:1.1188604821817099\n",
      "train loss:1.1388566850866326\n",
      "train loss:1.2626781850193445\n",
      "train loss:0.951449639559886\n",
      "train loss:1.0840850487731846\n",
      "train loss:1.2184462918742986\n",
      "train loss:1.2761488806678587\n",
      "train loss:1.0824171242241838\n",
      "train loss:0.9646156868027381\n",
      "train loss:1.180076483185359\n",
      "train loss:1.043472607663739\n",
      "train loss:1.0587176814876778\n",
      "train loss:1.083186817835882\n",
      "train loss:0.9417213899689088\n",
      "train loss:1.1854288873325225\n",
      "train loss:1.0696908631942366\n",
      "train loss:1.0034532018131959\n",
      "train loss:0.9466488387041453\n",
      "train loss:1.1164597907364566\n",
      "train loss:1.1605896439262586\n",
      "train loss:1.162938978588243\n",
      "train loss:1.170312490656855\n",
      "train loss:1.0984494708422041\n",
      "train loss:1.129648758626666\n",
      "train loss:1.2164426518594014\n",
      "train loss:1.0100993282077941\n",
      "train loss:1.0373655276096538\n",
      "=== epoch:2, train acc:0.975, test acc:0.971 ===\n",
      "train loss:1.23028247408567\n",
      "train loss:1.2294447540375386\n",
      "train loss:1.0715420641071653\n",
      "train loss:1.0293734801646925\n",
      "train loss:1.1808744285403487\n",
      "train loss:1.1108416367328153\n",
      "train loss:1.1451952789192998\n",
      "train loss:1.1971058983637266\n",
      "train loss:1.1842230859558902\n",
      "train loss:1.0795480163256037\n",
      "train loss:1.274803886656763\n",
      "train loss:0.9841553024784669\n",
      "train loss:1.0516895461836577\n",
      "train loss:1.2363447413259714\n",
      "train loss:1.184009106096958\n",
      "train loss:1.2078080949265624\n",
      "train loss:1.13593238034803\n",
      "train loss:1.0975019862663664\n",
      "train loss:1.1127311378227507\n",
      "train loss:1.1479990588772346\n",
      "train loss:0.9728879125032129\n",
      "train loss:1.213962913559237\n",
      "train loss:1.1207638506476085\n",
      "train loss:1.314973337808244\n",
      "train loss:1.0950894813749918\n",
      "train loss:1.1515881028299435\n",
      "train loss:1.1111709034643553\n",
      "train loss:1.0551253765100197\n",
      "train loss:0.9325818865652663\n",
      "train loss:0.8301584252273301\n",
      "train loss:1.1268904794429964\n",
      "train loss:1.0970165283458722\n",
      "train loss:1.0693798481625556\n",
      "train loss:1.2283825245778799\n",
      "train loss:1.0572891208507393\n",
      "train loss:1.1519799363828824\n",
      "train loss:1.1565009257336702\n",
      "train loss:1.0545520302495865\n",
      "train loss:1.2051458436763924\n",
      "train loss:0.969112522406008\n",
      "train loss:1.1758048409768949\n",
      "train loss:1.1759521610208519\n",
      "train loss:1.0445266022279889\n",
      "train loss:1.1747720368961843\n",
      "train loss:1.0967292890889733\n",
      "train loss:1.000109711937948\n",
      "train loss:1.0012694034016252\n",
      "train loss:1.20037436347081\n",
      "train loss:1.0007912699440622\n",
      "train loss:1.134786979953879\n",
      "train loss:0.9674152635354872\n",
      "train loss:1.0428142731900183\n",
      "train loss:0.9238316175959824\n",
      "train loss:1.0139709272190078\n",
      "train loss:1.0250717174571018\n",
      "train loss:1.0638668459224865\n",
      "train loss:0.9346177208432442\n",
      "train loss:0.8279960925854497\n",
      "train loss:1.024162644845908\n",
      "train loss:0.9567275317340013\n",
      "train loss:1.210346063238402\n",
      "train loss:0.9495597330472139\n",
      "train loss:0.9365223165934872\n",
      "train loss:1.2408572469928205\n",
      "train loss:1.0438000837063803\n",
      "train loss:1.065553289935729\n",
      "train loss:1.084953880990119\n",
      "train loss:1.0423778826373438\n",
      "train loss:0.9256136597874939\n",
      "train loss:1.0641022400683275\n",
      "train loss:1.1150286713817732\n",
      "train loss:1.1859946261958871\n",
      "train loss:0.9900007311773698\n",
      "train loss:1.1533785648373966\n",
      "train loss:1.0447436134615118\n",
      "train loss:1.224351030523827\n",
      "train loss:1.090095707092883\n",
      "train loss:1.094190206138811\n",
      "train loss:1.130528764808942\n",
      "train loss:0.9653921321755705\n",
      "train loss:1.2201191662963353\n",
      "train loss:1.1708486965188125\n",
      "train loss:0.9464133772703197\n",
      "train loss:1.0102809285749852\n",
      "train loss:1.1514901439716299\n",
      "train loss:1.1806224864845392\n",
      "train loss:0.9387426380115018\n",
      "train loss:1.1992588516337022\n",
      "train loss:1.001098764229254\n",
      "train loss:1.153260793016341\n",
      "train loss:1.065055377956083\n",
      "train loss:1.0948980757423268\n",
      "train loss:1.2224382572603212\n",
      "train loss:1.1188679791930085\n",
      "train loss:0.9497241983488597\n",
      "train loss:1.2102512641193\n",
      "train loss:1.013781818969908\n",
      "train loss:0.9729591768002968\n",
      "train loss:1.2378122020197149\n",
      "train loss:1.0242271502265397\n",
      "train loss:1.1408134454041616\n",
      "train loss:1.0630896661196643\n",
      "train loss:1.1241825693934127\n",
      "train loss:1.2600905556119206\n",
      "train loss:1.0051626130990872\n",
      "train loss:1.2077413418204215\n",
      "train loss:1.0430268358889903\n",
      "train loss:1.0479058623147897\n",
      "train loss:0.9783496352111528\n",
      "train loss:1.0933294385258208\n",
      "train loss:1.1196935614628472\n",
      "train loss:1.1789020408647284\n",
      "train loss:1.1392876905326657\n",
      "train loss:0.8550703062423197\n",
      "train loss:1.2350564548871046\n",
      "train loss:1.0449624739669372\n",
      "train loss:1.1683860193867652\n",
      "train loss:1.1082539178943576\n",
      "train loss:1.1770770090454004\n",
      "train loss:1.0647500893779986\n",
      "train loss:1.0677268993651836\n",
      "train loss:1.0341903744454104\n",
      "train loss:1.1661037355819157\n",
      "train loss:1.0181353521884302\n",
      "train loss:1.2416228340009554\n",
      "train loss:1.0318188203511027\n",
      "train loss:0.9528108020796054\n",
      "train loss:1.0999408837819318\n",
      "train loss:1.1309977610958821\n",
      "train loss:0.9357838003021495\n",
      "train loss:1.1958435273590717\n",
      "train loss:1.0052238165907597\n",
      "train loss:1.0072912099333766\n",
      "train loss:1.0920576162234323\n",
      "train loss:0.9589995850898978\n",
      "train loss:0.9451638561200143\n",
      "train loss:1.299917622321873\n",
      "train loss:1.2644965999727256\n",
      "train loss:1.2685931286211898\n",
      "train loss:0.9888262320140562\n",
      "train loss:1.119532234269529\n",
      "train loss:1.0620670126731164\n",
      "train loss:1.1316925178380175\n",
      "train loss:0.9834430120621172\n",
      "train loss:0.9786600149465401\n",
      "train loss:0.9084329184591131\n",
      "train loss:1.0385381378609262\n",
      "train loss:1.2002924667782482\n",
      "train loss:1.1494319139048028\n",
      "train loss:1.0680083333453902\n",
      "train loss:1.0203146852147094\n",
      "train loss:0.9609800578343096\n",
      "train loss:0.9275520288381514\n",
      "train loss:1.0978237757520333\n",
      "train loss:1.2333706967296383\n",
      "train loss:1.1585099167910833\n",
      "train loss:0.9783899814346709\n",
      "train loss:1.2502259185614468\n",
      "train loss:1.1701900667584595\n",
      "train loss:1.0202158051202666\n",
      "train loss:1.078186765593134\n",
      "train loss:0.9381714646053609\n",
      "train loss:0.871155635002376\n",
      "train loss:1.063613711926409\n",
      "train loss:1.0273976966446416\n",
      "train loss:1.1496942077051044\n",
      "train loss:1.1684255298943236\n",
      "train loss:0.9070415862445145\n",
      "train loss:1.2526138061094974\n",
      "train loss:1.1372031093160708\n",
      "train loss:0.9621960778635945\n",
      "train loss:0.9512679551712452\n",
      "train loss:1.0410573971102781\n",
      "train loss:1.181978074869675\n",
      "train loss:1.0051349645831626\n",
      "train loss:1.2228715026020744\n",
      "train loss:1.1407950589946487\n",
      "train loss:0.8604725103893364\n",
      "train loss:1.1395849283895605\n",
      "train loss:0.8883433215717267\n",
      "train loss:1.1865051375456968\n",
      "train loss:1.0087011243105832\n",
      "train loss:1.0568121409490294\n",
      "train loss:1.0454562351852386\n",
      "train loss:1.101010146850554\n",
      "train loss:1.2040488379621388\n",
      "train loss:0.979053770617451\n",
      "train loss:1.1824573393271745\n",
      "train loss:1.1028232659089259\n",
      "train loss:1.1571680736450372\n",
      "train loss:1.0639547845975577\n",
      "train loss:0.9002222124749761\n",
      "train loss:1.0703861896005835\n",
      "train loss:1.19570768938172\n",
      "train loss:0.9529885971964799\n",
      "train loss:0.8730815544941508\n",
      "train loss:1.0595430486763981\n",
      "train loss:1.1099581858517225\n",
      "train loss:0.8466288075154864\n",
      "train loss:1.1049256851113711\n",
      "train loss:1.3322913899088582\n",
      "train loss:1.0403768007337395\n",
      "train loss:1.1016014694410965\n",
      "train loss:1.0172222622257974\n",
      "train loss:1.1222191405741015\n",
      "train loss:1.1357321406863174\n",
      "train loss:1.0450213713386847\n",
      "train loss:0.8830420189004482\n",
      "train loss:1.163613546569104\n",
      "train loss:1.0077181920372018\n",
      "train loss:0.9688446259084469\n",
      "train loss:0.8563130761129122\n",
      "train loss:1.0835454037362355\n",
      "train loss:1.2120728026646939\n",
      "train loss:1.0208221535769786\n",
      "train loss:1.1189709137305615\n",
      "train loss:1.0473943044521603\n",
      "train loss:1.2657653088279728\n",
      "train loss:0.9477236804717445\n",
      "train loss:1.0642592196678542\n",
      "train loss:1.0448492800758467\n",
      "train loss:1.0202351644363086\n",
      "train loss:1.0933470496478732\n",
      "train loss:1.154362028073735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.993984985601655\n",
      "train loss:0.9616064639684165\n",
      "train loss:0.9006584890969401\n",
      "train loss:1.032941360565387\n",
      "train loss:0.9648000805268774\n",
      "train loss:1.1255995730689126\n",
      "train loss:1.2158043731877675\n",
      "train loss:1.1083194535459382\n",
      "train loss:1.1992720266369532\n",
      "train loss:1.0958520255552655\n",
      "train loss:1.037510399100614\n",
      "train loss:0.9767217157288435\n",
      "train loss:1.02351852953205\n",
      "train loss:0.8749904427161717\n",
      "train loss:1.09232174836478\n",
      "train loss:0.855076709155745\n",
      "train loss:1.1004901480719878\n",
      "train loss:0.9542198963437721\n",
      "train loss:1.0289347886307783\n",
      "train loss:1.0923488464129836\n",
      "train loss:1.0157864495603763\n",
      "train loss:0.9792482145614602\n",
      "train loss:0.8356688905572303\n",
      "train loss:1.0301493770991441\n",
      "train loss:1.0258416196390607\n",
      "train loss:0.9712932454312666\n",
      "train loss:1.2075430294204366\n",
      "train loss:1.1888902033286726\n",
      "train loss:1.1433472816260846\n",
      "train loss:0.963963572201906\n",
      "train loss:1.3882318678252146\n",
      "train loss:0.9659037933888177\n",
      "train loss:0.8429685823427178\n",
      "train loss:1.1833778349132162\n",
      "train loss:0.9537518359106365\n",
      "train loss:1.1128341918542712\n",
      "train loss:1.0023905528446302\n",
      "train loss:0.978688448003236\n",
      "train loss:1.1292029772741312\n",
      "train loss:0.9921211912339528\n",
      "train loss:0.9205085678189334\n",
      "train loss:1.0162071535933068\n",
      "train loss:1.0773455085574057\n",
      "train loss:1.2424527225286168\n",
      "train loss:0.9435963132907742\n",
      "train loss:1.3603341221359668\n",
      "train loss:1.108420266682205\n",
      "train loss:0.9825911865125299\n",
      "train loss:0.9761293898418255\n",
      "train loss:1.0052447669769142\n",
      "train loss:1.086814106190081\n",
      "train loss:1.1210564196703274\n",
      "train loss:1.1862728410880217\n",
      "train loss:0.9818515959116705\n",
      "train loss:1.1054378449853737\n",
      "train loss:1.1092038577458234\n",
      "train loss:1.0506235161896837\n",
      "train loss:1.0903931382665144\n",
      "train loss:1.1225199072123742\n",
      "train loss:0.8854695742148876\n",
      "train loss:0.9834570058527942\n",
      "train loss:1.0099839229765137\n",
      "train loss:1.1678928102835449\n",
      "train loss:0.8927246626887242\n",
      "train loss:1.0346762495949253\n",
      "train loss:1.1052660043011568\n",
      "train loss:1.1244201149623076\n",
      "train loss:1.100343380313165\n",
      "train loss:0.9863121442830918\n",
      "train loss:0.9518610165881961\n",
      "train loss:0.9809365420583752\n",
      "train loss:0.9175172229872782\n",
      "train loss:1.2213940398801966\n",
      "train loss:1.028152229243763\n",
      "train loss:1.0782778249737577\n",
      "train loss:0.9753415640615044\n",
      "train loss:0.8464660851462327\n",
      "train loss:0.9508184761281739\n",
      "train loss:0.8575356807553782\n",
      "train loss:0.8580959371190245\n",
      "train loss:1.084969507978325\n",
      "train loss:1.0130058576550645\n",
      "train loss:1.1174135996131291\n",
      "train loss:0.9282343047832362\n",
      "train loss:0.8945681090597524\n",
      "train loss:1.1221091132299434\n",
      "train loss:1.2528303090702848\n",
      "train loss:1.0592652917643601\n",
      "train loss:1.1256300287977377\n",
      "train loss:1.2636623270986396\n",
      "train loss:1.0283253744616971\n",
      "train loss:1.04379316938516\n",
      "train loss:0.8721976251559677\n",
      "train loss:0.922483731953638\n",
      "train loss:1.0884642498672663\n",
      "train loss:0.9401333822554071\n",
      "train loss:1.1334548604254358\n",
      "train loss:1.0533558895042534\n",
      "train loss:1.073448842893886\n",
      "train loss:0.8665663207701203\n",
      "train loss:1.0460688841236339\n",
      "train loss:0.9854681836543571\n",
      "train loss:1.0061793790160822\n",
      "train loss:1.17435467413266\n",
      "train loss:1.1273390504650267\n",
      "train loss:0.991583033294686\n",
      "train loss:0.9450419823510094\n",
      "train loss:0.9185324125091647\n",
      "train loss:1.1181801931289423\n",
      "train loss:0.8903947169316071\n",
      "train loss:0.9211901090719841\n",
      "train loss:1.1480341951291535\n",
      "train loss:0.8369106393408451\n",
      "train loss:0.8388262073381465\n",
      "train loss:1.1056624438923999\n",
      "train loss:1.0874273097045395\n",
      "train loss:0.8884581826148356\n",
      "train loss:1.1129274084671632\n",
      "train loss:0.8997277136352743\n",
      "train loss:1.0325706631983305\n",
      "train loss:0.9631671548026152\n",
      "train loss:0.971911246508259\n",
      "train loss:1.0434552662948477\n",
      "train loss:0.9927649606174324\n",
      "train loss:1.049617155245466\n",
      "train loss:0.795257317661402\n",
      "train loss:0.9808304854466564\n",
      "train loss:1.1800539153401468\n",
      "train loss:1.165798159067367\n",
      "train loss:0.9619285676338233\n",
      "train loss:0.974024752105817\n",
      "train loss:0.9787298961959291\n",
      "train loss:1.2156875458685823\n",
      "train loss:1.034519709138431\n",
      "train loss:1.0539268300703561\n",
      "train loss:0.9211128385736805\n",
      "train loss:0.9025187346367812\n",
      "train loss:1.0649923468484266\n",
      "train loss:0.8893555820413604\n",
      "train loss:1.057587658052224\n",
      "train loss:0.931036091290278\n",
      "train loss:0.9692730484491949\n",
      "train loss:0.7341346827858074\n",
      "train loss:1.1114194564735087\n",
      "train loss:0.9250759753823807\n",
      "train loss:1.0715219323873721\n",
      "train loss:1.1539865002247824\n",
      "train loss:0.9261870981409152\n",
      "train loss:0.8797115433818868\n",
      "train loss:0.9838332657352369\n",
      "train loss:0.9964515744347618\n",
      "train loss:1.0286061044600239\n",
      "train loss:1.0181395143952408\n",
      "train loss:1.063528284750658\n",
      "train loss:0.9589300027382079\n",
      "train loss:0.9222137787190618\n",
      "train loss:1.0422024763619324\n",
      "train loss:0.9145792699275447\n",
      "train loss:0.932144313517945\n",
      "train loss:0.9708567454513503\n",
      "train loss:1.0344463530879626\n",
      "train loss:0.8969862886662642\n",
      "train loss:1.0227611588535843\n",
      "train loss:1.04471688668219\n",
      "train loss:1.0753930064220667\n",
      "train loss:1.114555192959511\n",
      "train loss:1.13054399262124\n",
      "train loss:0.835889638424079\n",
      "train loss:1.0104676450894874\n",
      "train loss:1.1025069151766278\n",
      "train loss:1.1017625496377423\n",
      "train loss:1.0226532338017227\n",
      "train loss:1.3565229412762192\n",
      "train loss:1.009943553963088\n",
      "train loss:1.0658638118317798\n",
      "train loss:1.0289151389442515\n",
      "train loss:1.0165539065196392\n",
      "train loss:1.0046646172150528\n",
      "train loss:0.9159189874812114\n",
      "train loss:0.9777154883895461\n",
      "train loss:1.129202559400964\n",
      "train loss:0.9662951937983114\n",
      "train loss:0.986487385083501\n",
      "train loss:1.0257683622800635\n",
      "train loss:0.920654789903592\n",
      "train loss:0.9812376965209304\n",
      "train loss:1.1456589177828038\n",
      "train loss:1.1786301835325546\n",
      "train loss:1.083394513913185\n",
      "train loss:0.8400969614661462\n",
      "train loss:0.8953195088241998\n",
      "train loss:0.9639656007697787\n",
      "train loss:1.1503920886384704\n",
      "train loss:1.0076711227263286\n",
      "train loss:1.0306560491333419\n",
      "train loss:1.0412117134822074\n",
      "train loss:0.9102637156490949\n",
      "train loss:0.8807500195684825\n",
      "train loss:0.9394609125215494\n",
      "train loss:0.8928344351085138\n",
      "train loss:0.8503203338039209\n",
      "train loss:1.0282130772249563\n",
      "train loss:1.0072370238092834\n",
      "train loss:1.147038993573006\n",
      "train loss:0.985683328859884\n",
      "train loss:1.0514832971992005\n",
      "train loss:1.1467380608533155\n",
      "train loss:1.0746601992127374\n",
      "train loss:1.0987617760446606\n",
      "train loss:1.1464440029300484\n",
      "train loss:0.8841183986519968\n",
      "train loss:1.0086543360555311\n",
      "train loss:0.9812021814236762\n",
      "train loss:0.9547790922237078\n",
      "train loss:0.9186165192968221\n",
      "train loss:0.7901443775003597\n",
      "train loss:0.858634556989631\n",
      "train loss:1.1435335273942788\n",
      "train loss:1.0227271121856714\n",
      "train loss:0.9769252508019504\n",
      "train loss:1.0420235399806055\n",
      "train loss:0.9927124282539604\n",
      "train loss:1.0400929977689988\n",
      "train loss:1.063720171044375\n",
      "train loss:0.9002218969042823\n",
      "train loss:1.0261334757745992\n",
      "train loss:0.9188393923004778\n",
      "train loss:1.1112797795889158\n",
      "train loss:0.9416575606801031\n",
      "train loss:0.8131273929154014\n",
      "train loss:1.0540693092493623\n",
      "train loss:0.979237246910467\n",
      "train loss:0.9571858462494701\n",
      "train loss:1.1940140284954002\n",
      "train loss:0.9718429557936028\n",
      "train loss:0.9536540059770114\n",
      "train loss:1.0763926671813693\n",
      "train loss:0.9558914429736092\n",
      "train loss:0.8518817338125118\n",
      "train loss:0.9952767835244974\n",
      "train loss:0.8476084108026636\n",
      "train loss:1.097824757689053\n",
      "train loss:0.8269324289491358\n",
      "train loss:1.0430769338986936\n",
      "train loss:0.8000191097726146\n",
      "train loss:1.0647781672198817\n",
      "train loss:0.9307224099453281\n",
      "train loss:1.0262159996815963\n",
      "train loss:1.0279409813102551\n",
      "train loss:1.0216996157999203\n",
      "train loss:1.1332135070497484\n",
      "train loss:1.040336231448135\n",
      "train loss:1.2042727772190778\n",
      "train loss:1.0342992255051564\n",
      "train loss:1.099764840781392\n",
      "train loss:1.030030728086408\n",
      "train loss:1.0793295754561143\n",
      "train loss:1.1309713146609621\n",
      "train loss:1.0553150985234425\n",
      "train loss:1.092045375588909\n",
      "train loss:1.0843870153724893\n",
      "train loss:0.9456032599242044\n",
      "train loss:1.0410734109002058\n",
      "train loss:1.0184577586245513\n",
      "train loss:0.8256254355425799\n",
      "train loss:0.896274622823681\n",
      "train loss:1.0381054087383799\n",
      "train loss:1.0994937292030242\n",
      "train loss:1.0721435242810182\n",
      "train loss:0.9820202125804605\n",
      "train loss:1.1852976433913562\n",
      "train loss:0.8955410296337736\n",
      "train loss:1.059099824731623\n",
      "train loss:1.0180433843364929\n",
      "train loss:1.1715861699787233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:1.20973272323603\n",
      "train loss:0.849370761663213\n",
      "train loss:1.1064110433963088\n",
      "train loss:1.0724500013907001\n",
      "train loss:1.037409024380724\n",
      "train loss:0.9447849933692549\n",
      "train loss:0.9025564897680574\n",
      "train loss:1.095684658655619\n",
      "train loss:0.9914736777454145\n",
      "train loss:1.0044858457612422\n",
      "train loss:0.8533107475148648\n",
      "train loss:0.979328692488295\n",
      "train loss:1.1091324041423525\n",
      "train loss:1.0269860557673702\n",
      "train loss:0.9965796515573337\n",
      "train loss:1.0608019413422807\n",
      "train loss:1.0835771724161039\n",
      "train loss:0.9072681588963085\n",
      "train loss:1.0072378834327516\n",
      "train loss:0.8855595195983075\n",
      "train loss:0.7783521520388943\n",
      "train loss:0.967235716092404\n",
      "train loss:0.8927420649168019\n",
      "train loss:0.9858989565407384\n",
      "train loss:1.099305393185223\n",
      "train loss:0.9488053472952075\n",
      "train loss:1.1393410037294514\n",
      "train loss:1.1234042981913466\n",
      "train loss:0.9680247375679475\n",
      "train loss:0.8308967486480909\n",
      "train loss:0.9514669814771193\n",
      "train loss:1.0435095176101057\n",
      "train loss:1.0197353372378684\n",
      "train loss:0.9386561102139978\n",
      "train loss:0.9804338685496358\n",
      "train loss:0.7771603659703108\n",
      "train loss:1.0803712544637438\n",
      "train loss:0.9983890711904989\n",
      "train loss:1.0125106554432508\n",
      "train loss:0.9644282882512778\n",
      "train loss:1.03523747895481\n",
      "train loss:0.9417358034540213\n",
      "train loss:0.9768784714068766\n",
      "train loss:1.2639624508359117\n",
      "train loss:0.9626310051779927\n",
      "train loss:0.9404310096868531\n",
      "train loss:1.0010012343192316\n",
      "train loss:1.0953815231581934\n",
      "train loss:0.9327997987866632\n",
      "train loss:1.089853217020032\n",
      "train loss:1.0575191484114952\n",
      "train loss:0.9838125265030984\n",
      "train loss:0.9877964913484486\n",
      "train loss:0.9149538148147633\n",
      "train loss:0.876564701696644\n",
      "train loss:0.8728578175407297\n",
      "train loss:1.089135470551349\n",
      "train loss:0.9909191121563419\n",
      "train loss:0.9609812392404183\n",
      "train loss:0.9224982823644479\n",
      "train loss:1.028404732051822\n",
      "train loss:1.0420393021429946\n",
      "train loss:0.7766418880818415\n",
      "train loss:0.9878178052501714\n",
      "train loss:1.0665151823902104\n",
      "train loss:1.1095503515700413\n",
      "train loss:1.0666384628358074\n",
      "train loss:1.0682330911470486\n",
      "train loss:1.0741882349221101\n",
      "train loss:0.9493190017360732\n",
      "train loss:0.8228775945166983\n",
      "train loss:1.186316414877453\n",
      "train loss:1.030643997670784\n",
      "train loss:1.1761693268178006\n",
      "train loss:0.9684361072110302\n",
      "train loss:1.0188961056868875\n",
      "train loss:1.0835472049507098\n",
      "train loss:1.2200341928128662\n",
      "train loss:1.1851673874036646\n",
      "train loss:0.9464669569032403\n",
      "train loss:0.9354838943428462\n",
      "train loss:0.8562013069672315\n",
      "train loss:1.079395360028595\n",
      "train loss:0.9122474191125121\n",
      "train loss:1.040607651334684\n",
      "train loss:0.9690413913790452\n",
      "train loss:0.9550295497559301\n",
      "train loss:0.9628592513496812\n",
      "train loss:0.8654647541045667\n",
      "train loss:1.0636084153801375\n",
      "train loss:1.1076799558528851\n",
      "train loss:0.9033756651728168\n",
      "train loss:1.0674632724544384\n",
      "train loss:1.1066012971107062\n",
      "train loss:1.1014830496294514\n",
      "train loss:1.1021201123786846\n",
      "train loss:1.1569188940330954\n",
      "train loss:0.8978195814126232\n",
      "train loss:1.0074759081513533\n",
      "train loss:0.9592243087714778\n",
      "=== epoch:3, train acc:0.983, test acc:0.984 ===\n",
      "train loss:1.0340768120897876\n",
      "train loss:0.9820340806759966\n",
      "train loss:0.8622512844010493\n",
      "train loss:1.0678009486300597\n",
      "train loss:0.9449764140979804\n",
      "train loss:1.0183453125047313\n",
      "train loss:1.0261734354312315\n",
      "train loss:1.1474297591404108\n",
      "train loss:0.9589219696707915\n",
      "train loss:1.1314198281825636\n",
      "train loss:0.9789242778500151\n",
      "train loss:1.0018238356004658\n",
      "train loss:0.9486785412570796\n",
      "train loss:1.1690557081319235\n",
      "train loss:1.0970135918467367\n",
      "train loss:1.0432309090110008\n",
      "train loss:1.1648119141892044\n",
      "train loss:0.9836115491146837\n",
      "train loss:1.010035128937124\n",
      "train loss:1.0122553016181646\n",
      "train loss:0.9666727862704309\n",
      "train loss:0.9871707286831289\n",
      "train loss:1.086052612011533\n",
      "train loss:1.1098760494026991\n",
      "train loss:1.0918228365734803\n",
      "train loss:0.8633345506091693\n",
      "train loss:1.080913434401575\n",
      "train loss:1.2055181707056426\n",
      "train loss:1.0887305623641037\n",
      "train loss:1.0481165806314983\n",
      "train loss:1.0894756578715514\n",
      "train loss:0.9348734702709565\n",
      "train loss:0.9703331453883625\n",
      "train loss:1.0579575142926558\n",
      "train loss:1.0636607809403862\n",
      "train loss:1.0429312190270204\n",
      "train loss:1.016051561811527\n",
      "train loss:0.9472351434703815\n",
      "train loss:1.0311483666630499\n",
      "train loss:0.9079005315547807\n",
      "train loss:0.9999278165701463\n",
      "train loss:1.0526284801527537\n",
      "train loss:1.0333293430005153\n",
      "train loss:0.8901818343217368\n",
      "train loss:1.1251124653946312\n",
      "train loss:1.046831452787559\n",
      "train loss:0.9195463010883771\n",
      "train loss:0.8643222281252796\n",
      "train loss:0.986021081452203\n",
      "train loss:1.0351276238838891\n",
      "train loss:0.9058833777264138\n",
      "train loss:1.0903448872311885\n",
      "train loss:0.8867890200348856\n",
      "train loss:1.084482710209705\n",
      "train loss:0.9187926278441334\n",
      "train loss:0.9782883352225423\n",
      "train loss:0.9439655104693836\n",
      "train loss:1.0021007393784778\n",
      "train loss:1.1764900781113825\n",
      "train loss:0.9405227739328947\n",
      "train loss:1.1314163894311222\n",
      "train loss:0.8906158712324104\n",
      "train loss:1.007495108994935\n",
      "train loss:0.9974841999502949\n",
      "train loss:0.9896853302697558\n",
      "train loss:0.861636153201273\n",
      "train loss:0.9144142856488987\n",
      "train loss:0.9282288614994216\n",
      "train loss:1.0988607308525138\n",
      "train loss:1.0194035989977615\n",
      "train loss:1.0755720154010506\n",
      "train loss:1.031317664126271\n",
      "train loss:1.0405407248388463\n",
      "train loss:1.1670046561416287\n",
      "train loss:1.1330295434321502\n",
      "train loss:1.1509837310349043\n",
      "train loss:0.9736351474997167\n",
      "train loss:0.988150652994419\n",
      "train loss:1.0745161023567322\n",
      "train loss:0.9317794572879265\n",
      "train loss:1.0876032504372812\n",
      "train loss:0.8695987777088554\n",
      "train loss:1.0834352213226914\n",
      "train loss:0.8720119702648554\n",
      "train loss:1.0561183943073298\n",
      "train loss:1.0621862397244601\n",
      "train loss:0.883522619216091\n",
      "train loss:1.0579254313230164\n",
      "train loss:0.7875836415051992\n",
      "train loss:0.971175454017208\n",
      "train loss:0.9257950414102551\n",
      "train loss:0.8088267590847003\n",
      "train loss:0.9303929974148152\n",
      "train loss:0.7999269965299044\n",
      "train loss:1.129870419396599\n",
      "train loss:0.8910857935805818\n",
      "train loss:1.112240552524512\n",
      "train loss:0.942196708922303\n",
      "train loss:0.8017754223801874\n",
      "train loss:1.1684266722645398\n",
      "train loss:0.8845977932370753\n",
      "train loss:1.0309191738755517\n",
      "train loss:0.8689265292467405\n",
      "train loss:0.9796880481666925\n",
      "train loss:0.9583965890476273\n",
      "train loss:0.9448865879271127\n",
      "train loss:1.060118165213387\n",
      "train loss:1.2363035729795664\n",
      "train loss:1.1650854178315198\n",
      "train loss:1.0088080784191056\n",
      "train loss:0.889572553209875\n",
      "train loss:0.9847804431008699\n",
      "train loss:0.9839239174584149\n",
      "train loss:0.8892289126256757\n",
      "train loss:1.1216329797504587\n",
      "train loss:0.8202533332562463\n",
      "train loss:0.9776146532343342\n",
      "train loss:0.7669389238931317\n",
      "train loss:0.9733477662759829\n",
      "train loss:1.0451405127058668\n",
      "train loss:0.7185870926209565\n",
      "train loss:1.049326560657253\n",
      "train loss:1.070821027112275\n",
      "train loss:1.0108304006931441\n",
      "train loss:0.8886876342860153\n",
      "train loss:0.9279650616292447\n",
      "train loss:1.0512296556252394\n",
      "train loss:1.0236078019161763\n",
      "train loss:0.9966500215472739\n",
      "train loss:0.9935389047816028\n",
      "train loss:0.9972407423510417\n",
      "train loss:0.9742903054855693\n",
      "train loss:1.024874934124443\n",
      "train loss:1.0286728974501615\n",
      "train loss:1.1234071529167335\n",
      "train loss:0.9903474654591159\n",
      "train loss:1.0899475400037488\n",
      "train loss:1.0417802514821901\n",
      "train loss:0.8251408915097693\n",
      "train loss:0.9355231268559863\n",
      "train loss:0.9220608664592622\n",
      "train loss:0.9870437078190344\n",
      "train loss:0.8296068188573413\n",
      "train loss:0.9617886682059412\n",
      "train loss:0.9527311422713599\n",
      "train loss:0.8865238638160424\n",
      "train loss:0.9761483895340939\n",
      "train loss:0.8342802790252457\n",
      "train loss:0.8903469192390756\n",
      "train loss:0.8927707639035369\n",
      "train loss:0.9050726699234712\n",
      "train loss:1.0559745145020905\n",
      "train loss:0.9062092892550874\n",
      "train loss:0.7643849713218299\n",
      "train loss:0.8714707268500669\n",
      "train loss:1.117103160492433\n",
      "train loss:0.9864987220279876\n",
      "train loss:0.7318643408237772\n",
      "train loss:1.0261765783622294\n",
      "train loss:0.957183954862419\n",
      "train loss:0.9086520132657919\n",
      "train loss:0.8824848744274577\n",
      "train loss:0.9358939092949409\n",
      "train loss:0.9636467728410081\n",
      "train loss:0.9870154969137078\n",
      "train loss:0.9572076052026324\n",
      "train loss:0.9760262793142036\n",
      "train loss:1.0091902942635478\n",
      "train loss:1.0111154979001562\n",
      "train loss:0.9110902681491442\n",
      "train loss:0.8434966481246878\n",
      "train loss:0.9787452135098391\n",
      "train loss:1.0699815996486834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:1.0258225507753658\n",
      "train loss:0.9884739718195107\n",
      "train loss:0.985242599509857\n",
      "train loss:1.040896439917657\n",
      "train loss:1.1138924081525206\n",
      "train loss:0.7569116245019167\n",
      "train loss:0.8637408498735436\n",
      "train loss:0.9471557932732233\n",
      "train loss:1.0838755534511735\n",
      "train loss:1.0496232086568298\n",
      "train loss:1.101446988179355\n",
      "train loss:1.1214442313513393\n",
      "train loss:0.9625692436656063\n",
      "train loss:1.0169457828255335\n",
      "train loss:1.0808320258715565\n",
      "train loss:0.8243651452305373\n",
      "train loss:1.1387516322541715\n",
      "train loss:0.9933189380750753\n",
      "train loss:0.8623447318424654\n",
      "train loss:1.1250659803683274\n",
      "train loss:0.9304248817596011\n",
      "train loss:1.00723382897371\n",
      "train loss:0.9352456788479819\n",
      "train loss:1.0672707700623278\n",
      "train loss:1.1072764750947688\n",
      "train loss:0.9197365013407446\n",
      "train loss:1.0780482131343196\n",
      "train loss:1.2271210085702025\n",
      "train loss:0.9475389649216818\n",
      "train loss:0.9460068643041901\n",
      "train loss:0.9618627673447985\n",
      "train loss:1.0353114867083166\n",
      "train loss:0.947463384827642\n",
      "train loss:0.7240848284926735\n",
      "train loss:0.9668793945760266\n",
      "train loss:1.0836952409218474\n",
      "train loss:0.8519705034503505\n",
      "train loss:0.9947345155307636\n",
      "train loss:1.038308731969559\n",
      "train loss:0.9498070855399068\n",
      "train loss:1.1060595224671623\n",
      "train loss:1.0313475546015654\n",
      "train loss:0.8869148604003417\n",
      "train loss:1.0698540176560993\n",
      "train loss:0.877597113054589\n",
      "train loss:0.95299522081123\n",
      "train loss:0.9150563726240692\n",
      "train loss:0.9835360071924516\n",
      "train loss:1.0113594740897007\n",
      "train loss:1.1418697550992944\n",
      "train loss:0.847133919848201\n",
      "train loss:0.873463689226692\n",
      "train loss:1.0804725886153113\n",
      "train loss:0.942693894095691\n",
      "train loss:1.0955905310277\n",
      "train loss:0.9529874710521555\n",
      "train loss:1.1242756094800235\n",
      "train loss:1.0875787741542104\n",
      "train loss:1.108205812974925\n",
      "train loss:1.0391125816132378\n",
      "train loss:0.8139381673284024\n",
      "train loss:0.9768694888605824\n",
      "train loss:1.00948155189184\n",
      "train loss:1.0071189907679077\n",
      "train loss:1.0644437034115812\n",
      "train loss:0.8213218533802029\n",
      "train loss:0.9946977920720821\n",
      "train loss:0.9202214656229701\n",
      "train loss:0.9566488105964405\n",
      "train loss:0.9102889008098037\n",
      "train loss:0.9334269496761749\n",
      "train loss:1.15865489215708\n",
      "train loss:1.0000900692634753\n",
      "train loss:0.9883501383345762\n",
      "train loss:1.0515810772276761\n",
      "train loss:1.0198323661018789\n",
      "train loss:1.0121420095680898\n",
      "train loss:1.0214767609574646\n",
      "train loss:0.8127246525669662\n",
      "train loss:0.9832481673702286\n",
      "train loss:1.0509739127787314\n",
      "train loss:1.002285939167461\n",
      "train loss:0.7944551739695497\n",
      "train loss:0.9134081657207278\n",
      "train loss:0.8922549739726197\n",
      "train loss:0.7750252402538963\n",
      "train loss:0.9872902681370345\n",
      "train loss:0.8635690018837684\n",
      "train loss:1.128428109489008\n",
      "train loss:0.9218462958638282\n",
      "train loss:0.8593179669110111\n",
      "train loss:0.8323919852461007\n",
      "train loss:1.1080056615425828\n",
      "train loss:0.9647371056074877\n",
      "train loss:1.125139618030803\n",
      "train loss:1.0254266431628707\n",
      "train loss:1.0197369980180135\n",
      "train loss:0.952245848293817\n",
      "train loss:1.0179254957870842\n",
      "train loss:0.8348393673197931\n",
      "train loss:0.9289199741696781\n",
      "train loss:1.0151110248813513\n",
      "train loss:0.9090876635328153\n",
      "train loss:0.8360776095707078\n",
      "train loss:0.9370640997409357\n",
      "train loss:0.975611978955315\n",
      "train loss:0.9842259234000201\n",
      "train loss:0.978290834282473\n",
      "train loss:0.8999359252135009\n",
      "train loss:1.2370881041894548\n",
      "train loss:1.042452047564457\n",
      "train loss:1.0341217036555306\n",
      "train loss:1.1358751020837332\n",
      "train loss:0.8870276622350919\n",
      "train loss:1.079324465085901\n",
      "train loss:1.1034514732188823\n",
      "train loss:1.0315215859077995\n",
      "train loss:0.9580078225904566\n",
      "train loss:0.971080947393624\n",
      "train loss:1.0677418383824742\n",
      "train loss:0.9309056982565096\n",
      "train loss:1.106888225813131\n",
      "train loss:1.0826443749844241\n",
      "train loss:0.9266875971730589\n",
      "train loss:0.8492813459329613\n",
      "train loss:1.0459750477807421\n",
      "train loss:1.0951338642130755\n",
      "train loss:0.806778277841924\n",
      "train loss:1.1513780292580391\n",
      "train loss:0.9650814618929543\n",
      "train loss:1.0434773077384927\n",
      "train loss:1.1018075794269986\n",
      "train loss:0.8493735300510409\n",
      "train loss:1.0165243800861945\n",
      "train loss:0.9756458459350104\n",
      "train loss:0.8719756322534351\n",
      "train loss:0.8757071096032761\n",
      "train loss:0.8332087798802607\n",
      "train loss:1.034086007773752\n",
      "train loss:0.9608273814085304\n",
      "train loss:0.9733576734050864\n",
      "train loss:0.9488690046574986\n",
      "train loss:0.9184737885081116\n",
      "train loss:0.9368325253619684\n",
      "train loss:1.1509332312839924\n",
      "train loss:1.0763862383420504\n",
      "train loss:0.8086349079976486\n",
      "train loss:0.9283803409087968\n",
      "train loss:1.0788657266114876\n",
      "train loss:0.9346321570631326\n",
      "train loss:0.984944685342331\n",
      "train loss:1.0815371055573293\n",
      "train loss:0.9827899222484031\n",
      "train loss:1.1435097996862569\n",
      "train loss:1.1007568044442424\n",
      "train loss:1.0181035138604444\n",
      "train loss:0.8493028735520344\n",
      "train loss:0.8629332342731825\n",
      "train loss:1.2060000473042618\n",
      "train loss:0.9909764849812339\n",
      "train loss:1.0035891362161211\n",
      "train loss:0.9780401889828676\n",
      "train loss:0.7956872378553855\n",
      "train loss:1.054311767658963\n",
      "train loss:0.9851921065007755\n",
      "train loss:0.9880898862736375\n",
      "train loss:0.919744606340727\n",
      "train loss:1.1262742372517083\n",
      "train loss:0.903926093345197\n",
      "train loss:1.0995468423699086\n",
      "train loss:0.9021017348180007\n",
      "train loss:0.736177159028852\n",
      "train loss:0.9013022151691936\n",
      "train loss:0.9282630482702484\n",
      "train loss:1.0543005015545182\n",
      "train loss:0.9565145172902112\n",
      "train loss:0.9809445963862892\n",
      "train loss:0.9274748127852184\n",
      "train loss:1.0701476341057683\n",
      "train loss:1.1721544578634822\n",
      "train loss:0.8122740481268348\n",
      "train loss:0.9340999836352312\n",
      "train loss:0.8649799136319387\n",
      "train loss:1.0798328233578576\n",
      "train loss:0.9743031670576577\n",
      "train loss:1.1024007933475755\n",
      "train loss:0.8147862274640457\n",
      "train loss:0.8225887315343692\n",
      "train loss:0.9146916951034463\n",
      "train loss:0.8394883994605316\n",
      "train loss:0.8066583901766674\n",
      "train loss:0.8674877753277436\n",
      "train loss:1.0066753945281615\n",
      "train loss:0.9193054786447487\n",
      "train loss:0.9421211586994986\n",
      "train loss:1.0745003513910327\n",
      "train loss:0.8283360996126681\n",
      "train loss:0.9771293064754748\n",
      "train loss:0.9479271479188899\n",
      "train loss:0.9495180861000365\n",
      "train loss:1.0612150910199223\n",
      "train loss:0.9632276601867699\n",
      "train loss:0.8399698358220837\n",
      "train loss:0.9141840729699209\n",
      "train loss:1.073834248526292\n",
      "train loss:0.9785068750481685\n",
      "train loss:0.8997910458092865\n",
      "train loss:1.0437169091504108\n",
      "train loss:1.0168072865199074\n",
      "train loss:1.0326979179101519\n",
      "train loss:1.0862909731381258\n",
      "train loss:0.846118055247479\n",
      "train loss:0.9783313736949819\n",
      "train loss:1.0150632410459475\n",
      "train loss:0.9889055162309817\n",
      "train loss:1.0337624778388486\n",
      "train loss:1.0533988266898722\n",
      "train loss:1.0299765587018854\n",
      "train loss:0.931681090390828\n",
      "train loss:0.9549293176680874\n",
      "train loss:0.8983271450656746\n",
      "train loss:0.8213822344203392\n",
      "train loss:0.9535536010015514\n",
      "train loss:1.0551479359396567\n",
      "train loss:1.0253638272613412\n",
      "train loss:0.9051912173087092\n",
      "train loss:0.9963747579442352\n",
      "train loss:0.8148131010153308\n",
      "train loss:0.7789781708150726\n",
      "train loss:0.9694130069189582\n",
      "train loss:0.917654073964968\n",
      "train loss:0.9955507029210859\n",
      "train loss:1.0619357847130082\n",
      "train loss:0.8784159083969142\n",
      "train loss:0.8630914742475584\n",
      "train loss:1.093992300942116\n",
      "train loss:0.8893987308344632\n",
      "train loss:1.038965916579773\n",
      "train loss:1.1136030057480837\n",
      "train loss:0.8481954408768736\n",
      "train loss:0.9533001295497457\n",
      "train loss:0.9077288756044735\n",
      "train loss:0.824389428279151\n",
      "train loss:0.842621373200324\n",
      "train loss:0.8604115627796252\n",
      "train loss:0.9860977307253654\n",
      "train loss:0.9197602819920947\n",
      "train loss:0.9746325252879394\n",
      "train loss:0.9834799035149385\n",
      "train loss:0.7158497926838969\n",
      "train loss:0.9237847900753365\n",
      "train loss:0.8908809986084394\n",
      "train loss:0.9616643891148238\n",
      "train loss:1.1482125459851655\n",
      "train loss:1.0504178295432731\n",
      "train loss:0.9642433358347524\n",
      "train loss:0.9090084720683859\n",
      "train loss:0.8691991025123517\n",
      "train loss:1.0054358195664017\n",
      "train loss:1.0267801475808527\n",
      "train loss:0.9561223376410986\n",
      "train loss:1.0117536381908994\n",
      "train loss:0.9891604672678502\n",
      "train loss:0.8593778136645197\n",
      "train loss:0.9909546386204785\n",
      "train loss:0.9516044190735411\n",
      "train loss:1.019770579695334\n",
      "train loss:0.9733145629025514\n",
      "train loss:0.9280980238484705\n",
      "train loss:1.0581810298496226\n",
      "train loss:0.9049677844844165\n",
      "train loss:1.0418000987845155\n",
      "train loss:0.9018778728811234\n",
      "train loss:0.9117601897338226\n",
      "train loss:1.0083021668404661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.9113111517439827\n",
      "train loss:0.9430936228672422\n",
      "train loss:1.0623865579027774\n",
      "train loss:1.0059692409181908\n",
      "train loss:1.0579180696430506\n",
      "train loss:0.9182791432371257\n",
      "train loss:0.9867865782828974\n",
      "train loss:0.8141265118355071\n",
      "train loss:0.9333237194856997\n",
      "train loss:0.9125565952114164\n",
      "train loss:0.8821137703506626\n",
      "train loss:0.8940707570971668\n",
      "train loss:0.8808787021662126\n",
      "train loss:0.9473270264449973\n",
      "train loss:1.0662648202621972\n",
      "train loss:0.9870675310177903\n",
      "train loss:1.115738954949902\n",
      "train loss:0.9975334770322118\n",
      "train loss:1.0491562049469794\n",
      "train loss:0.9623076841307658\n",
      "train loss:0.8917195220070724\n",
      "train loss:1.1123338113215147\n",
      "train loss:1.0615110157169854\n",
      "train loss:0.9296748035104168\n",
      "train loss:1.0090333202959236\n",
      "train loss:1.0222188855412044\n",
      "train loss:1.1411818033474603\n",
      "train loss:0.9376478300593383\n",
      "train loss:1.0198920722672506\n",
      "train loss:0.9524024288523694\n",
      "train loss:0.9214993656160445\n",
      "train loss:0.9788688373416775\n",
      "train loss:0.9112856216597794\n",
      "train loss:0.99035874965256\n",
      "train loss:0.9687546419322356\n",
      "train loss:0.9317956704247592\n",
      "train loss:0.8759215696285061\n",
      "train loss:0.9715801836603497\n",
      "train loss:0.9899275488177602\n",
      "train loss:0.9044805795164714\n",
      "train loss:1.01672604247415\n",
      "train loss:0.8679801585534191\n",
      "train loss:1.0528785039398607\n",
      "train loss:1.0332974987609151\n",
      "train loss:0.8917905948642563\n",
      "train loss:0.9525147494835826\n",
      "train loss:0.7310085493488053\n",
      "train loss:1.1680095592271613\n",
      "train loss:1.070843665684767\n",
      "train loss:0.9825945027375562\n",
      "train loss:0.9809472644652157\n",
      "train loss:0.9916089736383691\n",
      "train loss:0.8339867315255564\n",
      "train loss:1.0280776424201274\n",
      "train loss:1.1150239356966112\n",
      "train loss:1.0138440973267426\n",
      "train loss:0.8967883867226554\n",
      "train loss:1.051641399378277\n",
      "train loss:0.839333394679351\n",
      "train loss:0.812162409973133\n",
      "train loss:0.8824943311058666\n",
      "train loss:1.205854198798764\n",
      "train loss:0.9603251445720861\n",
      "train loss:0.983613139406623\n",
      "train loss:0.9877944778286232\n",
      "train loss:0.8509566603108779\n",
      "train loss:0.9073860976324599\n",
      "train loss:0.923065858581991\n",
      "train loss:1.0917009152328454\n",
      "train loss:0.6809657981822174\n",
      "train loss:0.9489015970649536\n",
      "train loss:0.9498163518579902\n",
      "train loss:0.7179208314171199\n",
      "train loss:0.9425253366484054\n",
      "train loss:0.8422340956153609\n",
      "train loss:0.7949235569925851\n",
      "train loss:0.8920435436273172\n",
      "train loss:1.0125870200822518\n",
      "train loss:0.9096603772208925\n",
      "train loss:0.7905825106026428\n",
      "train loss:1.0024545969481218\n",
      "train loss:1.0625956657916271\n",
      "train loss:0.8781794971261787\n",
      "train loss:1.0359636889044417\n",
      "train loss:0.9623095187831562\n",
      "train loss:1.08419684621856\n",
      "train loss:0.8447568130996248\n",
      "train loss:0.8820645899958026\n",
      "train loss:0.7220264799287645\n",
      "train loss:1.0764657953544823\n",
      "train loss:0.9613256873348008\n",
      "train loss:0.9510614213997696\n",
      "train loss:0.8619134571393978\n",
      "train loss:0.8360091240614215\n",
      "train loss:0.8654151648872025\n",
      "train loss:1.0912974062780085\n",
      "train loss:1.0435572755909666\n",
      "train loss:0.9596298899028254\n",
      "train loss:0.7936812087563652\n",
      "train loss:1.043155865109491\n",
      "train loss:1.0575153481414334\n",
      "train loss:0.9733244688031512\n",
      "train loss:0.9935884950174011\n",
      "train loss:0.9895581214974224\n",
      "train loss:0.8295534738093069\n",
      "train loss:0.9203724987858756\n",
      "train loss:0.9265237380542248\n",
      "train loss:0.8692156064416185\n",
      "train loss:1.0343996021216049\n",
      "train loss:1.1315222872117159\n",
      "train loss:1.07705465244643\n",
      "train loss:0.973182272637569\n",
      "train loss:0.8609259933364035\n",
      "train loss:1.002009399721623\n",
      "train loss:0.9329206101319727\n",
      "train loss:1.1917765761390244\n",
      "train loss:1.0864582185718912\n",
      "train loss:0.9973649867472766\n",
      "train loss:1.0198500919588824\n",
      "train loss:0.7547544409935018\n",
      "train loss:0.9125036334175582\n",
      "train loss:0.9955547025520154\n",
      "train loss:0.8944286735846275\n",
      "train loss:1.038821889879597\n",
      "train loss:0.9731150891365171\n",
      "train loss:0.9063145602311721\n",
      "train loss:1.0834200801419465\n",
      "train loss:0.8185629234745471\n",
      "train loss:1.0601254654489276\n",
      "train loss:0.9455699606020724\n",
      "train loss:1.0634111678306781\n",
      "train loss:0.9691003398983892\n",
      "train loss:1.0179441338179378\n",
      "train loss:0.9754987662930397\n",
      "train loss:0.9681426627530451\n",
      "train loss:0.9630953912793595\n",
      "train loss:0.9454565607306056\n",
      "train loss:1.1683939397899015\n",
      "train loss:1.010052636267669\n",
      "train loss:0.930049184210813\n",
      "train loss:0.953854901120998\n",
      "train loss:1.069089078807481\n",
      "train loss:0.9904557964163243\n",
      "train loss:1.097709352459308\n",
      "train loss:0.7658707161131905\n",
      "train loss:0.8951564911405164\n",
      "train loss:0.9320490451570086\n",
      "train loss:1.0796023346625168\n",
      "train loss:0.8921785700763444\n",
      "train loss:0.9007515309184313\n",
      "train loss:0.8425425339301925\n",
      "train loss:0.8334128163298635\n",
      "=== epoch:4, train acc:0.988, test acc:0.987 ===\n",
      "train loss:1.132621333444937\n",
      "train loss:0.9658256988225936\n",
      "train loss:1.0757959414999763\n",
      "train loss:0.8179118443896152\n",
      "train loss:0.923227743286183\n",
      "train loss:0.8930150850528833\n",
      "train loss:1.041573457452833\n",
      "train loss:1.040903468689364\n",
      "train loss:0.9054442905987501\n",
      "train loss:1.08722449699638\n",
      "train loss:0.9962530959996961\n",
      "train loss:1.0108724341798123\n",
      "train loss:0.7792251073532225\n",
      "train loss:0.9343079690523538\n",
      "train loss:0.8937895339203514\n",
      "train loss:0.8823791475806426\n",
      "train loss:0.9342066855942922\n",
      "train loss:0.7783288394385989\n",
      "train loss:1.0070200657112058\n",
      "train loss:0.7087443657580775\n",
      "train loss:0.9071880406575804\n",
      "train loss:0.8600881305383911\n",
      "train loss:1.0949837572985646\n",
      "train loss:0.8826354486857869\n",
      "train loss:0.9435715945387259\n",
      "train loss:0.9408644770922518\n",
      "train loss:0.8399398818066893\n",
      "train loss:0.8632976841577853\n",
      "train loss:0.7525851696118565\n",
      "train loss:0.8751828657737001\n",
      "train loss:1.036151422815414\n",
      "train loss:0.8475252487675584\n",
      "train loss:1.0682656349727293\n",
      "train loss:1.0516744509186802\n",
      "train loss:1.0976263761390195\n",
      "train loss:0.9913678414464777\n",
      "train loss:1.0541968344666783\n",
      "train loss:1.114466168182402\n",
      "train loss:0.8814911970797268\n",
      "train loss:0.9389598270038018\n",
      "train loss:1.0669041820390754\n",
      "train loss:0.9558724197413716\n",
      "train loss:0.9252079686392983\n",
      "train loss:0.8813122423605587\n",
      "train loss:0.893052073189862\n",
      "train loss:0.9941672314223865\n",
      "train loss:0.8956130720076031\n",
      "train loss:0.95673776498422\n",
      "train loss:0.8487951401902356\n",
      "train loss:1.0275918087819023\n",
      "train loss:1.013384531685513\n",
      "train loss:0.8783223493422265\n",
      "train loss:0.9048767787808442\n",
      "train loss:0.8875175347547452\n",
      "train loss:0.8907037524700391\n",
      "train loss:1.1872386536207846\n",
      "train loss:0.9201316944187998\n",
      "train loss:0.8839624243464206\n",
      "train loss:0.9300799662421848\n",
      "train loss:0.9205341400854217\n",
      "train loss:1.0296631692062475\n",
      "train loss:0.8576793463015789\n",
      "train loss:0.9263116374611946\n",
      "train loss:0.9435670424586009\n",
      "train loss:0.9089263825424224\n",
      "train loss:1.0042762791249245\n",
      "train loss:0.9240256715302475\n",
      "train loss:0.8755569113405683\n",
      "train loss:0.9235684311323041\n",
      "train loss:1.0563540455868874\n",
      "train loss:0.918134570641771\n",
      "train loss:0.9251415703028294\n",
      "train loss:0.9809507723287308\n",
      "train loss:1.074068968761943\n",
      "train loss:0.9345705981638522\n",
      "train loss:0.8526378667892911\n",
      "train loss:0.8835812141163472\n",
      "train loss:0.8378329152599011\n",
      "train loss:0.954787044262423\n",
      "train loss:1.0560656427382034\n",
      "train loss:0.939786226930718\n",
      "train loss:0.8941313823552215\n",
      "train loss:0.9784236463695379\n",
      "train loss:1.012878685592038\n",
      "train loss:1.048711458003686\n",
      "train loss:0.8254613277632135\n",
      "train loss:0.9287090599974451\n",
      "train loss:0.9860122956775264\n",
      "train loss:0.791982350688561\n",
      "train loss:0.8890301839720023\n",
      "train loss:0.9704650588385338\n",
      "train loss:0.9702067083074897\n",
      "train loss:0.9969592921600389\n",
      "train loss:0.8781698750711358\n",
      "train loss:0.8307505442878238\n",
      "train loss:0.9171450904842463\n",
      "train loss:1.191990688969649\n",
      "train loss:0.8615249382397294\n",
      "train loss:1.1283935864362407\n",
      "train loss:1.1181329130274384\n",
      "train loss:0.9346917875093123\n",
      "train loss:0.9732964474559134\n",
      "train loss:0.8636169436342557\n",
      "train loss:0.9484351714749877\n",
      "train loss:1.0619116574096445\n",
      "train loss:0.8712764413680546\n",
      "train loss:0.9671680981123942\n",
      "train loss:1.060978256241734\n",
      "train loss:0.7610896645765195\n",
      "train loss:0.8937146171912684\n",
      "train loss:1.0062946376446105\n",
      "train loss:0.9248176827561057\n",
      "train loss:1.0589058031667569\n",
      "train loss:0.8633974495630089\n",
      "train loss:0.8878180543966373\n",
      "train loss:0.8761962131178468\n",
      "train loss:1.0251309531847448\n",
      "train loss:0.9378556920183391\n",
      "train loss:1.1705348591310476\n",
      "train loss:0.8901772981683927\n",
      "train loss:1.0253284954032988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.9847156511465549\n",
      "train loss:0.8299777092148607\n",
      "train loss:0.8960538014998989\n",
      "train loss:0.8908773077671002\n",
      "train loss:0.9037276063310091\n",
      "train loss:0.8401061178498181\n",
      "train loss:0.9598768858676513\n",
      "train loss:1.0542250181938728\n",
      "train loss:1.0416454800506383\n",
      "train loss:0.9254765718779556\n",
      "train loss:1.1368473952568174\n",
      "train loss:0.7687120400175131\n",
      "train loss:0.8407099526245694\n",
      "train loss:0.9084037435478597\n",
      "train loss:0.7950489759142307\n",
      "train loss:0.9021799501253969\n",
      "train loss:0.9533472986526459\n",
      "train loss:1.142815909049694\n",
      "train loss:0.8827718293844861\n",
      "train loss:0.9446976342170484\n",
      "train loss:0.9738220432224418\n",
      "train loss:0.9375320973001371\n",
      "train loss:0.9002517602852099\n",
      "train loss:0.9767858499339935\n",
      "train loss:1.008459841755605\n",
      "train loss:0.9161251964203587\n",
      "train loss:0.9016937388709162\n",
      "train loss:0.9692425544162545\n",
      "train loss:0.7936289580492926\n",
      "train loss:0.8127813519651178\n",
      "train loss:0.9452645762602536\n",
      "train loss:1.0425659803376868\n",
      "train loss:1.0325571297089544\n",
      "train loss:0.949925029811583\n",
      "train loss:1.0867764490956988\n",
      "train loss:0.9235173874481639\n",
      "train loss:0.8727178520855552\n",
      "train loss:1.0184490525396568\n",
      "train loss:0.9012447282886821\n",
      "train loss:0.881906053470018\n",
      "train loss:0.8299670027291723\n",
      "train loss:1.0773035765368026\n",
      "train loss:1.021379345592986\n",
      "train loss:1.0589177577921738\n",
      "train loss:1.0307793890504227\n",
      "train loss:0.8199191492572132\n",
      "train loss:0.8182031609204045\n",
      "train loss:0.7924363642973355\n",
      "train loss:1.0252180085541205\n",
      "train loss:1.0214582712609523\n",
      "train loss:0.9808916402323846\n",
      "train loss:0.8647726996355906\n",
      "train loss:0.9130350138907539\n",
      "train loss:1.0940108363187044\n",
      "train loss:0.9522552879438554\n",
      "train loss:0.8401038200788244\n",
      "train loss:0.9645372064447415\n",
      "train loss:0.8677832785510846\n",
      "train loss:0.8874498697044825\n",
      "train loss:0.7822964798475973\n",
      "train loss:0.8418976346517631\n",
      "train loss:0.9496444002554544\n",
      "train loss:0.9670055836450793\n",
      "train loss:0.8135741362320453\n",
      "train loss:0.932757737456687\n",
      "train loss:1.0070188121389976\n",
      "train loss:1.0116494489048973\n",
      "train loss:0.8997169894526696\n",
      "train loss:1.021429692582342\n",
      "train loss:0.9757500443039905\n",
      "train loss:0.9160809455195319\n",
      "train loss:1.125526170477142\n",
      "train loss:1.0317209046860352\n",
      "train loss:0.9536975791069024\n",
      "train loss:1.0266752466298419\n",
      "train loss:0.8747401321380933\n",
      "train loss:0.9516196004818819\n",
      "train loss:1.029109967449719\n",
      "train loss:0.9910550012545609\n",
      "train loss:0.9256868930674578\n",
      "train loss:1.0005406271236914\n",
      "train loss:1.0112340491948324\n",
      "train loss:0.7958708108511461\n",
      "train loss:0.9175147654554262\n",
      "train loss:0.8735414571561462\n",
      "train loss:0.8528364320772045\n",
      "train loss:0.8556789665010984\n",
      "train loss:1.000896135737545\n",
      "train loss:0.8449875239893936\n",
      "train loss:0.8252701313276176\n",
      "train loss:1.0596321335304912\n",
      "train loss:0.8687335916577981\n",
      "train loss:1.0240193405507727\n",
      "train loss:1.0345761025370432\n",
      "train loss:0.8725071562389758\n",
      "train loss:0.8508830376181055\n",
      "train loss:0.9823574408913739\n",
      "train loss:0.8436411483930552\n",
      "train loss:1.0136165860779076\n",
      "train loss:0.7404303421370468\n",
      "train loss:0.9926921656505077\n",
      "train loss:0.9863833326017637\n",
      "train loss:0.7737432190663095\n",
      "train loss:1.0735731482468196\n",
      "train loss:0.7470779017310392\n",
      "train loss:0.9203010563187338\n",
      "train loss:0.9790421872239429\n",
      "train loss:0.7913700054564594\n",
      "train loss:1.0148874633581138\n",
      "train loss:0.9777463160625905\n",
      "train loss:0.8034112818876329\n",
      "train loss:1.180229773539831\n",
      "train loss:0.8497863002715812\n",
      "train loss:1.0154132253176733\n",
      "train loss:1.060721167222242\n",
      "train loss:1.0415914922080174\n",
      "train loss:0.8954766080148915\n",
      "train loss:0.9824758743058242\n",
      "train loss:0.8590727507805603\n",
      "train loss:0.9574343382027871\n",
      "train loss:0.8777596700236517\n",
      "train loss:1.010767061400876\n",
      "train loss:1.0450307811651915\n",
      "train loss:0.9169252812943779\n",
      "train loss:1.0265850687365132\n",
      "train loss:0.9970161018330138\n",
      "train loss:1.0470631917633377\n",
      "train loss:1.0025380312587289\n",
      "train loss:1.0073230863852674\n",
      "train loss:0.9825941282767491\n",
      "train loss:0.9290364074100148\n",
      "train loss:0.9168927509372335\n",
      "train loss:0.8778697393144006\n",
      "train loss:0.9209446470274399\n",
      "train loss:0.9212915136713307\n",
      "train loss:0.9749149465120377\n",
      "train loss:1.0660794748752134\n",
      "train loss:0.9647475590086881\n",
      "train loss:1.0852552215748383\n",
      "train loss:0.8783023646930053\n",
      "train loss:0.8430820986148668\n",
      "train loss:0.916495673838541\n",
      "train loss:0.9264926141421559\n",
      "train loss:0.9468290126570804\n",
      "train loss:0.8769311336958675\n",
      "train loss:1.1242888960469108\n",
      "train loss:0.920806107826774\n",
      "train loss:0.8281529236740574\n",
      "train loss:1.1027615381052707\n",
      "train loss:0.86590688619863\n",
      "train loss:0.8914892746695032\n",
      "train loss:0.9752939111463707\n",
      "train loss:1.021626680136018\n",
      "train loss:0.9121077272928901\n",
      "train loss:0.7921332262966227\n",
      "train loss:0.921305495161533\n",
      "train loss:0.9240693056735949\n",
      "train loss:1.045874773254002\n",
      "train loss:1.0758907912645583\n",
      "train loss:0.7461916969223203\n",
      "train loss:1.0070885255908708\n",
      "train loss:0.8696324992090058\n",
      "train loss:0.9765926980290598\n",
      "train loss:1.1323359569675502\n",
      "train loss:0.9382037990636831\n",
      "train loss:0.8397241808688911\n",
      "train loss:0.8963635291061637\n",
      "train loss:0.975806931076825\n",
      "train loss:0.913459709271745\n",
      "train loss:0.8573638522690206\n",
      "train loss:0.8846654991899505\n",
      "train loss:1.0010113330719508\n",
      "train loss:1.0997550034352568\n",
      "train loss:0.7879806909055165\n",
      "train loss:0.9736057497000792\n",
      "train loss:0.9743131492330943\n",
      "train loss:1.030559004841935\n",
      "train loss:0.9968966589146211\n",
      "train loss:0.9901684007483424\n",
      "train loss:1.005459266462655\n",
      "train loss:0.9655018434607255\n",
      "train loss:0.8655796552925717\n",
      "train loss:1.0389112941618592\n",
      "train loss:0.8624755828865658\n",
      "train loss:0.8698055331754239\n",
      "train loss:1.036318886438916\n",
      "train loss:1.000093895806864\n",
      "train loss:1.0328319006568034\n",
      "train loss:0.881296241918441\n",
      "train loss:1.172383716658967\n",
      "train loss:1.0438901759451078\n",
      "train loss:0.9284546520947125\n",
      "train loss:0.895277272478495\n",
      "train loss:0.7544529769559598\n",
      "train loss:0.9789057817499314\n",
      "train loss:1.0882622896705387\n",
      "train loss:0.9519142063111193\n",
      "train loss:0.8342228625337651\n",
      "train loss:1.0277466736505838\n",
      "train loss:0.8489278632383898\n",
      "train loss:0.8916054950086492\n",
      "train loss:0.8129790213716903\n",
      "train loss:0.8794165523560961\n",
      "train loss:0.8667833322068746\n",
      "train loss:0.8358306658277993\n",
      "train loss:0.927022984540107\n",
      "train loss:0.8546461545560412\n",
      "train loss:0.9310130696189169\n",
      "train loss:1.0060361558216153\n",
      "train loss:0.975329846522733\n",
      "train loss:0.8726882904400758\n",
      "train loss:0.7489948839405628\n",
      "train loss:0.8946139791621104\n",
      "train loss:1.0341359377983725\n",
      "train loss:0.805214959632475\n",
      "train loss:0.8967988662757861\n",
      "train loss:1.0506490417856027\n",
      "train loss:1.0180430330912074\n",
      "train loss:0.6801956618112789\n",
      "train loss:0.9998371321582106\n",
      "train loss:0.9941348440117097\n",
      "train loss:1.1744541426546804\n",
      "train loss:0.918716558602733\n",
      "train loss:1.0323655450446523\n",
      "train loss:0.8291189608722571\n",
      "train loss:0.851267274031918\n",
      "train loss:0.88959950074526\n",
      "train loss:1.046141436685162\n",
      "train loss:0.7076702448244677\n",
      "train loss:0.927904538489675\n",
      "train loss:1.0035266172539112\n",
      "train loss:0.9146891707619004\n",
      "train loss:1.099171067414818\n",
      "train loss:0.8187241438538178\n",
      "train loss:1.0154288791316153\n",
      "train loss:1.0765099143050298\n",
      "train loss:1.0343022011748213\n",
      "train loss:0.9017893369203442\n",
      "train loss:0.9570558706739686\n",
      "train loss:1.0234819424052573\n",
      "train loss:1.039505423847435\n",
      "train loss:0.8872424636842992\n",
      "train loss:0.8665518978570327\n",
      "train loss:0.8587127069735648\n",
      "train loss:1.1701753628651692\n",
      "train loss:0.9922740974543025\n",
      "train loss:0.8998320155685756\n",
      "train loss:1.1014996441904374\n",
      "train loss:0.8976936047844917\n",
      "train loss:0.9996034681561947\n",
      "train loss:0.9638347330787751\n",
      "train loss:1.004310809850361\n",
      "train loss:0.9300625303172128\n",
      "train loss:0.8967246896164078\n",
      "train loss:0.9726240841700143\n",
      "train loss:0.9501979380319777\n",
      "train loss:0.9538660670939714\n",
      "train loss:0.9194019431201736\n",
      "train loss:0.9191777574919543\n",
      "train loss:0.9522617456568214\n",
      "train loss:0.8336267720518125\n",
      "train loss:1.0685258700342577\n",
      "train loss:1.026475053102105\n",
      "train loss:0.8177310895387382\n",
      "train loss:0.8853181556419539\n",
      "train loss:0.8726309606542618\n",
      "train loss:0.9160207373455844\n",
      "train loss:0.9158533785091472\n",
      "train loss:0.9796756452753723\n",
      "train loss:1.0141636319515621\n",
      "train loss:1.000682744833824\n",
      "train loss:0.9787063685871433\n",
      "train loss:1.0751641759970996\n",
      "train loss:0.9197103023230193\n",
      "train loss:0.8350283354995441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.8887258975567377\n",
      "train loss:0.8455237356021325\n",
      "train loss:0.8997092193493736\n",
      "train loss:1.0387222579330428\n",
      "train loss:1.0228205197402125\n",
      "train loss:0.9250367227749676\n",
      "train loss:0.8457890829667193\n",
      "train loss:0.9293651834751486\n",
      "train loss:1.0040625815000153\n",
      "train loss:0.9310402727941329\n",
      "train loss:1.079407810084847\n",
      "train loss:0.9106439544252705\n",
      "train loss:0.8711222206239997\n",
      "train loss:1.0073921149356189\n",
      "train loss:0.9515726669373568\n",
      "train loss:0.6242940154535296\n",
      "train loss:0.8566054618063749\n",
      "train loss:0.8511660222334718\n",
      "train loss:0.8604563576592108\n",
      "train loss:1.012027284268797\n",
      "train loss:0.9445386631601067\n",
      "train loss:0.9568743263935678\n",
      "train loss:0.9620711638684729\n",
      "train loss:1.0886041921585723\n",
      "train loss:0.8762737556038374\n",
      "train loss:1.0583412673236334\n",
      "train loss:0.905137413536177\n",
      "train loss:0.8277090484014572\n",
      "train loss:0.994750555423145\n",
      "train loss:0.9624655417201189\n",
      "train loss:1.003582853418985\n",
      "train loss:1.001201985342534\n",
      "train loss:0.9406293489637393\n",
      "train loss:1.0462935049854036\n",
      "train loss:1.0751636508478857\n",
      "train loss:0.9234739139615497\n",
      "train loss:0.7217774154669679\n",
      "train loss:0.9379688406748565\n",
      "train loss:0.8582298740376315\n",
      "train loss:0.9444782801931353\n",
      "train loss:1.13488549534607\n",
      "train loss:0.9415348985857114\n",
      "train loss:0.8912549961493869\n",
      "train loss:0.9436652290068804\n",
      "train loss:1.0756643077262975\n",
      "train loss:0.8599648364166721\n",
      "train loss:0.8519930362016384\n",
      "train loss:0.8322208616651825\n",
      "train loss:0.9019863377855849\n",
      "train loss:0.814860198411068\n",
      "train loss:0.9800583995213789\n",
      "train loss:0.9102409560760384\n",
      "train loss:0.9821969346019567\n",
      "train loss:1.0120566354579126\n",
      "train loss:1.079174250023217\n",
      "train loss:0.8412651209376562\n",
      "train loss:0.8820829538030772\n",
      "train loss:1.0300932098807214\n",
      "train loss:0.9621366765059062\n",
      "train loss:1.0922866057990825\n",
      "train loss:1.0283420537303452\n",
      "train loss:0.9008330250484733\n",
      "train loss:0.896690915981035\n",
      "train loss:0.995170078750578\n",
      "train loss:0.9760459641349465\n",
      "train loss:0.9373531297140582\n",
      "train loss:0.9623819115072876\n",
      "train loss:0.9135235267915958\n",
      "train loss:0.8623531700001444\n",
      "train loss:0.8470071549459394\n",
      "train loss:1.0182333842320057\n",
      "train loss:1.0351291068736324\n",
      "train loss:0.9153680862207652\n",
      "train loss:0.9364494240211032\n",
      "train loss:0.9289692442686875\n",
      "train loss:1.1848653823625563\n",
      "train loss:0.9598938619635854\n",
      "train loss:0.853856248099131\n",
      "train loss:0.9610151333736172\n",
      "train loss:0.9119696621150094\n",
      "train loss:1.0353134096562249\n",
      "train loss:0.8586195276765173\n",
      "train loss:0.8606740763806013\n",
      "train loss:1.1088742604886992\n",
      "train loss:0.8756556908678087\n",
      "train loss:0.904488650463202\n",
      "train loss:1.0069348526432937\n",
      "train loss:0.8202081097263058\n",
      "train loss:0.8389476483251325\n",
      "train loss:0.8284737203007126\n",
      "train loss:0.905463678299753\n",
      "train loss:0.9395732811334603\n",
      "train loss:1.058091661534977\n",
      "train loss:0.9061720883534715\n",
      "train loss:0.9441358761489235\n",
      "train loss:1.0375031777480392\n",
      "train loss:0.9308789581096626\n",
      "train loss:1.0179561700371902\n",
      "train loss:0.9318607290146363\n",
      "train loss:0.933855091595079\n",
      "train loss:0.8668518683034333\n",
      "train loss:1.0952316405378277\n",
      "train loss:0.8853949075211541\n",
      "train loss:0.8951031320952868\n",
      "train loss:1.1070322723928003\n",
      "train loss:0.9441183385911686\n",
      "train loss:0.836889477286857\n",
      "train loss:1.0713671725708291\n",
      "train loss:0.9656555939915115\n",
      "train loss:0.7544586189679721\n",
      "train loss:0.92355599108608\n",
      "train loss:0.9912770420225577\n",
      "train loss:0.9306888935639784\n",
      "train loss:0.8940849140294513\n",
      "train loss:0.9613330032973602\n",
      "train loss:0.9195505149655868\n",
      "train loss:0.8874312318922053\n",
      "train loss:0.9423468216717812\n",
      "train loss:0.9810398173326524\n",
      "train loss:0.9010701784410096\n",
      "train loss:1.089840627927399\n",
      "train loss:0.8208224180958956\n",
      "train loss:0.9179413117434487\n",
      "train loss:0.89599516693592\n",
      "train loss:0.7887205460341998\n",
      "train loss:0.9492428272429807\n",
      "train loss:1.017198650660106\n",
      "train loss:0.9211612178309785\n",
      "train loss:0.8722770046316871\n",
      "train loss:0.8649886867675916\n",
      "train loss:0.8554609896586974\n",
      "train loss:1.1490699378059073\n",
      "train loss:0.9882267419541297\n",
      "train loss:0.7767867793151262\n",
      "train loss:0.8441461517149925\n",
      "train loss:0.842585075229978\n",
      "train loss:0.9084410400046399\n",
      "train loss:1.0710440515098525\n",
      "train loss:0.8325823344202671\n",
      "train loss:1.1267928295845282\n",
      "train loss:0.8844257131745364\n",
      "train loss:0.8802453562849548\n",
      "train loss:0.9045727388410107\n",
      "train loss:0.9557345910667113\n",
      "train loss:0.999541039209187\n",
      "train loss:0.7399378749266405\n",
      "train loss:1.1076392904995367\n",
      "train loss:0.8627522355971388\n",
      "train loss:0.8390774169239417\n",
      "train loss:0.9387582659286923\n",
      "train loss:1.0350600795543325\n",
      "train loss:0.90194871845696\n",
      "train loss:0.8888714073003358\n",
      "train loss:0.9592833214114544\n",
      "train loss:1.0084850897050521\n",
      "train loss:0.8791737556220879\n",
      "train loss:0.7842996693557925\n",
      "train loss:0.9187857706819241\n",
      "train loss:1.0337511601124592\n",
      "train loss:0.9351038178618275\n",
      "train loss:0.8975626036103437\n",
      "train loss:0.7025878614995489\n",
      "train loss:1.0005912360968119\n",
      "train loss:0.7312189797952552\n",
      "train loss:0.9289948884219749\n",
      "train loss:0.9109186760614787\n",
      "train loss:0.9004215691465121\n",
      "train loss:0.8928345848231066\n",
      "train loss:0.7844193433764641\n",
      "train loss:1.0521537423960572\n",
      "train loss:0.8974525968556112\n",
      "train loss:0.8310504919967263\n",
      "train loss:0.7766178952388246\n",
      "train loss:0.8360672151769767\n",
      "train loss:0.9659644992777635\n",
      "train loss:0.8522101718210306\n",
      "train loss:0.8990012504175993\n",
      "train loss:0.9151175775888567\n",
      "train loss:0.8577511493399811\n",
      "train loss:0.9321155950525356\n",
      "train loss:0.9399541512712295\n",
      "train loss:1.098101307331762\n",
      "train loss:1.072420098376416\n",
      "train loss:0.9126639685533772\n",
      "train loss:0.9608346487174214\n",
      "train loss:1.1113540376057673\n",
      "train loss:0.8472899455367744\n",
      "train loss:0.8157578416738134\n",
      "train loss:0.8861415428028774\n",
      "train loss:0.9305103455664039\n",
      "train loss:0.8719905410524773\n",
      "train loss:0.8499689712910999\n",
      "train loss:0.8670602765964925\n",
      "train loss:1.2036307262247155\n",
      "train loss:0.8625820828831802\n",
      "train loss:0.9397399882743988\n",
      "train loss:0.9847062795463691\n",
      "train loss:1.0513701978950702\n",
      "train loss:0.9422860503565478\n",
      "train loss:1.0265520162761093\n",
      "train loss:0.8697118561399416\n",
      "train loss:0.8292920150114118\n",
      "train loss:0.95415382375278\n",
      "train loss:1.109924429332116\n",
      "=== epoch:5, train acc:0.992, test acc:0.985 ===\n",
      "train loss:0.9970437066321926\n",
      "train loss:0.8318081665446527\n",
      "train loss:0.9394992909355996\n",
      "train loss:0.7430973672169208\n",
      "train loss:0.7912839365915603\n",
      "train loss:0.8784646412389714\n",
      "train loss:1.0366164039135202\n",
      "train loss:1.0595828098919935\n",
      "train loss:0.9470874488621251\n",
      "train loss:0.8659248200874036\n",
      "train loss:0.854240207887154\n",
      "train loss:1.1644958691506204\n",
      "train loss:0.9284168381085841\n",
      "train loss:0.8895555589116895\n",
      "train loss:1.0411747291784286\n",
      "train loss:1.0325654335435064\n",
      "train loss:0.8543414521159357\n",
      "train loss:0.9812147275887072\n",
      "train loss:0.965004827329892\n",
      "train loss:1.0889824934363062\n",
      "train loss:0.7903536920470358\n",
      "train loss:0.9014534846921977\n",
      "train loss:0.9405046423314779\n",
      "train loss:0.8991455051939063\n",
      "train loss:0.9366984178947716\n",
      "train loss:0.7674627555503721\n",
      "train loss:0.9295761939486435\n",
      "train loss:0.8748925195387026\n",
      "train loss:0.9140239443591958\n",
      "train loss:1.0117670874284974\n",
      "train loss:1.072478932742086\n",
      "train loss:0.8460273301858727\n",
      "train loss:0.9000345480441703\n",
      "train loss:0.8575976232498231\n",
      "train loss:0.9570006535940344\n",
      "train loss:0.8875166393554577\n",
      "train loss:0.9056711871226217\n",
      "train loss:0.9873477305307852\n",
      "train loss:0.9813224643403263\n",
      "train loss:0.9741293865784921\n",
      "train loss:1.042954346715537\n",
      "train loss:1.0396210834735513\n",
      "train loss:1.0673356519630623\n",
      "train loss:0.6311788289350894\n",
      "train loss:0.893355080898071\n",
      "train loss:0.8911827054428564\n",
      "train loss:0.9222397881031362\n",
      "train loss:0.9148318192135322\n",
      "train loss:0.9330027229921218\n",
      "train loss:0.9568645635302512\n",
      "train loss:0.6620613559542019\n",
      "train loss:0.9208462364953242\n",
      "train loss:0.9271364660359025\n",
      "train loss:1.0174825465770068\n",
      "train loss:0.7621605628003284\n",
      "train loss:0.8810895692205236\n",
      "train loss:0.9111223375737951\n",
      "train loss:0.925064458226539\n",
      "train loss:0.8136469178264414\n",
      "train loss:0.9252646641758028\n",
      "train loss:0.9455361635797427\n",
      "train loss:0.8791076071733318\n",
      "train loss:0.7985415691692355\n",
      "train loss:0.8476084620569625\n",
      "train loss:0.9078361143433953\n",
      "train loss:0.8455347088323784\n",
      "train loss:1.0135190324245764\n",
      "train loss:0.9080297734089232\n",
      "train loss:0.8130421354755271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.8540232813091447\n",
      "train loss:0.7929323867561918\n",
      "train loss:0.846318104567225\n",
      "train loss:0.9830817676403508\n",
      "train loss:0.918307573515952\n",
      "train loss:0.7497467296513747\n",
      "train loss:1.004022073238482\n",
      "train loss:0.9753906718712996\n",
      "train loss:0.8058272985028175\n",
      "train loss:0.9179657322835562\n",
      "train loss:0.981114977494905\n",
      "train loss:0.9044289800874108\n",
      "train loss:0.9237168374569009\n",
      "train loss:1.0404882604860821\n",
      "train loss:0.9072018266080086\n",
      "train loss:0.7981109018166065\n",
      "train loss:0.7344957479347634\n",
      "train loss:0.9762554432210852\n",
      "train loss:0.9771877883132697\n",
      "train loss:0.816925800891109\n",
      "train loss:1.037913533100018\n",
      "train loss:0.8769146712171775\n",
      "train loss:0.8833689444365918\n",
      "train loss:0.8633698999760422\n",
      "train loss:0.841179259699279\n",
      "train loss:0.9294530018554502\n",
      "train loss:0.8752208258748082\n",
      "train loss:1.0127630711947084\n",
      "train loss:0.9332495703125082\n",
      "train loss:1.0253296776187575\n",
      "train loss:1.0451161450015984\n",
      "train loss:0.9856597777132459\n",
      "train loss:0.9372762095067421\n",
      "train loss:0.9382811047125195\n",
      "train loss:0.9345966136526461\n",
      "train loss:0.9797183374722045\n",
      "train loss:0.9970555696364285\n",
      "train loss:0.9090054486792724\n",
      "train loss:0.9679485118094192\n",
      "train loss:0.9418085605048632\n",
      "train loss:0.9035361945376909\n",
      "train loss:0.9912034396188527\n",
      "train loss:0.7779051779944794\n",
      "train loss:0.8217345990888595\n",
      "train loss:1.0467769792720096\n",
      "train loss:1.0232529795880416\n",
      "train loss:0.92588419923308\n",
      "train loss:0.8416766966733301\n",
      "train loss:1.0986186574494519\n",
      "train loss:1.0797500743205606\n",
      "train loss:0.9510588590734577\n",
      "train loss:0.9089643687576485\n",
      "train loss:0.9867646961066786\n",
      "train loss:0.8477565169929174\n",
      "train loss:0.9695471757334161\n",
      "train loss:0.8753781673815304\n",
      "train loss:0.9245656947520681\n",
      "train loss:0.9220297346563332\n",
      "train loss:0.907114415252452\n",
      "train loss:0.8504228748650233\n",
      "train loss:0.8526970199794683\n",
      "train loss:0.7794282065662945\n",
      "train loss:0.7502647285750911\n",
      "train loss:0.9497995017236649\n",
      "train loss:0.8462400101707364\n",
      "train loss:0.8572119697811291\n",
      "train loss:0.9948024781577375\n",
      "train loss:0.8981798991026467\n",
      "train loss:0.9903893719974274\n",
      "train loss:0.8573505824713733\n",
      "train loss:0.8243391189516555\n",
      "train loss:0.8587488076492891\n",
      "train loss:0.9522511004615954\n",
      "train loss:1.0065801905064935\n",
      "train loss:0.9640522382011709\n",
      "train loss:1.1213725483275834\n",
      "train loss:0.8803611120481815\n",
      "train loss:1.0871021245230659\n",
      "train loss:0.8830663829204224\n",
      "train loss:0.7766717769024745\n",
      "train loss:1.020207516459747\n",
      "train loss:1.0860595968653517\n",
      "train loss:0.7986837642053196\n",
      "train loss:0.8898286066302639\n",
      "train loss:0.7935267480601834\n",
      "train loss:0.8126042899853343\n",
      "train loss:0.8012555772273068\n",
      "train loss:0.9602092871347635\n",
      "train loss:0.9040623696507428\n",
      "train loss:0.8875826191236034\n",
      "train loss:0.9062415044943277\n",
      "train loss:0.8895266544482083\n",
      "train loss:0.9124656747428384\n",
      "train loss:0.8452500058121811\n",
      "train loss:0.8700865943579946\n",
      "train loss:0.8503249798246415\n",
      "train loss:0.9945140842386095\n",
      "train loss:0.9621760783767408\n",
      "train loss:0.9152828391988918\n",
      "train loss:0.8595051836812104\n",
      "train loss:0.950367676692723\n",
      "train loss:0.906028040124717\n",
      "train loss:1.1550075302187839\n",
      "train loss:1.0024225171118892\n",
      "train loss:0.9660556041601024\n",
      "train loss:1.0554346077164398\n",
      "train loss:0.8273346420216546\n",
      "train loss:1.0733218170271441\n",
      "train loss:0.7944596722856682\n",
      "train loss:1.023921502957225\n",
      "train loss:0.8461845905061609\n",
      "train loss:1.0533189865878847\n",
      "train loss:0.8903262874027523\n",
      "train loss:1.0045456181541572\n",
      "train loss:1.025314576746563\n",
      "train loss:0.8694432358100258\n",
      "train loss:0.8270688690408354\n",
      "train loss:0.7683220302398035\n",
      "train loss:0.9259604608827918\n",
      "train loss:0.9674973695926963\n",
      "train loss:0.8358454192688756\n",
      "train loss:0.7130386256948795\n",
      "train loss:0.9145109544826622\n",
      "train loss:1.0020185715514025\n",
      "train loss:0.8890353057856266\n",
      "train loss:0.9617799646452585\n",
      "train loss:0.8218846032307091\n",
      "train loss:0.9650789582307678\n",
      "train loss:1.028745059161153\n",
      "train loss:1.0157875452643632\n",
      "train loss:1.0525213383649639\n",
      "train loss:1.008939251038815\n",
      "train loss:0.8735210561253491\n",
      "train loss:0.903574679654485\n",
      "train loss:0.8316499781479838\n",
      "train loss:0.9916408879011236\n",
      "train loss:0.9402886301660139\n",
      "train loss:0.9001431571801075\n",
      "train loss:0.7034616525694668\n",
      "train loss:0.7291399305762369\n",
      "train loss:0.8800150436527916\n",
      "train loss:0.8022143976926881\n",
      "train loss:0.9893782137851435\n",
      "train loss:0.9883549230435732\n",
      "train loss:1.226675632162619\n",
      "train loss:0.9405697944254291\n",
      "train loss:1.0393569601559658\n",
      "train loss:1.0009119359738081\n",
      "train loss:1.0091220012315334\n",
      "train loss:1.0482288046013941\n",
      "train loss:0.9155264296864456\n",
      "train loss:0.8377953576843553\n",
      "train loss:0.8719368347032207\n",
      "train loss:0.9828477059509327\n",
      "train loss:0.8486201320731434\n",
      "train loss:0.8774573998714444\n",
      "train loss:0.850629790524285\n",
      "train loss:0.9516770482541539\n",
      "train loss:0.7899836649867343\n",
      "train loss:1.1291361679941776\n",
      "train loss:0.8659636585974196\n",
      "train loss:1.0510665692996453\n",
      "train loss:0.7998328369808764\n",
      "train loss:0.957626613880485\n",
      "train loss:0.9529297427487279\n",
      "train loss:0.9769269964277291\n",
      "train loss:0.8979666492198981\n",
      "train loss:1.0445317194256158\n",
      "train loss:0.92889709946973\n",
      "train loss:0.9527215967059642\n",
      "train loss:1.0158594132953598\n",
      "train loss:0.9725520152833299\n",
      "train loss:0.9430856669120581\n",
      "train loss:0.9309226833383363\n",
      "train loss:0.9001985981683363\n",
      "train loss:0.9901205680542827\n",
      "train loss:1.0786456763872072\n",
      "train loss:0.8253846360444267\n",
      "train loss:0.8018916640403565\n",
      "train loss:0.881197563981972\n",
      "train loss:0.8377827794151114\n",
      "train loss:0.7665929153294705\n",
      "train loss:0.7904004651744541\n",
      "train loss:0.8449283294182675\n",
      "train loss:0.911076534732807\n",
      "train loss:1.005128241065433\n",
      "train loss:0.893234863111004\n",
      "train loss:0.9045659204571751\n",
      "train loss:1.0378045639194815\n",
      "train loss:1.0624089544989699\n",
      "train loss:0.8888003257614844\n",
      "train loss:0.9564552212323723\n",
      "train loss:0.7233920521881566\n",
      "train loss:0.7504150713855782\n",
      "train loss:0.8741151595231692\n",
      "train loss:1.0378871153202356\n",
      "train loss:0.7988285379877563\n",
      "train loss:0.742328776955469\n",
      "train loss:0.8777533508156965\n",
      "train loss:0.924018445047539\n",
      "train loss:0.8606100447418723\n",
      "train loss:0.8355915432810133\n",
      "train loss:0.8134566433844731\n",
      "train loss:0.9085941800941848\n",
      "train loss:0.9119849033386701\n",
      "train loss:0.9816993193679882\n",
      "train loss:0.9931398612824391\n",
      "train loss:0.8098775960163028\n",
      "train loss:0.9185358722833726\n",
      "train loss:0.9283500497562401\n",
      "train loss:0.9464704080639049\n",
      "train loss:1.0047853130497881\n",
      "train loss:0.8671042638166844\n",
      "train loss:0.818768010271038\n",
      "train loss:0.8162898243158344\n",
      "train loss:0.9029730116133037\n",
      "train loss:1.050663152249422\n",
      "train loss:0.8007874153989938\n",
      "train loss:1.0360607229784926\n",
      "train loss:0.9670957953611893\n",
      "train loss:1.0170516690645377\n",
      "train loss:0.8674040053336075\n",
      "train loss:0.888106877591595\n",
      "train loss:0.9846842810082336\n",
      "train loss:0.8091267908175968\n",
      "train loss:0.8568380714575461\n",
      "train loss:1.14246262078088\n",
      "train loss:0.8964958329677267\n",
      "train loss:0.8213150422984686\n",
      "train loss:0.873154206000678\n",
      "train loss:0.8737106307693702\n",
      "train loss:0.9765911919276745\n",
      "train loss:0.851059316218851\n",
      "train loss:0.7427312556179664\n",
      "train loss:0.8835200284093863\n",
      "train loss:1.0850701685135966\n",
      "train loss:0.8643653203363095\n",
      "train loss:0.8012449214594578\n",
      "train loss:0.9114775906188052\n",
      "train loss:0.8022407562097779\n",
      "train loss:0.9749128293634048\n",
      "train loss:0.8256264868277721\n",
      "train loss:1.0022103098574626\n",
      "train loss:1.0115529296450316\n",
      "train loss:0.8820309889017756\n",
      "train loss:0.90703506334322\n",
      "train loss:0.9045275866976915\n",
      "train loss:0.9989496304485602\n",
      "train loss:0.7889498143821622\n",
      "train loss:0.8919920637721629\n",
      "train loss:0.8450967564498818\n",
      "train loss:0.9980287948990693\n",
      "train loss:0.9023913978227328\n",
      "train loss:1.263454941664654\n",
      "train loss:0.8243920825337502\n",
      "train loss:1.0001261165755904\n",
      "train loss:0.9057026369624208\n",
      "train loss:0.9805541761131344\n",
      "train loss:0.8135888108172196\n",
      "train loss:0.8843780266279612\n",
      "train loss:0.7689172571961612\n",
      "train loss:0.8466166649874336\n",
      "train loss:1.003501949898062\n",
      "train loss:0.7881567134924309\n",
      "train loss:0.9238004955171167\n",
      "train loss:1.0653829936034755\n",
      "train loss:1.0218265007626557\n",
      "train loss:0.9343268225525256\n",
      "train loss:0.8673584971075836\n",
      "train loss:0.9283637919400958\n",
      "train loss:0.7552023128419926\n",
      "train loss:1.0237515769335754\n",
      "train loss:0.8920906117608304\n",
      "train loss:0.8890948914458204\n",
      "train loss:0.9135988336960209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.8251680750422736\n",
      "train loss:1.0645737925572027\n",
      "train loss:0.8882664396130703\n",
      "train loss:0.9243360387060116\n",
      "train loss:0.8018896970903817\n",
      "train loss:0.8013781666027895\n",
      "train loss:0.7508620631591927\n",
      "train loss:0.9202467468891222\n",
      "train loss:0.9870586688819151\n",
      "train loss:0.9413876558999117\n",
      "train loss:1.1157347437028984\n",
      "train loss:0.9470491840969995\n",
      "train loss:0.8759048640176408\n",
      "train loss:0.9617154678813492\n",
      "train loss:0.9596583152879284\n",
      "train loss:1.1212160558396853\n",
      "train loss:0.9992347395120595\n",
      "train loss:1.0679824081922586\n",
      "train loss:0.7981179676637624\n",
      "train loss:0.8811802385626758\n",
      "train loss:0.9470418138828908\n",
      "train loss:0.7812462310825816\n",
      "train loss:0.7948919588118166\n",
      "train loss:0.937459669012159\n",
      "train loss:0.8744476054136071\n",
      "train loss:1.017814469325949\n",
      "train loss:0.7593309871674405\n",
      "train loss:0.9888653504307067\n",
      "train loss:0.7618785954897309\n",
      "train loss:0.8255094205125684\n",
      "train loss:1.0198491930597922\n",
      "train loss:0.8621830919623931\n",
      "train loss:0.9151297158308286\n",
      "train loss:0.8865327094895525\n",
      "train loss:0.8649450077254742\n",
      "train loss:0.9126246397141596\n",
      "train loss:0.8501575370088805\n",
      "train loss:0.9051290476532112\n",
      "train loss:0.9799099528982438\n",
      "train loss:0.9937242998219813\n",
      "train loss:0.8293732025664269\n",
      "train loss:0.9341626713459781\n",
      "train loss:0.7581085050125453\n",
      "train loss:0.9103053282381667\n",
      "train loss:0.8708212920826233\n",
      "train loss:0.9958089723066996\n",
      "train loss:1.0325261858203807\n",
      "train loss:0.7956290961454711\n",
      "train loss:0.9481698363404195\n",
      "train loss:0.8084842027567498\n",
      "train loss:0.9480142024489274\n",
      "train loss:0.884171197687606\n",
      "train loss:0.8866628532070557\n",
      "train loss:0.8533026575065662\n",
      "train loss:0.9892816708985553\n",
      "train loss:0.935006400372919\n",
      "train loss:0.8324854112717672\n",
      "train loss:0.8984800316510771\n",
      "train loss:0.99775003381396\n",
      "train loss:0.9191898990433464\n",
      "train loss:0.9771883638776397\n",
      "train loss:1.090195727209514\n",
      "train loss:0.9722872995066786\n",
      "train loss:0.9616558190013238\n",
      "train loss:0.9140615948941381\n",
      "train loss:1.0610050453173085\n",
      "train loss:0.9157917458964409\n",
      "train loss:1.0572269349956591\n",
      "train loss:1.0255862097427304\n",
      "train loss:0.933973676075796\n",
      "train loss:0.7789028380862699\n",
      "train loss:0.8463607319912425\n",
      "train loss:0.9183670425480157\n",
      "train loss:0.8725706348465992\n",
      "train loss:0.9439223996347699\n",
      "train loss:1.1924066630725696\n",
      "train loss:0.9439182874055244\n",
      "train loss:0.8307072253918747\n",
      "train loss:0.9697382765571446\n",
      "train loss:0.973522133899482\n",
      "train loss:0.8549534271247446\n",
      "train loss:0.9761114512219722\n",
      "train loss:0.9312075944743842\n",
      "train loss:1.0133997119492362\n",
      "train loss:0.8369749619867786\n",
      "train loss:0.9670989831993356\n",
      "train loss:0.9898225363261404\n",
      "train loss:0.7411813315978555\n",
      "train loss:1.0864913218748538\n",
      "train loss:1.0483393610952558\n",
      "train loss:0.9987713686438054\n",
      "train loss:0.8196315852265207\n",
      "train loss:0.9008211928300761\n",
      "train loss:0.8984878430819252\n",
      "train loss:0.9681752101484524\n",
      "train loss:0.7538510057434316\n",
      "train loss:0.8501215823223243\n",
      "train loss:0.8709938633102073\n",
      "train loss:0.6922162218419576\n",
      "train loss:0.7777752149805606\n",
      "train loss:0.8789889371721117\n",
      "train loss:0.8283413770792178\n",
      "train loss:0.9022912600566254\n",
      "train loss:0.8887521520317806\n",
      "train loss:0.9787841739002029\n",
      "train loss:0.8364338408385801\n",
      "train loss:0.791687165466411\n",
      "train loss:0.9167800546781083\n",
      "train loss:0.9934490153918225\n",
      "train loss:0.8210843538801185\n",
      "train loss:0.7754337716069613\n",
      "train loss:1.129650970645317\n",
      "train loss:0.9035564340999659\n",
      "train loss:1.1272176023052507\n",
      "train loss:0.9880046227630912\n",
      "train loss:0.7806016484395658\n",
      "train loss:0.9826851546710423\n",
      "train loss:0.929389555522342\n",
      "train loss:0.837045226402168\n",
      "train loss:1.0921927718813\n",
      "train loss:0.8410483033973981\n",
      "train loss:0.9054448441337064\n",
      "train loss:0.9100812272068696\n",
      "train loss:1.0443566629404812\n",
      "train loss:0.8362737437346724\n",
      "train loss:0.821419496659299\n",
      "train loss:0.9654234443425032\n",
      "train loss:0.8739144560687362\n",
      "train loss:0.8769211623457954\n",
      "train loss:0.7013747529728975\n",
      "train loss:0.8648961837601672\n",
      "train loss:0.9619581008158697\n",
      "train loss:0.8178892270202982\n",
      "train loss:0.8974878502385307\n",
      "train loss:0.9757436256320335\n",
      "train loss:0.842078511309687\n",
      "train loss:0.7807530125564776\n",
      "train loss:0.895509193400652\n",
      "train loss:0.6713694891470721\n",
      "train loss:1.0025599789899649\n",
      "train loss:1.0982703729989707\n",
      "train loss:0.9928154998268316\n",
      "train loss:1.0187851682862048\n",
      "train loss:0.9607858072909327\n",
      "train loss:0.9144365674859585\n",
      "train loss:0.8474860149625222\n",
      "train loss:1.081257664147157\n",
      "train loss:0.9590876750827606\n",
      "train loss:0.8020832830868065\n",
      "train loss:0.9303887703972845\n",
      "train loss:0.8829684946960243\n",
      "train loss:0.698943064573008\n",
      "train loss:0.9036300954219505\n",
      "train loss:0.9193658050829973\n",
      "train loss:0.7849763543956948\n",
      "train loss:0.9437878299770976\n",
      "train loss:1.0073329678368417\n",
      "train loss:0.9114693796835626\n",
      "train loss:1.0165189056931634\n",
      "train loss:0.7487766174596134\n",
      "train loss:0.928517154857515\n",
      "train loss:1.050058886348556\n",
      "train loss:0.8305549301231377\n",
      "train loss:0.9498523606823096\n",
      "train loss:0.8446889612343269\n",
      "train loss:0.8733549811099209\n",
      "train loss:0.8542922439681944\n",
      "train loss:0.8623722217411585\n",
      "train loss:0.8602832490777675\n",
      "train loss:0.8707122121200211\n",
      "train loss:1.0315780097238532\n",
      "train loss:0.8603212927270046\n",
      "train loss:1.0306000781217999\n",
      "train loss:0.9988796368138722\n",
      "train loss:0.9918254272195436\n",
      "train loss:0.8647686174633081\n",
      "train loss:1.004178644969732\n",
      "train loss:0.7895086695292821\n",
      "train loss:0.9048973602462957\n",
      "train loss:1.042944770186154\n",
      "train loss:0.9764144935324005\n",
      "train loss:0.9824453632552406\n",
      "train loss:0.927873189112368\n",
      "train loss:1.1886931554358156\n",
      "train loss:0.8011752821368217\n",
      "train loss:0.8535718761758035\n",
      "train loss:0.971820109640203\n",
      "train loss:0.7329808570205972\n",
      "train loss:1.056978234207168\n",
      "train loss:1.075068107906621\n",
      "train loss:0.8881106113354355\n",
      "train loss:0.9111395331483262\n",
      "train loss:1.0590897088690265\n",
      "train loss:0.87951070567773\n",
      "train loss:0.882353300427649\n",
      "train loss:0.9399722264481853\n",
      "train loss:1.0587481555473892\n",
      "train loss:0.8691488615211976\n",
      "train loss:0.8721104723589851\n",
      "train loss:0.990740147986192\n",
      "train loss:0.8567837637966887\n",
      "train loss:0.9873739807227484\n",
      "train loss:0.7655088398123562\n",
      "train loss:1.0437497997689877\n",
      "train loss:0.9079802084167761\n",
      "train loss:0.7766628622542153\n",
      "train loss:0.847147984194552\n",
      "train loss:0.7638273292085453\n",
      "train loss:0.8815488938443287\n",
      "train loss:0.8880647019547707\n",
      "train loss:1.0071263259274752\n",
      "train loss:0.7817820148449787\n",
      "train loss:0.9625789898845377\n",
      "train loss:0.9743317386127229\n",
      "train loss:0.8461369029361911\n",
      "train loss:0.9924357410862784\n",
      "train loss:1.048333647407954\n",
      "train loss:0.8649089987164069\n",
      "train loss:1.0403735377240435\n",
      "train loss:0.9827967006272432\n",
      "train loss:1.0912712043492658\n",
      "train loss:0.9027989325176844\n",
      "train loss:0.8993047461840882\n",
      "train loss:0.8039543562498344\n",
      "train loss:0.9045828431396654\n",
      "train loss:0.8814385078144285\n",
      "train loss:1.1319696356014173\n",
      "train loss:0.933923416471429\n",
      "train loss:0.9940866228503584\n",
      "train loss:0.8474781246440409\n",
      "train loss:0.7745224862006388\n",
      "train loss:0.8865152722493912\n",
      "train loss:0.869159460635047\n",
      "train loss:0.8112835329393342\n",
      "train loss:0.8749342396872709\n",
      "train loss:0.9248218662828781\n",
      "train loss:0.9447243922506325\n",
      "train loss:1.199390217786654\n",
      "train loss:0.9324171825502926\n",
      "train loss:0.9427767626634559\n",
      "train loss:0.9334464591631617\n",
      "train loss:0.8365612618371939\n",
      "train loss:0.9571915267944613\n",
      "train loss:0.7164630329294319\n",
      "train loss:0.8785043936489952\n",
      "train loss:0.9920669303304941\n",
      "train loss:1.0211333431012526\n",
      "train loss:1.0431369568381312\n",
      "train loss:1.0441659378798334\n",
      "train loss:0.9333775525195555\n",
      "train loss:0.8954204729798744\n",
      "train loss:0.797191423408932\n",
      "train loss:0.94539392088867\n",
      "train loss:0.9981668331019091\n",
      "train loss:1.0425039521296051\n",
      "train loss:1.005007614807852\n",
      "=== epoch:6, train acc:0.992, test acc:0.986 ===\n",
      "train loss:0.7305150050642979\n",
      "train loss:0.8969500164874321\n",
      "train loss:0.9023991143458229\n",
      "train loss:0.9072089595400082\n",
      "train loss:0.9564437688604714\n",
      "train loss:1.0588755892222579\n",
      "train loss:0.8759350704961746\n",
      "train loss:0.9092518071135112\n",
      "train loss:0.9886212594367827\n",
      "train loss:0.9946536981032353\n",
      "train loss:1.013631578614347\n",
      "train loss:0.8894838216114099\n",
      "train loss:0.8504792933080448\n",
      "train loss:0.8618126395175301\n",
      "train loss:0.8280536661668294\n",
      "train loss:1.0393585215667316\n",
      "train loss:0.9067560529016564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.7352392859644405\n",
      "train loss:0.8853529098679777\n",
      "train loss:0.8605710590288838\n",
      "train loss:0.885150048275317\n",
      "train loss:0.7704274968671299\n",
      "train loss:0.89685472773091\n",
      "train loss:0.9457168680146859\n",
      "train loss:1.0944633010137388\n",
      "train loss:1.0363674632303361\n",
      "train loss:1.0199261116028397\n",
      "train loss:0.9547928180946745\n",
      "train loss:0.760041624738908\n",
      "train loss:0.8786451903394181\n",
      "train loss:0.9279280392821466\n",
      "train loss:0.9549586760305547\n",
      "train loss:1.0161552553149023\n",
      "train loss:0.9643445139394377\n",
      "train loss:0.8186881103796495\n",
      "train loss:0.8710613721176008\n",
      "train loss:0.8486650490578433\n",
      "train loss:0.8057464173666468\n",
      "train loss:0.8599967155681469\n",
      "train loss:0.9114630114485207\n",
      "train loss:0.9266905036798899\n",
      "train loss:0.922661730611856\n",
      "train loss:0.7331709605899809\n",
      "train loss:0.946744571050181\n",
      "train loss:0.7899581791264151\n",
      "train loss:0.8822339946836665\n",
      "train loss:0.8735284198800133\n",
      "train loss:0.7149863679886382\n",
      "train loss:0.9039612340776896\n",
      "train loss:1.1344246129339681\n",
      "train loss:1.0564943425113205\n",
      "train loss:0.930972985116239\n",
      "train loss:0.8597359219523213\n",
      "train loss:1.2279567603061248\n",
      "train loss:0.9964187164440098\n",
      "train loss:1.0040677162425033\n",
      "train loss:0.9502801943334532\n",
      "train loss:0.9063635021668965\n",
      "train loss:0.8890675609812128\n",
      "train loss:0.8945046125648163\n",
      "train loss:0.8234221278360228\n",
      "train loss:0.9622157007656597\n",
      "train loss:0.8625574767447475\n",
      "train loss:1.0608540799044262\n",
      "train loss:0.9051861374425326\n",
      "train loss:0.9060852697424757\n",
      "train loss:0.9952321340259016\n",
      "train loss:0.8796323126391027\n",
      "train loss:0.8883480462165741\n",
      "train loss:1.034831644886944\n",
      "train loss:0.9163889281067172\n",
      "train loss:0.9257898885878276\n",
      "train loss:0.8450457432166827\n",
      "train loss:0.8131753842931552\n",
      "train loss:1.0244945966036778\n",
      "train loss:0.784689787584363\n",
      "train loss:1.0238871237465221\n",
      "train loss:0.7980783429342789\n",
      "train loss:1.0475570194317738\n",
      "train loss:0.7063321021865707\n",
      "train loss:0.8613316364481355\n",
      "train loss:0.677278954534959\n",
      "train loss:0.9650118003896653\n",
      "train loss:0.7141958466212137\n",
      "train loss:0.787819446821845\n",
      "train loss:0.6650521366555731\n",
      "train loss:0.7791699891933979\n",
      "train loss:0.8203282072588436\n",
      "train loss:0.8762502842950319\n",
      "train loss:0.792303223600038\n",
      "train loss:1.007306306865371\n",
      "train loss:0.9532146194126958\n",
      "train loss:0.8941191852849579\n",
      "train loss:0.8172459200749863\n",
      "train loss:0.9751062290072336\n",
      "train loss:0.8963435969605265\n",
      "train loss:0.8430347079771897\n",
      "train loss:0.8050994562548073\n",
      "train loss:0.8677093706217177\n",
      "train loss:0.9271244365347994\n",
      "train loss:0.9395207793741611\n",
      "train loss:0.8725529983979485\n",
      "train loss:1.0907256712539164\n",
      "train loss:0.885788030046089\n",
      "train loss:0.9295021662353848\n",
      "train loss:0.9091968907448554\n",
      "train loss:1.016020274175531\n",
      "train loss:0.9398487074271636\n",
      "train loss:0.9619759560191962\n",
      "train loss:0.891411745216873\n",
      "train loss:0.8160986506523839\n",
      "train loss:0.8413872830188547\n",
      "train loss:1.0452229754121067\n",
      "train loss:0.8037266435504571\n",
      "train loss:1.0482172105255063\n",
      "train loss:0.7074821222012995\n",
      "train loss:1.013668837316002\n",
      "train loss:0.8299914303725557\n",
      "train loss:0.9302393481258311\n",
      "train loss:0.9431525671204222\n",
      "train loss:0.9475709470854629\n",
      "train loss:1.017217746112082\n",
      "train loss:1.025198007804488\n",
      "train loss:0.8819212905335659\n",
      "train loss:0.7614637011436182\n",
      "train loss:0.8980988999286085\n",
      "train loss:0.7862294415774475\n",
      "train loss:0.8594324448697657\n",
      "train loss:0.9199948821079444\n",
      "train loss:0.9016265731458194\n",
      "train loss:0.9109461478160878\n",
      "train loss:0.9492614008030322\n",
      "train loss:0.7981508926668838\n",
      "train loss:1.0477574504845075\n",
      "train loss:0.9957284346322075\n",
      "train loss:0.9280374217436562\n",
      "train loss:0.8795305465359753\n",
      "train loss:0.860194975800285\n",
      "train loss:0.9467071576235806\n",
      "train loss:0.9779160436612463\n",
      "train loss:0.9796255995166503\n",
      "train loss:0.9988759224160821\n",
      "train loss:0.9872848829149439\n",
      "train loss:0.7485844218691438\n",
      "train loss:1.0359770829510293\n",
      "train loss:0.9274838966906553\n",
      "train loss:0.787391079858808\n",
      "train loss:1.017921513242294\n",
      "train loss:0.953329910423534\n",
      "train loss:0.9963324184718934\n",
      "train loss:0.9740586481302391\n",
      "train loss:1.0404345902189467\n",
      "train loss:0.9390119055499743\n",
      "train loss:0.8506375776057529\n",
      "train loss:0.9820722573343672\n",
      "train loss:0.7990542471349571\n",
      "train loss:0.8872695147029177\n",
      "train loss:0.828733510132578\n",
      "train loss:0.9539793591597641\n",
      "train loss:0.918331634633742\n",
      "train loss:0.8373827053935925\n",
      "train loss:0.8313434632232146\n",
      "train loss:0.843754995941745\n",
      "train loss:0.9279401927527651\n",
      "train loss:0.9738499433552075\n",
      "train loss:0.893962122670229\n",
      "train loss:0.8794703283721895\n",
      "train loss:1.0471054960534343\n",
      "train loss:0.8806904772634502\n",
      "train loss:0.9250931231539373\n",
      "train loss:0.9985606757149762\n",
      "train loss:0.8734153249320852\n",
      "train loss:0.8843191162611683\n",
      "train loss:0.9796663292536314\n",
      "train loss:1.0054071420084711\n",
      "train loss:0.8557072192316155\n",
      "train loss:0.8370537331925598\n",
      "train loss:0.8158459934465233\n",
      "train loss:0.8858255512422707\n",
      "train loss:0.8533462903394539\n",
      "train loss:0.8373126629086733\n",
      "train loss:0.8759842159778303\n",
      "train loss:1.034938092046189\n",
      "train loss:0.9031118966183963\n",
      "train loss:0.7679021606242713\n",
      "train loss:0.8198026126067096\n",
      "train loss:0.983768678513794\n",
      "train loss:0.8585672331348586\n",
      "train loss:0.9165032614261601\n",
      "train loss:0.9569781734347377\n",
      "train loss:0.9299502955878184\n",
      "train loss:0.973812068565333\n",
      "train loss:0.8986529098276764\n",
      "train loss:0.9479519830139551\n",
      "train loss:0.91677936773461\n",
      "train loss:0.7246220257501536\n",
      "train loss:1.026942472257941\n",
      "train loss:0.8819281120687813\n",
      "train loss:0.7992102430529547\n",
      "train loss:0.8674711128706661\n",
      "train loss:0.8489544084187771\n",
      "train loss:0.9274021162823725\n",
      "train loss:0.9289096368063733\n",
      "train loss:0.7387503554066878\n",
      "train loss:0.9163080556869204\n",
      "train loss:0.8722731628020477\n",
      "train loss:0.9562031034020548\n",
      "train loss:0.8226213206785622\n",
      "train loss:1.0553895158338158\n",
      "train loss:0.8596479648364825\n",
      "train loss:0.9760426792050088\n",
      "train loss:0.9624237438704157\n",
      "train loss:0.9024329858813982\n",
      "train loss:0.8233060688650542\n",
      "train loss:0.9081156746537193\n",
      "train loss:1.1119059104636668\n",
      "train loss:0.9572215834610535\n",
      "train loss:0.9855687300417909\n",
      "train loss:1.025837573812035\n",
      "train loss:0.8081680048636259\n",
      "train loss:0.8202909587220496\n",
      "train loss:0.9717630653632372\n",
      "train loss:0.9181445343673044\n",
      "train loss:0.7384999151988881\n",
      "train loss:0.9483553058746742\n",
      "train loss:0.9369679716327822\n",
      "train loss:0.73565634495175\n",
      "train loss:0.957505962822203\n",
      "train loss:1.1708670677493647\n",
      "train loss:1.0757802342588476\n",
      "train loss:0.9915352888717598\n",
      "train loss:0.8595794567902929\n",
      "train loss:0.9580368173569214\n",
      "train loss:0.9879208743880716\n",
      "train loss:0.8855225410557663\n",
      "train loss:0.8103394032938188\n",
      "train loss:1.0586027181796007\n",
      "train loss:0.8670105421736103\n",
      "train loss:0.9131190005804646\n",
      "train loss:0.8759123872581581\n",
      "train loss:1.010940009194882\n",
      "train loss:0.9089604766018539\n",
      "train loss:0.8217051007794736\n",
      "train loss:0.9300353920470471\n",
      "train loss:0.9118287065709343\n",
      "train loss:0.9525571981259979\n",
      "train loss:0.8822682196096093\n",
      "train loss:0.8597680098184735\n",
      "train loss:0.7980048247860342\n",
      "train loss:1.0560593540489007\n",
      "train loss:1.0788992026043482\n",
      "train loss:0.797370411691793\n",
      "train loss:0.7462739200088002\n",
      "train loss:0.8376389690591175\n",
      "train loss:0.8192349050705036\n",
      "train loss:0.9293934951382226\n",
      "train loss:1.0722297091914157\n",
      "train loss:0.8311493899880492\n",
      "train loss:0.8662201210976568\n",
      "train loss:0.9457974302089395\n",
      "train loss:0.8520966582342261\n",
      "train loss:0.8004252182552263\n",
      "train loss:0.9130290648695016\n",
      "train loss:1.1269525304514731\n",
      "train loss:0.8615393901500451\n",
      "train loss:0.6380716696183913\n",
      "train loss:0.9795909804590743\n",
      "train loss:1.0278641244784519\n",
      "train loss:0.8914492350389007\n",
      "train loss:1.0114605565924035\n",
      "train loss:0.7929726813323917\n",
      "train loss:1.0197547613936069\n",
      "train loss:0.8416200919364241\n",
      "train loss:0.935476574065948\n",
      "train loss:0.9557083996206509\n",
      "train loss:0.7187336561336912\n",
      "train loss:1.001196813687294\n",
      "train loss:0.9875436528556798\n",
      "train loss:0.7905905504796492\n",
      "train loss:0.8073268334835576\n",
      "train loss:0.9920828303322787\n",
      "train loss:0.8527235187769995\n",
      "train loss:0.8398580096252456\n",
      "train loss:0.8870073356047695\n",
      "train loss:0.9422930507821686\n",
      "train loss:1.0092132118773507\n",
      "train loss:0.8186422676178826\n",
      "train loss:1.0681205976341053\n",
      "train loss:0.8885865565583133\n",
      "train loss:0.8011244790840746\n",
      "train loss:0.8991638071066452\n",
      "train loss:0.8025362403888705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.8831121767262906\n",
      "train loss:0.9080799763182845\n",
      "train loss:0.9755029030837531\n",
      "train loss:0.8937350334257432\n",
      "train loss:0.8234272347963619\n",
      "train loss:0.9527162674490052\n",
      "train loss:1.0073727925372242\n",
      "train loss:0.8496833261018417\n",
      "train loss:0.7086902118245988\n",
      "train loss:0.9876497305318327\n",
      "train loss:0.9775770068162773\n",
      "train loss:0.92706009958365\n",
      "train loss:0.9046293332505028\n",
      "train loss:0.8354657212088548\n",
      "train loss:0.8684369807083793\n",
      "train loss:0.858363014762046\n",
      "train loss:0.8140622334380682\n",
      "train loss:0.7952655134998516\n",
      "train loss:0.8716226097627012\n",
      "train loss:0.88489823207784\n",
      "train loss:0.957741985825541\n",
      "train loss:0.9122302069518627\n",
      "train loss:0.9493325643232114\n",
      "train loss:0.8693745897666751\n",
      "train loss:0.7696517155100129\n",
      "train loss:0.9494454086888596\n",
      "train loss:0.9069404226416311\n",
      "train loss:0.8599991902972114\n",
      "train loss:0.9326956217613752\n",
      "train loss:0.9237263536150526\n",
      "train loss:0.7402074307088646\n",
      "train loss:0.8238240788670943\n",
      "train loss:0.9238348544978042\n",
      "train loss:1.072018848854979\n",
      "train loss:1.0189737529819023\n",
      "train loss:1.1079597850204916\n",
      "train loss:0.9439719695051291\n",
      "train loss:0.8667706123902776\n",
      "train loss:0.8528500851620803\n",
      "train loss:1.0698152375086039\n",
      "train loss:0.8809523829588641\n",
      "train loss:1.0002339148600772\n",
      "train loss:0.9715663466783482\n",
      "train loss:0.7210198633128069\n",
      "train loss:0.943999854306973\n",
      "train loss:0.9229431591265547\n",
      "train loss:0.864899912022708\n",
      "train loss:0.9250536845730041\n",
      "train loss:0.8560984853684224\n",
      "train loss:0.8774202197606452\n",
      "train loss:0.827015638662474\n",
      "train loss:0.8854493683827136\n",
      "train loss:0.927566926985198\n",
      "train loss:0.8715932867431442\n",
      "train loss:0.9434957676628298\n",
      "train loss:0.9800308216895052\n",
      "train loss:0.9835866960756391\n",
      "train loss:0.8445430619999281\n",
      "train loss:0.8970542727378862\n",
      "train loss:0.9281677344085663\n",
      "train loss:0.8911729042664979\n",
      "train loss:0.8855373388165718\n",
      "train loss:0.7943700006159847\n",
      "train loss:0.8260077689074795\n",
      "train loss:0.9174999243407878\n",
      "train loss:0.8505473323367917\n",
      "train loss:0.7463486255540904\n",
      "train loss:0.9164360260378046\n",
      "train loss:0.829234712995527\n",
      "train loss:0.8699961276688096\n",
      "train loss:0.8228857531208387\n",
      "train loss:0.8703394328144176\n",
      "train loss:0.8782455703660969\n",
      "train loss:0.8216512058414586\n",
      "train loss:0.8857597501654932\n",
      "train loss:0.8659522188723726\n",
      "train loss:1.024883491399624\n",
      "train loss:0.8771542567122488\n",
      "train loss:1.1404110661421358\n",
      "train loss:0.971036229055513\n",
      "train loss:0.7826612118053304\n",
      "train loss:0.878257059296936\n",
      "train loss:0.9965265387640622\n",
      "train loss:0.9665250972458391\n",
      "train loss:0.9600659846349774\n",
      "train loss:1.0061007220984173\n",
      "train loss:0.8946905655921116\n",
      "train loss:0.907594873459924\n",
      "train loss:0.8227851501689402\n",
      "train loss:0.8920446968018082\n",
      "train loss:1.1108867679165044\n",
      "train loss:0.979967010055761\n",
      "train loss:0.9366267184706939\n",
      "train loss:1.0746692626510024\n",
      "train loss:0.8887789349407733\n",
      "train loss:0.9752922945470986\n",
      "train loss:0.8668602902984891\n",
      "train loss:0.8870520131513513\n",
      "train loss:0.7412327039655595\n",
      "train loss:0.9871919221061575\n",
      "train loss:0.8737900793780875\n",
      "train loss:0.8839096865529565\n",
      "train loss:0.7297210658624168\n",
      "train loss:0.8244692881179628\n",
      "train loss:0.8392669752543158\n",
      "train loss:0.996139946974361\n",
      "train loss:0.8606530934294522\n",
      "train loss:0.7973590191630335\n",
      "train loss:0.8296021585148518\n",
      "train loss:0.928548113690473\n",
      "train loss:1.0402512366156438\n",
      "train loss:0.876379212919562\n",
      "train loss:0.9455541622368948\n",
      "train loss:0.9506751203151328\n",
      "train loss:0.9078147235644615\n",
      "train loss:1.002547960607967\n",
      "train loss:0.8799250630393124\n",
      "train loss:0.9671269886682694\n",
      "train loss:0.8879432860236314\n",
      "train loss:1.0003530708429826\n",
      "train loss:0.8923630069575538\n",
      "train loss:0.8941043791424821\n",
      "train loss:0.861633605997065\n",
      "train loss:0.8733870208133356\n",
      "train loss:0.843003042244979\n",
      "train loss:0.701249264386632\n",
      "train loss:0.8731125275814549\n",
      "train loss:0.9257666573020866\n",
      "train loss:0.8688963760690129\n",
      "train loss:0.8405797705612705\n",
      "train loss:1.0027005543857863\n",
      "train loss:0.7524024940977984\n",
      "train loss:0.8596397064333972\n",
      "train loss:0.8988328451089644\n",
      "train loss:0.9838176593259012\n",
      "train loss:0.9797581004244295\n",
      "train loss:0.9524576266414334\n",
      "train loss:0.8557569940009535\n",
      "train loss:0.9153112622627695\n",
      "train loss:0.9121814780845419\n",
      "train loss:0.893232690485028\n",
      "train loss:0.8717825384771372\n",
      "train loss:0.8942578789708618\n",
      "train loss:0.833025016541044\n",
      "train loss:0.9453604614676259\n",
      "train loss:0.9269938147751176\n",
      "train loss:0.7300538846265633\n",
      "train loss:0.9967044805071394\n",
      "train loss:0.8839102486691199\n",
      "train loss:0.7968799069996089\n",
      "train loss:0.8593100258993387\n",
      "train loss:0.906831548336241\n",
      "train loss:0.9205586516663203\n",
      "train loss:0.7958641169032427\n",
      "train loss:0.981294103823594\n",
      "train loss:1.0608969810647004\n",
      "train loss:0.8522354191342891\n",
      "train loss:0.8078446146476237\n",
      "train loss:0.8713961291823058\n",
      "train loss:1.0770264255235293\n",
      "train loss:0.8619474497296451\n",
      "train loss:0.7058677912675304\n",
      "train loss:0.7571642098391915\n",
      "train loss:0.9103747740596033\n",
      "train loss:0.8019293728714775\n",
      "train loss:0.979243644798857\n",
      "train loss:0.9577187611785932\n",
      "train loss:0.992970793046378\n",
      "train loss:0.9357283273388455\n",
      "train loss:0.8682652412510069\n",
      "train loss:0.7823566203285661\n",
      "train loss:0.8715378982185557\n",
      "train loss:1.0104593387501106\n",
      "train loss:0.9809450304898369\n",
      "train loss:0.7654083817267088\n",
      "train loss:0.8817748500151804\n",
      "train loss:0.9795018117560571\n",
      "train loss:0.8405122213062929\n",
      "train loss:0.8140142568163733\n",
      "train loss:1.0418008203685067\n",
      "train loss:0.9750507449026871\n",
      "train loss:0.9052763768672861\n",
      "train loss:0.6775871061050768\n",
      "train loss:0.8752666930678042\n",
      "train loss:0.8873090448799037\n",
      "train loss:0.9515786845979385\n",
      "train loss:0.7749909513161052\n",
      "train loss:0.9116714988065282\n",
      "train loss:0.9454659779709128\n",
      "train loss:0.8414114930339436\n",
      "train loss:0.9597957052621544\n",
      "train loss:0.7735266280929942\n",
      "train loss:1.0178986493928674\n",
      "train loss:1.0674575204074863\n",
      "train loss:0.9008652009100655\n",
      "train loss:0.981707256894428\n",
      "train loss:1.0550544892412312\n",
      "train loss:1.0008785875919513\n",
      "train loss:0.9263255749253959\n",
      "train loss:0.849536330744408\n",
      "train loss:1.2210880696365838\n",
      "train loss:0.9982579526091311\n",
      "train loss:0.9270803219888205\n",
      "train loss:0.9711383230413608\n",
      "train loss:0.8256785754758866\n",
      "train loss:0.8288161363575872\n",
      "train loss:0.7448396517260853\n",
      "train loss:0.8795129949583611\n",
      "train loss:0.9174390235654587\n",
      "train loss:0.8427943331365367\n",
      "train loss:0.9376241993715343\n",
      "train loss:0.9083824659446461\n",
      "train loss:1.0335959188614015\n",
      "train loss:0.9585672354662254\n",
      "train loss:0.9538309996676333\n",
      "train loss:0.9725413773136818\n",
      "train loss:0.9912242423662313\n",
      "train loss:0.9578660459018192\n",
      "train loss:0.8968027785905511\n",
      "train loss:0.8968851607643873\n",
      "train loss:0.9427632191001075\n",
      "train loss:0.7010809930012182\n",
      "train loss:0.9496995262951882\n",
      "train loss:1.090554657713288\n",
      "train loss:1.034763883491619\n",
      "train loss:0.6722056543867031\n",
      "train loss:0.8556138390438148\n",
      "train loss:1.057964429434647\n",
      "train loss:0.7891250214986475\n",
      "train loss:0.7618112870705365\n",
      "train loss:0.7617981573800284\n",
      "train loss:0.6887164796041724\n",
      "train loss:1.212889415057983\n",
      "train loss:0.8660216907188335\n",
      "train loss:0.7917231237207129\n",
      "train loss:0.8146724922663752\n",
      "train loss:0.9363236766921235\n",
      "train loss:0.7197480594870733\n",
      "train loss:0.9196063759104233\n",
      "train loss:0.7022054451679988\n",
      "train loss:0.9128485463567958\n",
      "train loss:1.0327344064712887\n",
      "train loss:0.9389463142947848\n",
      "train loss:1.0082055871922175\n",
      "train loss:1.087497149700428\n",
      "train loss:0.940264649160178\n",
      "train loss:0.8777994373461588\n",
      "train loss:0.8692991032592555\n",
      "train loss:0.9160252689182853\n",
      "train loss:0.8734706540754159\n",
      "train loss:0.8505668121008598\n",
      "train loss:0.8216346745277211\n",
      "train loss:0.9093924339737162\n",
      "train loss:1.027920031745352\n",
      "train loss:0.7378735077692575\n",
      "train loss:0.9883377844982917\n",
      "train loss:0.8317087295313159\n",
      "train loss:0.8729220401113079\n",
      "train loss:0.7480342731943703\n",
      "train loss:1.0624062351181929\n",
      "train loss:0.8997132360992575\n",
      "train loss:1.1132485105647283\n",
      "train loss:1.0519197201953812\n",
      "train loss:0.8170072837988345\n",
      "train loss:0.8140327497071951\n",
      "train loss:1.0049936195735099\n",
      "train loss:0.9632073065593816\n",
      "train loss:1.0033333603725676\n",
      "train loss:1.0209921278002994\n",
      "train loss:0.8942308226985709\n",
      "train loss:0.8515637585144014\n",
      "train loss:0.9913849280924286\n",
      "train loss:0.8580238100367491\n",
      "train loss:0.8121381316755034\n",
      "train loss:0.9649167666491628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.9154963487373421\n",
      "train loss:0.9246962854585764\n",
      "train loss:0.9347592235736205\n",
      "train loss:0.9483193552971714\n",
      "train loss:0.8954233595720379\n",
      "train loss:0.8839511656600914\n",
      "train loss:0.9549266603864082\n",
      "train loss:0.8804728613038393\n",
      "train loss:0.9245205144563662\n",
      "train loss:0.9429835085537742\n",
      "train loss:0.7583760375085629\n",
      "train loss:0.9542496346085945\n",
      "train loss:0.8200563089407547\n",
      "train loss:0.8466396872745173\n",
      "train loss:1.0440492108031407\n",
      "train loss:0.9857299613467387\n",
      "train loss:0.9254750522554069\n",
      "train loss:0.7564946395704771\n",
      "train loss:0.8223053346502851\n",
      "train loss:0.8234981636977251\n",
      "train loss:0.9245401943011018\n",
      "train loss:0.8659005375747962\n",
      "train loss:0.8432823813532956\n",
      "train loss:0.9639775776009993\n",
      "train loss:0.8022490482869493\n",
      "train loss:0.8425985712651428\n",
      "train loss:0.8843980117104329\n",
      "train loss:0.7894246639221533\n",
      "train loss:0.8623586366778749\n",
      "train loss:0.8686203708957022\n",
      "train loss:0.8348536598501007\n",
      "train loss:0.7738678534514952\n",
      "train loss:0.9464424684203415\n",
      "=== epoch:7, train acc:0.994, test acc:0.991 ===\n",
      "train loss:0.8484584834616226\n",
      "train loss:0.7997123147952797\n",
      "train loss:0.9920321772908028\n",
      "train loss:1.0165432654856146\n",
      "train loss:0.8345771199547221\n",
      "train loss:0.9736931382883119\n",
      "train loss:0.831681862390698\n",
      "train loss:0.8898944544128061\n",
      "train loss:0.9075516938911741\n",
      "train loss:1.049742311316101\n",
      "train loss:0.9552202362397568\n",
      "train loss:0.7452208937251555\n",
      "train loss:0.8623509592342633\n",
      "train loss:0.8423282433686226\n",
      "train loss:0.948355820024584\n",
      "train loss:0.9241979985151868\n",
      "train loss:0.8214098861225003\n",
      "train loss:0.9263488974886269\n",
      "train loss:0.8940583163811696\n",
      "train loss:0.9004864164418683\n",
      "train loss:0.968951403057468\n",
      "train loss:0.8251661253653536\n",
      "train loss:0.7777366207572749\n",
      "train loss:0.805204938262039\n",
      "train loss:0.8631512696269177\n",
      "train loss:0.7686956424911314\n",
      "train loss:1.0999217503261283\n",
      "train loss:0.994665981169121\n",
      "train loss:0.8731798051469939\n",
      "train loss:0.8687432467240654\n",
      "train loss:0.9625793795611111\n",
      "train loss:0.9719249863896671\n",
      "train loss:0.9373895513209186\n",
      "train loss:0.8356433008242783\n",
      "train loss:0.924818310853508\n",
      "train loss:0.8478629423188706\n",
      "train loss:0.8568661090088396\n",
      "train loss:0.9747750979758864\n",
      "train loss:0.9323097989120761\n",
      "train loss:0.8753905696720696\n",
      "train loss:0.833427898146629\n",
      "train loss:0.6938327354249276\n",
      "train loss:0.9449685298116955\n",
      "train loss:0.739209397737666\n",
      "train loss:0.7638718753880482\n",
      "train loss:0.8498836404247386\n",
      "train loss:0.8789670933798693\n",
      "train loss:1.047994816117254\n",
      "train loss:1.0019658458300855\n",
      "train loss:0.781974192925462\n",
      "train loss:0.7689204013221504\n",
      "train loss:1.0743755087532931\n",
      "train loss:0.9588699969183122\n",
      "train loss:0.9213237635240589\n",
      "train loss:0.801369956829818\n",
      "train loss:0.857360380409574\n",
      "train loss:0.9675097215297684\n",
      "train loss:0.8856416993684871\n",
      "train loss:0.9598767897450625\n",
      "train loss:0.7842237894267692\n",
      "train loss:0.7914529010406928\n",
      "train loss:0.7508918545899084\n",
      "train loss:1.045471302526023\n",
      "train loss:0.827542744501569\n",
      "train loss:0.7793071651021911\n",
      "train loss:0.859102565209227\n",
      "train loss:0.9057455173898141\n",
      "train loss:0.8678569306577874\n",
      "train loss:0.8989748315448247\n",
      "train loss:0.908568676115108\n",
      "train loss:1.1300303750662979\n",
      "train loss:0.8073045270584922\n",
      "train loss:0.8464070609214258\n",
      "train loss:0.882314863366446\n",
      "train loss:0.8127116104368264\n",
      "train loss:0.9436329501685988\n",
      "train loss:0.8726028739851666\n",
      "train loss:0.7593455558549667\n",
      "train loss:0.9876208031914746\n",
      "train loss:1.0788694614747394\n",
      "train loss:0.9305698187044337\n",
      "train loss:0.7858441743320234\n",
      "train loss:0.659500843248503\n",
      "train loss:0.8745554074654984\n",
      "train loss:0.9735825887060328\n",
      "train loss:1.0082144155934505\n",
      "train loss:0.9363632983825977\n",
      "train loss:0.8263850628198012\n",
      "train loss:0.9906975267248952\n",
      "train loss:0.7258977356981235\n",
      "train loss:0.9003449088190427\n",
      "train loss:0.8690865485542687\n",
      "train loss:0.9303415252358395\n",
      "train loss:0.987688578094062\n",
      "train loss:0.9603889539948043\n",
      "train loss:0.9727842639659964\n",
      "train loss:0.6771888556647763\n",
      "train loss:0.8202577196981654\n",
      "train loss:0.8287480057583327\n",
      "train loss:0.7387539068892238\n",
      "train loss:0.9882993816232333\n",
      "train loss:0.881539454138219\n",
      "train loss:0.978118711845113\n",
      "train loss:0.9891790753219084\n",
      "train loss:0.9965018045362747\n",
      "train loss:0.8413153934672271\n",
      "train loss:0.9065045555015782\n",
      "train loss:1.0557269526068305\n",
      "train loss:0.9971280993845479\n",
      "train loss:0.8550706397921148\n",
      "train loss:0.8203815220531935\n",
      "train loss:0.7383568746145761\n",
      "train loss:1.0698520127540903\n",
      "train loss:0.8840837085982796\n",
      "train loss:0.8512153716748249\n",
      "train loss:0.7985116514886075\n",
      "train loss:0.9740991182004634\n",
      "train loss:0.9461307877960503\n",
      "train loss:0.8904220023504597\n",
      "train loss:0.6227955529263692\n",
      "train loss:0.7644883201556205\n",
      "train loss:0.9018429822775037\n",
      "train loss:1.0541249168121853\n",
      "train loss:1.1154605160768214\n",
      "train loss:0.9513426384023248\n",
      "train loss:0.8351281656921695\n",
      "train loss:0.7491040887844548\n",
      "train loss:0.9586176147672053\n",
      "train loss:0.9405039047472491\n",
      "train loss:1.0565592888211344\n",
      "train loss:0.8256000977558909\n",
      "train loss:0.8032744547053932\n",
      "train loss:0.7454713127681891\n",
      "train loss:1.023956184575161\n",
      "train loss:0.8587758641480664\n",
      "train loss:0.9550065327171986\n",
      "train loss:0.9342647749300776\n",
      "train loss:1.0650712979664059\n",
      "train loss:0.8974105945479063\n",
      "train loss:0.7697426436417149\n",
      "train loss:1.0176205852721365\n",
      "train loss:0.9753159318596525\n",
      "train loss:0.978320078385647\n",
      "train loss:0.8203795699734953\n",
      "train loss:0.9434400678826301\n",
      "train loss:0.7930279852403989\n",
      "train loss:0.7808788194644184\n",
      "train loss:0.8070055974831406\n",
      "train loss:0.9212841345082786\n",
      "train loss:0.8718047315261989\n",
      "train loss:0.8258762180555215\n",
      "train loss:0.8848554011275621\n",
      "train loss:0.7447356484052058\n",
      "train loss:0.9072893881093708\n",
      "train loss:0.8366891917351412\n",
      "train loss:0.9589361048054227\n",
      "train loss:0.8741738399079207\n",
      "train loss:1.0845837991727618\n",
      "train loss:0.9815565765646632\n",
      "train loss:0.9269686977086871\n",
      "train loss:0.7596637003510007\n",
      "train loss:0.9200672304840792\n",
      "train loss:0.9200696597664159\n",
      "train loss:0.9122275133803028\n",
      "train loss:0.8964167632635709\n",
      "train loss:0.9693422372432029\n",
      "train loss:1.0739234944612648\n",
      "train loss:0.9730900930665514\n",
      "train loss:0.8632177637506452\n",
      "train loss:0.9275092781806288\n",
      "train loss:0.9751943529133967\n",
      "train loss:0.9247789738167017\n",
      "train loss:0.9578911373296459\n",
      "train loss:0.7578855433097706\n",
      "train loss:0.874429551803467\n",
      "train loss:0.9609727404913331\n",
      "train loss:0.9075982410703651\n",
      "train loss:0.9799873295546319\n",
      "train loss:0.8918232447642761\n",
      "train loss:0.83101266238888\n",
      "train loss:0.8445870942983015\n",
      "train loss:1.059000872086137\n",
      "train loss:0.911937506346424\n",
      "train loss:1.0293092489577027\n",
      "train loss:0.7415032601695688\n",
      "train loss:0.8701057807064372\n",
      "train loss:0.8190366040104915\n",
      "train loss:0.9308931603153134\n",
      "train loss:0.8923251904706475\n",
      "train loss:1.1017100915686486\n",
      "train loss:0.9866445639841175\n",
      "train loss:0.7823146148958476\n",
      "train loss:0.9924684715977203\n",
      "train loss:1.2317254787396437\n",
      "train loss:0.9215383132573918\n",
      "train loss:0.8805761832830149\n",
      "train loss:0.8537692355215064\n",
      "train loss:0.8132272490560656\n",
      "train loss:1.1439743459592786\n",
      "train loss:0.9770546595783465\n",
      "train loss:0.8900808285094716\n",
      "train loss:0.9539435244827369\n",
      "train loss:1.039868878101483\n",
      "train loss:1.149900321655492\n",
      "train loss:0.7648960665127155\n",
      "train loss:0.7509585123813348\n",
      "train loss:1.0857589861768693\n",
      "train loss:1.0171407124802976\n",
      "train loss:0.8925413397503459\n",
      "train loss:0.7391752215587879\n",
      "train loss:0.9680371160764624\n",
      "train loss:0.8666732808069917\n",
      "train loss:0.9070597252791613\n",
      "train loss:0.9100689262632398\n",
      "train loss:0.807632529445526\n",
      "train loss:0.8944489831501443\n",
      "train loss:1.017480290913264\n",
      "train loss:0.9951882445248027\n",
      "train loss:1.0432070021082067\n",
      "train loss:0.9877490916571159\n",
      "train loss:0.844407513026199\n",
      "train loss:0.8797057720945475\n",
      "train loss:0.7309016615504198\n",
      "train loss:0.7553739431349765\n",
      "train loss:0.8979711191967478\n",
      "train loss:1.0105160385391512\n",
      "train loss:0.8126250657874787\n",
      "train loss:0.8342575867256631\n",
      "train loss:0.805255246498739\n",
      "train loss:0.9599418516562275\n",
      "train loss:0.9565371868313701\n",
      "train loss:0.8259852023215519\n",
      "train loss:0.9370083658029276\n",
      "train loss:0.9048742266431917\n",
      "train loss:0.8698494484140081\n",
      "train loss:0.8216349253677331\n",
      "train loss:0.8421160830382018\n",
      "train loss:0.9083681361161502\n",
      "train loss:1.2021513764593095\n",
      "train loss:0.8493386581220522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.9746854022963741\n",
      "train loss:1.0420908046525006\n",
      "train loss:1.051551136406481\n",
      "train loss:0.8887899375067327\n",
      "train loss:0.9799655624393229\n",
      "train loss:0.9260580267796144\n",
      "train loss:0.872498824000924\n",
      "train loss:0.60320737839287\n",
      "train loss:0.8680106423413123\n",
      "train loss:0.8233837777718577\n",
      "train loss:0.8179090582488981\n",
      "train loss:0.8360190075499481\n",
      "train loss:1.1065854151204566\n",
      "train loss:0.8569119458936314\n",
      "train loss:0.9724587226045333\n",
      "train loss:0.9208497313452044\n",
      "train loss:0.8651547194961512\n",
      "train loss:0.9653747661394542\n",
      "train loss:1.1193574374945663\n",
      "train loss:1.093109132132171\n",
      "train loss:0.8806431708916507\n",
      "train loss:0.9470881336643593\n",
      "train loss:0.7597811221864608\n",
      "train loss:0.8574548794044943\n",
      "train loss:0.9889716670414893\n",
      "train loss:0.8705778708727498\n",
      "train loss:1.0313933176102106\n",
      "train loss:0.9719220146297612\n",
      "train loss:0.9446202246269391\n",
      "train loss:0.8941143881955976\n",
      "train loss:0.8297226986404295\n",
      "train loss:0.9537937159403864\n",
      "train loss:1.0027649451941119\n",
      "train loss:0.7230061671198175\n",
      "train loss:0.9304258487932848\n",
      "train loss:0.8680888569065239\n",
      "train loss:1.0054913623748676\n",
      "train loss:0.6551224578330225\n",
      "train loss:0.7092613123909202\n",
      "train loss:0.7871110671505689\n",
      "train loss:0.8563426073971189\n",
      "train loss:1.1030712451081106\n",
      "train loss:0.8016240592477257\n",
      "train loss:1.0231653031424877\n",
      "train loss:1.0259867013384516\n",
      "train loss:0.8251545047565999\n",
      "train loss:0.9332289631329814\n",
      "train loss:0.8730569283316058\n",
      "train loss:1.0148319763739682\n",
      "train loss:0.9910121062958855\n",
      "train loss:1.1122218515871967\n",
      "train loss:0.8885997626424208\n",
      "train loss:0.7539469594876057\n",
      "train loss:0.9706118729781886\n",
      "train loss:0.9298081773330595\n",
      "train loss:1.0119268663646255\n",
      "train loss:0.7952979523247861\n",
      "train loss:0.8000946312885299\n",
      "train loss:0.8863077751879882\n",
      "train loss:0.769876907152899\n",
      "train loss:0.8548367302617704\n",
      "train loss:0.863280163337582\n",
      "train loss:0.9999460925721592\n",
      "train loss:0.744203149876332\n",
      "train loss:0.843574923672221\n",
      "train loss:0.976897873955497\n",
      "train loss:0.8035979498458375\n",
      "train loss:0.8865087012210039\n",
      "train loss:0.8453367548933631\n",
      "train loss:0.8405961822192186\n",
      "train loss:0.8377795845552215\n",
      "train loss:0.9690274384131631\n",
      "train loss:0.9493504740223853\n",
      "train loss:0.8665457439582939\n",
      "train loss:1.1147682748838228\n",
      "train loss:0.9600562303869402\n",
      "train loss:0.8628552775243228\n",
      "train loss:0.8830645076070828\n",
      "train loss:0.8241276222971508\n",
      "train loss:0.9307555074081513\n",
      "train loss:0.8569124362763684\n",
      "train loss:0.8478139862802633\n",
      "train loss:0.9046531713749769\n",
      "train loss:0.8130223533228341\n",
      "train loss:0.8261556062977862\n",
      "train loss:0.7801370059974263\n",
      "train loss:0.9272974963494168\n",
      "train loss:0.853324675844189\n",
      "train loss:0.9634464568781587\n",
      "train loss:0.930749589695809\n",
      "train loss:0.7631407756849942\n",
      "train loss:0.8937670643774118\n",
      "train loss:0.716550403930651\n",
      "train loss:1.0231585987777383\n",
      "train loss:0.8704545112683035\n",
      "train loss:0.9711146401344835\n",
      "train loss:0.9428777401074736\n",
      "train loss:0.9496904207687923\n",
      "train loss:0.865517259796585\n",
      "train loss:0.8366088789484806\n",
      "train loss:0.8905061537452454\n",
      "train loss:0.8881867267478732\n",
      "train loss:0.8497737295068812\n",
      "train loss:0.7795989893623819\n",
      "train loss:0.9619232338334411\n",
      "train loss:0.8492190448740822\n",
      "train loss:0.7802379879026182\n",
      "train loss:0.8364101226971318\n",
      "train loss:0.9251882968181817\n",
      "train loss:1.0473924995723192\n",
      "train loss:0.909773319726973\n",
      "train loss:0.7795940083268996\n",
      "train loss:0.9426339076584608\n",
      "train loss:0.8126833235198816\n",
      "train loss:0.9111960393351342\n",
      "train loss:0.8076325887034734\n",
      "train loss:0.8646604524245628\n",
      "train loss:0.9502767763997834\n",
      "train loss:1.0074355784586677\n",
      "train loss:0.7946687689931674\n",
      "train loss:0.8577796407298554\n",
      "train loss:0.8359711285934118\n",
      "train loss:0.9604748504555165\n",
      "train loss:0.9134338298237773\n",
      "train loss:0.9055584323339742\n",
      "train loss:0.8375565946137226\n",
      "train loss:0.9743337322972226\n",
      "train loss:0.9843870663269412\n",
      "train loss:0.8430602133353012\n",
      "train loss:0.9149787903672001\n",
      "train loss:1.0947357694505582\n",
      "train loss:0.9097407663386765\n",
      "train loss:0.8802031538222477\n",
      "train loss:0.8396185020524162\n",
      "train loss:0.7890049771019189\n",
      "train loss:0.8528262639421628\n",
      "train loss:0.846145525631401\n",
      "train loss:0.9699193899746151\n",
      "train loss:0.8906546780352618\n",
      "train loss:0.6810026512145736\n",
      "train loss:0.923489512073841\n",
      "train loss:0.9811137755918935\n",
      "train loss:0.968494530044302\n",
      "train loss:0.7107483897142843\n",
      "train loss:0.9691807080745488\n",
      "train loss:0.9441821313210188\n",
      "train loss:0.5961765954083863\n",
      "train loss:0.7033171375172141\n",
      "train loss:0.9036998401641719\n",
      "train loss:0.7334849316348544\n",
      "train loss:0.8839062617183909\n",
      "train loss:0.8824531998663465\n",
      "train loss:0.7241885988471444\n",
      "train loss:0.8294661019145559\n",
      "train loss:0.9133694157536918\n",
      "train loss:0.8104083851392919\n",
      "train loss:1.1322526714469228\n",
      "train loss:0.9711726996349642\n",
      "train loss:0.827524712137055\n",
      "train loss:0.9726312849301988\n",
      "train loss:0.7042059756649344\n",
      "train loss:1.0057078213778698\n",
      "train loss:0.8481930243193422\n",
      "train loss:0.8477223952845003\n",
      "train loss:0.9210355726568998\n",
      "train loss:0.9369970749603858\n",
      "train loss:1.0564800734678506\n",
      "train loss:0.8619100911772454\n",
      "train loss:0.9203858379770731\n",
      "train loss:0.9188625003005005\n",
      "train loss:0.8012089798383007\n",
      "train loss:0.8815695853153914\n",
      "train loss:0.9109374601360817\n",
      "train loss:0.7847860460180405\n",
      "train loss:0.9802617137486745\n",
      "train loss:0.8527409488034426\n",
      "train loss:0.9878737539410323\n",
      "train loss:1.0366838751570735\n",
      "train loss:0.8602455522419585\n",
      "train loss:0.8966862032287451\n",
      "train loss:0.8714422529233053\n",
      "train loss:0.9272309760535197\n",
      "train loss:1.0068158379688719\n",
      "train loss:0.8081697090175786\n",
      "train loss:0.7620448892953149\n",
      "train loss:0.8393673250539613\n",
      "train loss:0.8702086209408829\n",
      "train loss:1.1163879235524223\n",
      "train loss:0.7633102750302808\n",
      "train loss:0.9574977755694434\n",
      "train loss:0.9045236081860938\n",
      "train loss:0.9622465348343033\n",
      "train loss:0.9005446272202526\n",
      "train loss:0.9422449493265753\n",
      "train loss:0.9013164368171869\n",
      "train loss:0.8386221333030092\n",
      "train loss:0.9420192166838092\n",
      "train loss:0.8473551945755454\n",
      "train loss:0.8533945055908926\n",
      "train loss:0.8925960704905029\n",
      "train loss:0.6513349307218419\n",
      "train loss:0.7401474206048259\n",
      "train loss:0.9989851386737792\n",
      "train loss:0.7677304834769189\n",
      "train loss:0.9373393581412798\n",
      "train loss:1.0036729823591983\n",
      "train loss:0.904887485896351\n",
      "train loss:0.9267061715727034\n",
      "train loss:0.7814455724694434\n",
      "train loss:0.7775169463493435\n",
      "train loss:0.8510370010137376\n",
      "train loss:0.7865675495527837\n",
      "train loss:0.9320560270050828\n",
      "train loss:0.920183808069595\n",
      "train loss:0.9907754162619129\n",
      "train loss:0.836742714682346\n",
      "train loss:0.9369735862451379\n",
      "train loss:0.8003725259253871\n",
      "train loss:0.9644540934602052\n",
      "train loss:0.8598228025373246\n",
      "train loss:0.9181180718602474\n",
      "train loss:1.1136243085355657\n",
      "train loss:0.8423985742270762\n",
      "train loss:0.9002143882174007\n",
      "train loss:0.9434964029187303\n",
      "train loss:0.7193533590679582\n",
      "train loss:1.0355336881118042\n",
      "train loss:0.9187711455491219\n",
      "train loss:0.9294565685343644\n",
      "train loss:0.8207816218743911\n",
      "train loss:1.0577527730553755\n",
      "train loss:0.7688899312469688\n",
      "train loss:0.8426607351068572\n",
      "train loss:1.0108109410801083\n",
      "train loss:0.9308277049852868\n",
      "train loss:0.8347964063813801\n",
      "train loss:0.8783814901233522\n",
      "train loss:0.7615279315590052\n",
      "train loss:0.916037942106253\n",
      "train loss:0.9417867282235963\n",
      "train loss:0.7934697879827738\n",
      "train loss:0.8572517732012372\n",
      "train loss:1.018442362094803\n",
      "train loss:0.94498931961047\n",
      "train loss:0.8125877750894912\n",
      "train loss:0.9820939846031309\n",
      "train loss:1.0095472824494665\n",
      "train loss:0.7609482723367827\n",
      "train loss:0.8204105043809149\n",
      "train loss:0.9611656378350655\n",
      "train loss:0.886477524289091\n",
      "train loss:0.9251232880464584\n",
      "train loss:0.7660503471556158\n",
      "train loss:1.0784281860212979\n",
      "train loss:0.9025999872270024\n",
      "train loss:0.9431469979457623\n",
      "train loss:0.862261866517581\n",
      "train loss:0.6697637719307337\n",
      "train loss:0.9493692565853236\n",
      "train loss:1.024386732692615\n",
      "train loss:0.862968268362518\n",
      "train loss:0.9394963647422807\n",
      "train loss:0.8941164941465547\n",
      "train loss:1.0183085286887448\n",
      "train loss:0.7927920979907185\n",
      "train loss:0.8136675920521149\n",
      "train loss:0.9173642300246236\n",
      "train loss:1.032529763029728\n",
      "train loss:0.9894259871051176\n",
      "train loss:0.9707088757317658\n",
      "train loss:0.8179214089554744\n",
      "train loss:0.8982361034674783\n",
      "train loss:0.9431590330520412\n",
      "train loss:0.7845597945141526\n",
      "train loss:0.9816756345302661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.9465852208256713\n",
      "train loss:0.9800539975496433\n",
      "train loss:0.9025063115332782\n",
      "train loss:0.8418918970838806\n",
      "train loss:1.0510409827421812\n",
      "train loss:0.9442915644383586\n",
      "train loss:0.8744114317322469\n",
      "train loss:0.9487315762270154\n",
      "train loss:0.8907371596123661\n",
      "train loss:0.9783908021062615\n",
      "train loss:0.9961097493548426\n",
      "train loss:0.9116541167916735\n",
      "train loss:0.745788403319226\n",
      "train loss:0.9110791478895358\n",
      "train loss:0.94526521456973\n",
      "train loss:0.8698008567371552\n",
      "train loss:0.9087389401998114\n",
      "train loss:0.8679093163244082\n",
      "train loss:0.7938304395289311\n",
      "train loss:0.8238668602247214\n",
      "train loss:0.7624399697163186\n",
      "train loss:1.0891463862589683\n",
      "train loss:0.7821961684906178\n",
      "train loss:0.8667507355552568\n",
      "train loss:0.9213393055133312\n",
      "train loss:0.9129706137165224\n",
      "train loss:1.0006793039972295\n",
      "train loss:0.8552829463867326\n",
      "train loss:0.9472502048865294\n",
      "train loss:0.72697391859007\n",
      "train loss:0.8597914980468815\n",
      "train loss:0.8678189282997281\n",
      "train loss:1.0888819095098468\n",
      "train loss:0.7736139867480222\n",
      "train loss:0.8775882281267863\n",
      "train loss:0.8667045343718849\n",
      "train loss:0.7560292321674135\n",
      "train loss:0.7403571871562196\n",
      "train loss:0.8638352274259422\n",
      "train loss:0.7772515016466063\n",
      "train loss:0.9411876918597981\n",
      "train loss:0.7867786125569671\n",
      "train loss:0.84981662757745\n",
      "train loss:0.9794656017359742\n",
      "train loss:0.941610131296456\n",
      "train loss:0.7442482342877329\n",
      "train loss:0.858161456112536\n",
      "train loss:0.9619752270003541\n",
      "train loss:0.8907843330686667\n",
      "train loss:0.7667327937362947\n",
      "train loss:0.848001555257361\n",
      "train loss:0.8476659577982114\n",
      "train loss:0.853414194205858\n",
      "train loss:0.9769329164036425\n",
      "train loss:0.8480753439253417\n",
      "train loss:0.9090848533382602\n",
      "train loss:0.8940776252556292\n",
      "train loss:0.9641292719033631\n",
      "train loss:0.9384783885717011\n",
      "train loss:0.7558967425367533\n",
      "train loss:0.9482561657229978\n",
      "train loss:0.7688140694301997\n",
      "train loss:0.8398849487779865\n",
      "train loss:0.8000686663771214\n",
      "train loss:0.9788255795160093\n",
      "train loss:0.9627848333837907\n",
      "train loss:0.8644124949276312\n",
      "train loss:0.7648151330858091\n",
      "train loss:0.859583173525572\n",
      "train loss:0.8775806912762327\n",
      "train loss:0.6720706074266454\n",
      "train loss:0.8130539566255487\n",
      "train loss:0.9699289617615519\n",
      "train loss:0.8449388088173032\n",
      "train loss:0.8849587314225122\n",
      "train loss:0.9154369998310378\n",
      "train loss:0.9454147211379462\n",
      "train loss:0.8461476253373306\n",
      "train loss:0.6352951016626186\n",
      "train loss:0.7963771627940477\n",
      "train loss:0.9062867545130007\n",
      "train loss:0.8195582270385074\n",
      "train loss:0.7781631310632048\n",
      "train loss:0.814361584750347\n",
      "train loss:0.8543822883872387\n",
      "=== epoch:8, train acc:0.996, test acc:0.994 ===\n",
      "train loss:0.8676614903880955\n",
      "train loss:0.9000921511758836\n",
      "train loss:0.9358769267053048\n",
      "train loss:0.7616057193991372\n",
      "train loss:0.8702179073588475\n",
      "train loss:1.0267530165009295\n",
      "train loss:0.8395894455649627\n",
      "train loss:0.7920346496267905\n",
      "train loss:0.9703627698920334\n",
      "train loss:0.8761108594487986\n",
      "train loss:0.9051825544312865\n",
      "train loss:0.7956974956925825\n",
      "train loss:0.9841526590745926\n",
      "train loss:0.9829578206790061\n",
      "train loss:0.7456400022372304\n",
      "train loss:0.956227566282928\n",
      "train loss:0.9516272980282975\n",
      "train loss:0.8291934790737514\n",
      "train loss:0.9226104014676251\n",
      "train loss:0.7960560671865606\n",
      "train loss:0.9102208428020646\n",
      "train loss:0.8435319124184413\n",
      "train loss:0.982751469453204\n",
      "train loss:0.8950466454316836\n",
      "train loss:0.9954367216406684\n",
      "train loss:1.0003532385103049\n",
      "train loss:0.9276329926356454\n",
      "train loss:1.0304840982959698\n",
      "train loss:0.8270272565579359\n",
      "train loss:1.1151155490056492\n",
      "train loss:0.8172906320081413\n",
      "train loss:0.7842076332123885\n",
      "train loss:0.9875995581935413\n",
      "train loss:0.9121110599483595\n",
      "train loss:0.7646444455712167\n",
      "train loss:0.8064174595943006\n",
      "train loss:0.9749959163756173\n",
      "train loss:1.007661637828406\n",
      "train loss:1.0074704919320725\n",
      "train loss:0.9407833024868779\n",
      "train loss:0.816210057931534\n",
      "train loss:0.8089003555764127\n",
      "train loss:0.7499435811104966\n",
      "train loss:1.014354081367999\n",
      "train loss:0.8813622203889646\n",
      "train loss:0.8419373851947014\n",
      "train loss:0.7667328019177415\n",
      "train loss:1.0205766591795227\n",
      "train loss:1.0216741295275176\n",
      "train loss:0.8980738571508153\n",
      "train loss:0.8643982866014828\n",
      "train loss:0.8945944394204983\n",
      "train loss:0.8005431980215438\n",
      "train loss:0.8390981837311958\n",
      "train loss:0.8902558167666085\n",
      "train loss:0.8986506153412125\n",
      "train loss:0.861167800819388\n",
      "train loss:1.0782722030394953\n",
      "train loss:0.7763401211820559\n",
      "train loss:0.6355515239663722\n",
      "train loss:0.7236798548226521\n",
      "train loss:0.9351888181827128\n",
      "train loss:1.078292481599174\n",
      "train loss:0.9197304554508355\n",
      "train loss:0.8235456051148217\n",
      "train loss:0.8801505065030866\n",
      "train loss:0.9465851709497543\n",
      "train loss:1.0682996198195003\n",
      "train loss:0.9278930902493758\n",
      "train loss:0.8673136145812077\n",
      "train loss:0.7748227483523467\n",
      "train loss:0.9688740672479327\n",
      "train loss:0.8748443526454508\n",
      "train loss:0.8836619080750647\n",
      "train loss:0.9959707019600451\n",
      "train loss:0.7915764171072669\n",
      "train loss:1.0268546126217672\n",
      "train loss:0.9309557194267788\n",
      "train loss:0.7784512874400619\n",
      "train loss:0.9479866259775964\n",
      "train loss:0.8975213108701958\n",
      "train loss:0.7262004029873848\n",
      "train loss:1.0826332555499365\n",
      "train loss:1.0241860029218268\n",
      "train loss:0.9455158483608482\n",
      "train loss:0.8756695245965489\n",
      "train loss:0.7969226122885644\n",
      "train loss:0.9126521238754964\n",
      "train loss:0.7985971390161136\n",
      "train loss:0.7988052206857889\n",
      "train loss:1.154610614873724\n",
      "train loss:0.9647351402477307\n",
      "train loss:0.8860353693804729\n",
      "train loss:0.6110992882466129\n",
      "train loss:0.9874744005232095\n",
      "train loss:0.9637780979827779\n",
      "train loss:0.848416898671713\n",
      "train loss:1.0815126223759097\n",
      "train loss:0.8397849855136154\n",
      "train loss:0.8090159747872019\n",
      "train loss:0.8805000995997105\n",
      "train loss:0.7593923053092305\n",
      "train loss:0.8047214941114277\n",
      "train loss:0.8644753083051859\n",
      "train loss:0.7720369029673155\n",
      "train loss:0.7833917187560023\n",
      "train loss:0.9690718782920064\n",
      "train loss:0.7938916038884762\n",
      "train loss:0.9270993765783774\n",
      "train loss:0.856076016957566\n",
      "train loss:0.9631183400274366\n",
      "train loss:0.9664536860422425\n",
      "train loss:0.8698979967978615\n",
      "train loss:0.8297293122810098\n",
      "train loss:0.8823429887878335\n",
      "train loss:0.9380787308177241\n",
      "train loss:0.8712914456843012\n",
      "train loss:0.8174652070560523\n",
      "train loss:0.810939935409706\n",
      "train loss:0.854778387363891\n",
      "train loss:0.8347843833969196\n",
      "train loss:1.021018243063817\n",
      "train loss:0.9827132973445678\n",
      "train loss:0.7871318655760515\n",
      "train loss:0.8811217286195852\n",
      "train loss:0.8245105304949791\n",
      "train loss:0.7899056908194008\n",
      "train loss:0.794665227470784\n",
      "train loss:0.8163251965794488\n",
      "train loss:0.9459176707220986\n",
      "train loss:0.8085733430177133\n",
      "train loss:0.8992569453456247\n",
      "train loss:0.7333087261815568\n",
      "train loss:0.9301679114632934\n",
      "train loss:0.816481710234602\n",
      "train loss:0.8158557811372903\n",
      "train loss:0.9151313702054324\n",
      "train loss:0.8669702619622458\n",
      "train loss:0.7436728278241458\n",
      "train loss:1.054779384332065\n",
      "train loss:0.9446943291773425\n",
      "train loss:0.988563276965772\n",
      "train loss:1.0548922173857047\n",
      "train loss:0.867873370519376\n",
      "train loss:0.8329297495460698\n",
      "train loss:0.8894122900620173\n",
      "train loss:0.9008689516113374\n",
      "train loss:0.9265839697271505\n",
      "train loss:1.026686170353497\n",
      "train loss:0.8364439262641169\n",
      "train loss:0.9164623078312123\n",
      "train loss:0.9086543777800676\n",
      "train loss:0.9048406624341848\n",
      "train loss:0.7711462759900123\n",
      "train loss:0.9330032234290933\n",
      "train loss:0.8761673762265819\n",
      "train loss:0.8962851053486317\n",
      "train loss:0.7812512750922967\n",
      "train loss:0.7923958257357203\n",
      "train loss:0.8602403421173299\n",
      "train loss:0.8221078264988371\n",
      "train loss:0.8313937441052289\n",
      "train loss:0.8610082142347768\n",
      "train loss:0.9002833185027616\n",
      "train loss:0.8795159251129964\n",
      "train loss:0.8282525287195655\n",
      "train loss:0.7798189256065636\n",
      "train loss:0.8323146852545794\n",
      "train loss:0.9911394687434778\n",
      "train loss:0.9625740884780395\n",
      "train loss:0.7482516688394689\n",
      "train loss:0.7361081448960834\n",
      "train loss:0.907665857871023\n",
      "train loss:0.8728795674354859\n",
      "train loss:0.8770473905876426\n",
      "train loss:1.0910250484568371\n",
      "train loss:0.8807539289406955\n",
      "train loss:0.8812202158593544\n",
      "train loss:0.9644635021650497\n",
      "train loss:0.891320591496791\n",
      "train loss:0.8610987042378734\n",
      "train loss:0.8838335953862131\n",
      "train loss:0.8175524239557904\n",
      "train loss:0.8027616495844709\n",
      "train loss:0.8577860026974\n",
      "train loss:0.7203639797014318\n",
      "train loss:0.9310430375781275\n",
      "train loss:0.876819371523406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.7847507451427397\n",
      "train loss:0.8457538001608288\n",
      "train loss:0.9328356220877795\n",
      "train loss:0.8781407756730932\n",
      "train loss:0.8690045573441348\n",
      "train loss:0.8234751314264556\n",
      "train loss:0.817692624613949\n",
      "train loss:0.9496596393381839\n",
      "train loss:0.864080523397799\n",
      "train loss:0.9928286375620985\n",
      "train loss:0.8105628042454532\n",
      "train loss:0.9433090343639933\n",
      "train loss:0.7949449751978382\n",
      "train loss:0.7663903090463898\n",
      "train loss:0.8246392663675566\n",
      "train loss:0.7755646319499757\n",
      "train loss:0.9468908649385986\n",
      "train loss:0.8399207989788323\n",
      "train loss:0.8769878276962261\n",
      "train loss:0.8845010918879066\n",
      "train loss:0.8057458820505525\n",
      "train loss:0.7468905338791398\n",
      "train loss:0.7582535326221914\n",
      "train loss:0.8850752543565609\n",
      "train loss:0.7621312474461096\n",
      "train loss:0.7490954527816253\n",
      "train loss:0.8425984770318868\n",
      "train loss:0.9925486524689\n",
      "train loss:0.9628898492887504\n",
      "train loss:0.874874974931711\n",
      "train loss:1.0869913711315016\n",
      "train loss:0.7207295597206722\n",
      "train loss:0.8443233815545251\n",
      "train loss:0.9207662214377167\n",
      "train loss:1.0943185841554381\n",
      "train loss:0.9677260965857467\n",
      "train loss:0.8478930885199933\n",
      "train loss:0.8750960210184222\n",
      "train loss:0.8339083890451425\n",
      "train loss:0.9005532063166677\n",
      "train loss:0.8790461667735012\n",
      "train loss:0.8216895007139239\n",
      "train loss:0.8860481474573237\n",
      "train loss:0.9183532331785996\n",
      "train loss:0.9595103168314083\n",
      "train loss:0.8382361844804349\n",
      "train loss:0.9065275673618062\n",
      "train loss:1.0977555406572852\n",
      "train loss:0.9096763555217116\n",
      "train loss:0.7806018523913145\n",
      "train loss:0.8190205164018672\n",
      "train loss:0.8224636992179768\n",
      "train loss:1.0677180903654135\n",
      "train loss:0.9121733942334848\n",
      "train loss:0.7666827472714373\n",
      "train loss:0.7941369358743401\n",
      "train loss:0.9302944080902251\n",
      "train loss:0.9174104006608446\n",
      "train loss:0.9039402541131959\n",
      "train loss:0.8530915278752846\n",
      "train loss:0.698315375444847\n",
      "train loss:0.9888987748834566\n",
      "train loss:0.8397609266378946\n",
      "train loss:0.6888764300945556\n",
      "train loss:0.6935855795596355\n",
      "train loss:0.9941227665855439\n",
      "train loss:0.9046559601674735\n",
      "train loss:0.9876969549501027\n",
      "train loss:0.8833550883834116\n",
      "train loss:0.9259795214779699\n",
      "train loss:0.8175724388443725\n",
      "train loss:0.8390391246762061\n",
      "train loss:0.8270175307111868\n",
      "train loss:0.8588175311862329\n",
      "train loss:0.9197560818927731\n",
      "train loss:0.8042632088692941\n",
      "train loss:1.0667084071626223\n",
      "train loss:1.021396950042252\n",
      "train loss:0.8353004636354504\n",
      "train loss:0.8312095356230742\n",
      "train loss:0.8131184092147737\n",
      "train loss:0.9734329803363923\n",
      "train loss:0.8270062105883907\n",
      "train loss:1.0128259538545006\n",
      "train loss:0.8819869258075747\n",
      "train loss:1.0595002900940613\n",
      "train loss:1.08486685595852\n",
      "train loss:0.8597148878897255\n",
      "train loss:1.0091171988583938\n",
      "train loss:0.9429186436224876\n",
      "train loss:0.8911267230930856\n",
      "train loss:0.8308786534354066\n",
      "train loss:0.9479529987927038\n",
      "train loss:0.7724884855601682\n",
      "train loss:1.2253150990956738\n",
      "train loss:0.9240617721645872\n",
      "train loss:1.0619608403092295\n",
      "train loss:1.0183296050505233\n",
      "train loss:1.015875384741562\n",
      "train loss:0.9536077555704685\n",
      "train loss:0.912351780193324\n",
      "train loss:0.8965568020424025\n",
      "train loss:0.9711097949037706\n",
      "train loss:0.8590926718215063\n",
      "train loss:1.0536757490520656\n",
      "train loss:0.8387176782098171\n",
      "train loss:0.9382539403347715\n",
      "train loss:0.9594973823872418\n",
      "train loss:0.9202484220270531\n",
      "train loss:0.9953244130105067\n",
      "train loss:0.8992959126630707\n",
      "train loss:0.906537640878251\n",
      "train loss:1.0060095364692416\n",
      "train loss:0.9383636539504908\n",
      "train loss:0.8173394910473177\n",
      "train loss:0.8817676273372208\n",
      "train loss:0.8550275704351946\n",
      "train loss:1.0629770472250002\n",
      "train loss:1.0267898917631444\n",
      "train loss:0.7590751422677975\n",
      "train loss:0.7390172235293667\n",
      "train loss:0.8793650049837263\n",
      "train loss:0.8575262245675028\n",
      "train loss:0.9659812167232664\n",
      "train loss:0.7511480136973809\n",
      "train loss:0.9609783352236735\n",
      "train loss:1.0562243985017963\n",
      "train loss:0.8936709014621627\n",
      "train loss:0.939910251960102\n",
      "train loss:0.8377376078460085\n",
      "train loss:1.0382911585690753\n",
      "train loss:1.0162739905685227\n",
      "train loss:0.8115543406259484\n",
      "train loss:1.023437883654455\n",
      "train loss:0.886583776864128\n",
      "train loss:0.7741201601242403\n",
      "train loss:0.8281444649062515\n",
      "train loss:0.8763477667883639\n",
      "train loss:0.6890498294342601\n",
      "train loss:0.8880273329476028\n",
      "train loss:0.8506090822915285\n",
      "train loss:0.9607048980517818\n",
      "train loss:1.01503246904544\n",
      "train loss:0.8072046990616939\n",
      "train loss:0.8427404791113058\n",
      "train loss:0.7298368864922878\n",
      "train loss:0.9326454369027202\n",
      "train loss:0.9679097817318285\n",
      "train loss:1.1306877922389365\n",
      "train loss:0.9047964811920969\n",
      "train loss:1.0380444817303454\n",
      "train loss:0.915709396258745\n",
      "train loss:0.8317913434128229\n",
      "train loss:1.0025268953040203\n",
      "train loss:1.0139917725175793\n",
      "train loss:0.9696700726076537\n",
      "train loss:0.7340424685156363\n",
      "train loss:0.8982448403712607\n",
      "train loss:0.8848347214767784\n",
      "train loss:0.7708769141838672\n",
      "train loss:0.7298294984261947\n",
      "train loss:0.8876705881907871\n",
      "train loss:0.8406528668046259\n",
      "train loss:1.0453678869730039\n",
      "train loss:0.8259973806402262\n",
      "train loss:0.8509671594335145\n",
      "train loss:0.8431361172365303\n",
      "train loss:0.8892225854097355\n",
      "train loss:0.8900306624057116\n",
      "train loss:0.8828549253368233\n",
      "train loss:0.7639270421958939\n",
      "train loss:0.8466773611678522\n",
      "train loss:0.9343998699551025\n",
      "train loss:0.9954315393932275\n",
      "train loss:0.7549067005054647\n",
      "train loss:0.8212593665944269\n",
      "train loss:1.000366954405579\n",
      "train loss:1.04957078134159\n",
      "train loss:0.8322191917105751\n",
      "train loss:0.9864747246025263\n",
      "train loss:0.9407382771452126\n",
      "train loss:0.8452527004965592\n",
      "train loss:0.8926654965071021\n",
      "train loss:0.9971552669524477\n",
      "train loss:0.7417013387668568\n",
      "train loss:0.9347919679041259\n",
      "train loss:0.8114484064333513\n",
      "train loss:0.9505432991076789\n",
      "train loss:1.0181591307062188\n",
      "train loss:0.8471753933000145\n",
      "train loss:0.9523885415420823\n",
      "train loss:0.9013366120006415\n",
      "train loss:0.9047250364166903\n",
      "train loss:0.8570601773799271\n",
      "train loss:0.9180730895547577\n",
      "train loss:0.896029304795851\n",
      "train loss:0.874969728576443\n",
      "train loss:0.9559655256683988\n",
      "train loss:0.8946404060880415\n",
      "train loss:0.793284585976323\n",
      "train loss:0.7996533627685524\n",
      "train loss:0.932832927086575\n",
      "train loss:0.7637423643340102\n",
      "train loss:0.7278943256436495\n",
      "train loss:0.9379636539526846\n",
      "train loss:0.96300520462438\n",
      "train loss:0.8606522076583285\n",
      "train loss:0.9616994827720999\n",
      "train loss:0.8061254206910555\n",
      "train loss:0.7529188296378381\n",
      "train loss:0.7875428446539179\n",
      "train loss:0.8134959742802614\n",
      "train loss:0.7637125142847672\n",
      "train loss:0.9548654766716416\n",
      "train loss:0.9322033618264696\n",
      "train loss:0.7752850764407154\n",
      "train loss:0.9621058864084937\n",
      "train loss:0.9189324183598003\n",
      "train loss:0.9050430017651365\n",
      "train loss:1.0062605026968514\n",
      "train loss:0.9050913192348109\n",
      "train loss:1.0829963218321392\n",
      "train loss:0.8691116201939217\n",
      "train loss:0.8252309300713434\n",
      "train loss:0.897062275404418\n",
      "train loss:0.8116087422502409\n",
      "train loss:0.8763804225061453\n",
      "train loss:0.7387022021412384\n",
      "train loss:0.9016068498188702\n",
      "train loss:0.7793181911896256\n",
      "train loss:0.953327276159493\n",
      "train loss:0.9863238664826488\n",
      "train loss:0.7854697263200573\n",
      "train loss:0.815804608718046\n",
      "train loss:0.7072334434377461\n",
      "train loss:0.7711152485678887\n",
      "train loss:0.8937333680949809\n",
      "train loss:0.8616236889997895\n",
      "train loss:0.9439704061889218\n",
      "train loss:0.8934938184825283\n",
      "train loss:0.8968471426151525\n",
      "train loss:0.9975480420929813\n",
      "train loss:0.9780592261754818\n",
      "train loss:0.801366228534834\n",
      "train loss:1.0638019310382212\n",
      "train loss:0.7126891031599972\n",
      "train loss:0.834106412230766\n",
      "train loss:1.006293354844533\n",
      "train loss:0.8613313465593183\n",
      "train loss:0.8740823404975909\n",
      "train loss:0.941397583198308\n",
      "train loss:0.9018026476570078\n",
      "train loss:0.9029717555933245\n",
      "train loss:0.9160554161351313\n",
      "train loss:0.8315713812470144\n",
      "train loss:1.0572555920642162\n",
      "train loss:0.8637139141745618\n",
      "train loss:1.0043890201394878\n",
      "train loss:0.9598287698841763\n",
      "train loss:0.869652950358622\n",
      "train loss:0.9807019642519778\n",
      "train loss:0.9340296484573462\n",
      "train loss:0.9072702665824959\n",
      "train loss:0.8798239791010402\n",
      "train loss:0.8388499595080638\n",
      "train loss:0.6775740220870261\n",
      "train loss:0.8378544763204056\n",
      "train loss:0.9511026730693907\n",
      "train loss:0.9230207936303533\n",
      "train loss:0.8913766379756537\n",
      "train loss:1.0399503666195884\n",
      "train loss:0.9751359063255471\n",
      "train loss:0.769684579475403\n",
      "train loss:0.9389534594551922\n",
      "train loss:1.0487494217189977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:1.0068100826383057\n",
      "train loss:0.8589893334388341\n",
      "train loss:0.9133242047255165\n",
      "train loss:0.8960366755740781\n",
      "train loss:0.9421715671475853\n",
      "train loss:0.9116152492741623\n",
      "train loss:0.8964962001906475\n",
      "train loss:1.0064936479237416\n",
      "train loss:0.8520770532890991\n",
      "train loss:0.8429103792569022\n",
      "train loss:0.6968439706261151\n",
      "train loss:0.9176427702369121\n",
      "train loss:0.8848167014354883\n",
      "train loss:0.8566419533321544\n",
      "train loss:0.8847954403031908\n",
      "train loss:0.9640315297286887\n",
      "train loss:0.9834988766159352\n",
      "train loss:0.940839918296363\n",
      "train loss:0.8439505433387225\n",
      "train loss:0.9631540577772116\n",
      "train loss:0.8308160232304878\n",
      "train loss:0.7747325424697656\n",
      "train loss:0.8803332651443124\n",
      "train loss:0.8050583650812955\n",
      "train loss:0.9937430516958675\n",
      "train loss:1.0413601581128016\n",
      "train loss:0.9153141237469272\n",
      "train loss:0.9258392838134907\n",
      "train loss:1.0129273407885624\n",
      "train loss:0.8118295787491339\n",
      "train loss:0.7648905452266752\n",
      "train loss:0.9217426061276284\n",
      "train loss:0.9140191879472213\n",
      "train loss:0.7374810930339609\n",
      "train loss:0.807945672768224\n",
      "train loss:0.7318047789738419\n",
      "train loss:0.8228907926175014\n",
      "train loss:0.9309016200236553\n",
      "train loss:0.7981696005300215\n",
      "train loss:1.0593731479815762\n",
      "train loss:0.8337296193953079\n",
      "train loss:0.8331537761973091\n",
      "train loss:0.8169187987995258\n",
      "train loss:0.5486225651556262\n",
      "train loss:0.8995105715651577\n",
      "train loss:0.8993424378440669\n",
      "train loss:0.988138695752035\n",
      "train loss:0.9094554481243583\n",
      "train loss:0.9859195747037419\n",
      "train loss:1.1822170380840493\n",
      "train loss:0.9217839438275159\n",
      "train loss:0.9347839109546651\n",
      "train loss:0.7870697198524357\n",
      "train loss:0.8650909559700959\n",
      "train loss:0.858613046053808\n",
      "train loss:1.0102306662533398\n",
      "train loss:0.8263374862765293\n",
      "train loss:1.0607063704120094\n",
      "train loss:0.9570261181629379\n",
      "train loss:0.9547690464102162\n",
      "train loss:0.9048219483985611\n",
      "train loss:0.783553345071254\n",
      "train loss:0.8316248112169844\n",
      "train loss:0.9212832655215216\n",
      "train loss:0.8671217822087169\n",
      "train loss:0.892756833235611\n",
      "train loss:0.8751588140855024\n",
      "train loss:0.972596658484721\n",
      "train loss:0.8914271073519351\n",
      "train loss:0.8356880125247947\n",
      "train loss:0.985886357237782\n",
      "train loss:0.8216199836325118\n",
      "train loss:0.7633051799059635\n",
      "train loss:0.866567084312331\n",
      "train loss:0.8332792067183376\n",
      "train loss:0.7246411433973892\n",
      "train loss:0.7993464280957956\n",
      "train loss:0.7365811238010355\n",
      "train loss:0.8735438652667199\n",
      "train loss:0.8488918872308049\n",
      "train loss:0.8111143851783703\n",
      "train loss:0.877999833678619\n",
      "train loss:0.7011901677654881\n",
      "train loss:0.9988954733653864\n",
      "train loss:0.9231552824315585\n",
      "train loss:0.9256893246964409\n",
      "train loss:0.8742810697974893\n",
      "train loss:0.9328787921303058\n",
      "train loss:0.9690765222061064\n",
      "train loss:0.8512482067129906\n",
      "train loss:0.9103125916997835\n",
      "train loss:0.9641819565869676\n",
      "train loss:0.8051787954797276\n",
      "train loss:1.031792514982399\n",
      "train loss:0.7985936248508326\n",
      "train loss:0.6966717732247295\n",
      "train loss:1.002650134546935\n",
      "train loss:0.8582090089034072\n",
      "train loss:0.9814478760124616\n",
      "train loss:0.8272183815538923\n",
      "train loss:1.0721826667237546\n",
      "train loss:0.8295201024966274\n",
      "train loss:0.85437173135035\n",
      "train loss:0.7474074488664558\n",
      "train loss:0.95624362029703\n",
      "train loss:0.8371669921895508\n",
      "train loss:1.1047860704228893\n",
      "train loss:0.943171583714856\n",
      "train loss:0.9525596989595226\n",
      "train loss:0.7823276896202421\n",
      "train loss:0.8302552287934104\n",
      "train loss:0.8410903147703107\n",
      "train loss:0.9642360952259126\n",
      "train loss:1.0967550460113535\n",
      "train loss:0.9113126560901389\n",
      "train loss:1.1189760863023914\n",
      "train loss:0.913702850523945\n",
      "train loss:0.7983259377858658\n",
      "train loss:0.7724593913979705\n",
      "train loss:1.0262173066619478\n",
      "train loss:0.9534953238409315\n",
      "train loss:0.7876165752277712\n",
      "train loss:1.027890387972639\n",
      "train loss:0.9013095873612893\n",
      "train loss:0.9061059376267813\n",
      "train loss:0.835281372446746\n",
      "train loss:0.7985022120200941\n",
      "train loss:0.7332617754325743\n",
      "train loss:0.6627841469744875\n",
      "train loss:1.0757282715660414\n",
      "train loss:0.9233282298328033\n",
      "train loss:1.0000708797621445\n",
      "train loss:0.9477680059880401\n",
      "train loss:0.9348198206342748\n",
      "train loss:0.9748266373494053\n",
      "train loss:0.8689951049125031\n",
      "train loss:0.8459861658618102\n",
      "=== epoch:9, train acc:0.995, test acc:0.99 ===\n",
      "train loss:0.8149609955151479\n",
      "train loss:0.9396193363749533\n",
      "train loss:0.9608759463278317\n",
      "train loss:0.9472674590219698\n",
      "train loss:0.9988695856423704\n",
      "train loss:0.7893195514993289\n",
      "train loss:0.8919257059210572\n",
      "train loss:0.8876770209526625\n",
      "train loss:0.7727019967019655\n",
      "train loss:0.9171497754016058\n",
      "train loss:0.877885269726584\n",
      "train loss:0.9293347655306146\n",
      "train loss:1.0947814676580068\n",
      "train loss:0.813008659161422\n",
      "train loss:0.792044816204033\n",
      "train loss:0.9612228861730133\n",
      "train loss:0.8414795948703906\n",
      "train loss:0.9977756439464156\n",
      "train loss:0.7982757216149633\n",
      "train loss:0.9902052555239552\n",
      "train loss:0.7793901028963336\n",
      "train loss:0.9406488997140542\n",
      "train loss:0.9221802055368759\n",
      "train loss:1.0154306013371122\n",
      "train loss:0.8639533463118627\n",
      "train loss:0.8670729313894715\n",
      "train loss:0.8334328832295013\n",
      "train loss:0.8045008579191082\n",
      "train loss:0.9147241686923863\n",
      "train loss:0.8720433248722246\n",
      "train loss:0.9050818158335894\n",
      "train loss:0.972762357967377\n",
      "train loss:0.9809854583007628\n",
      "train loss:0.872810637163377\n",
      "train loss:0.6616878748266078\n",
      "train loss:0.8676543735276218\n",
      "train loss:0.855217268813428\n",
      "train loss:0.6981833250233497\n",
      "train loss:0.7928943763170028\n",
      "train loss:0.8744103592803529\n",
      "train loss:1.0009668248658916\n",
      "train loss:0.9075324182679851\n",
      "train loss:0.9218608554418037\n",
      "train loss:0.9160943907055946\n",
      "train loss:0.9835632902857593\n",
      "train loss:0.7369797359895233\n",
      "train loss:0.9711583743979633\n",
      "train loss:0.9522168221304602\n",
      "train loss:0.8070589571124512\n",
      "train loss:0.8644428212379338\n",
      "train loss:0.9595771172547208\n",
      "train loss:0.7350989762590174\n",
      "train loss:0.7955920620011286\n",
      "train loss:0.7296996785502862\n",
      "train loss:0.8756694866249275\n",
      "train loss:0.7686893249241865\n",
      "train loss:0.8290931262916247\n",
      "train loss:0.8276342721792518\n",
      "train loss:0.8252612625537376\n",
      "train loss:0.8989293598124999\n",
      "train loss:0.9560664862701003\n",
      "train loss:1.0451127887335883\n",
      "train loss:0.8500645499109061\n",
      "train loss:1.0215793484220164\n",
      "train loss:0.935528362392919\n",
      "train loss:0.7850348585908784\n",
      "train loss:1.0212643436823288\n",
      "train loss:0.7432554418031194\n",
      "train loss:0.8020516942380627\n",
      "train loss:0.9869784819767087\n",
      "train loss:0.7805547878070013\n",
      "train loss:0.9424828029619001\n",
      "train loss:0.9109376631511711\n",
      "train loss:0.8554416062309766\n",
      "train loss:0.8272208290623734\n",
      "train loss:0.8484705733113087\n",
      "train loss:0.8562300329711432\n",
      "train loss:0.9511311489194495\n",
      "train loss:1.099115409491642\n",
      "train loss:0.8533156920994629\n",
      "train loss:0.7715209590556771\n",
      "train loss:0.780984257012792\n",
      "train loss:0.9208116314220132\n",
      "train loss:0.8367823025737227\n",
      "train loss:0.9788453758289868\n",
      "train loss:0.8450695621054326\n",
      "train loss:0.842998171960112\n",
      "train loss:0.7746822965361442\n",
      "train loss:0.8421570349398495\n",
      "train loss:0.8747962277889357\n",
      "train loss:0.8869991480846727\n",
      "train loss:0.8506279221311354\n",
      "train loss:0.932688105077806\n",
      "train loss:0.8635234781741414\n",
      "train loss:0.9005180859656886\n",
      "train loss:0.7795856368690854\n",
      "train loss:0.9389663305614298\n",
      "train loss:0.8377908201395298\n",
      "train loss:0.8908925063818716\n",
      "train loss:0.9640021749964076\n",
      "train loss:0.8493925780141558\n",
      "train loss:0.8236732895147518\n",
      "train loss:0.8043582710687959\n",
      "train loss:0.8896768549809579\n",
      "train loss:0.9969695387077645\n",
      "train loss:1.0296801134362186\n",
      "train loss:0.8024036936024921\n",
      "train loss:0.8118521603130288\n",
      "train loss:0.765421470156956\n",
      "train loss:0.705352537188903\n",
      "train loss:0.9123708536241202\n",
      "train loss:1.062117272641806\n",
      "train loss:0.8309571112605606\n",
      "train loss:0.9351328395727236\n",
      "train loss:0.8415563966369827\n",
      "train loss:0.8650816909894492\n",
      "train loss:0.7676042956731677\n",
      "train loss:0.9964047212631741\n",
      "train loss:0.7727714991535036\n",
      "train loss:0.8337552030641399\n",
      "train loss:0.7800076502170712\n",
      "train loss:0.7353182151442924\n",
      "train loss:0.8500783668951722\n",
      "train loss:0.9816307508492682\n",
      "train loss:0.9566604422515281\n",
      "train loss:0.9386540053220184\n",
      "train loss:1.0187743395887103\n",
      "train loss:0.8676746710083778\n",
      "train loss:0.7121917560296543\n",
      "train loss:0.8940454041327189\n",
      "train loss:0.8612493097655647\n",
      "train loss:0.8560093482937619\n",
      "train loss:0.8201268630403792\n",
      "train loss:0.9303585398171513\n",
      "train loss:1.0161325808572612\n",
      "train loss:0.8216680605557615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.9424289119333481\n",
      "train loss:1.0687245475893548\n",
      "train loss:0.7962271975430903\n",
      "train loss:0.7870654098011839\n",
      "train loss:1.0469158283069675\n",
      "train loss:0.7898153838027206\n",
      "train loss:0.8292535681989678\n",
      "train loss:0.9532372123767345\n",
      "train loss:0.775551466953385\n",
      "train loss:0.9131143481562735\n",
      "train loss:0.822150831023379\n",
      "train loss:1.0196805205361748\n",
      "train loss:0.869912805041852\n",
      "train loss:0.9781399783076172\n",
      "train loss:0.7962861845728015\n",
      "train loss:1.0243997748361082\n",
      "train loss:0.7781796316173506\n",
      "train loss:0.7937175902000796\n",
      "train loss:0.9987534993043361\n",
      "train loss:0.8024995414768036\n",
      "train loss:0.7690008870344162\n",
      "train loss:0.6307884942635719\n",
      "train loss:0.8930117402995112\n",
      "train loss:0.9429336834127209\n",
      "train loss:0.9206595005634293\n",
      "train loss:0.8235173358826937\n",
      "train loss:1.023759396691465\n",
      "train loss:0.8811371896367433\n",
      "train loss:0.809441332480412\n",
      "train loss:0.8925619614954301\n",
      "train loss:0.8958212379749699\n",
      "train loss:1.0239023130237639\n",
      "train loss:0.8798212316951424\n",
      "train loss:0.9548963317217897\n",
      "train loss:0.8546045189314977\n",
      "train loss:0.9770238011428093\n",
      "train loss:0.8186394635041964\n",
      "train loss:0.8715916524590638\n",
      "train loss:1.0349652344825315\n",
      "train loss:0.9346494809984459\n",
      "train loss:0.963913230726152\n",
      "train loss:0.9022913926035947\n",
      "train loss:0.9451909216059475\n",
      "train loss:0.8731725570044478\n",
      "train loss:0.7932045339941358\n",
      "train loss:0.9493313345388151\n",
      "train loss:0.8850820052230971\n",
      "train loss:0.9423442880417291\n",
      "train loss:0.7982708645413034\n",
      "train loss:0.7917940483353618\n",
      "train loss:0.844150269369557\n",
      "train loss:0.7447302331429958\n",
      "train loss:0.7933505270882883\n",
      "train loss:0.9523353634163675\n",
      "train loss:1.114826633627954\n",
      "train loss:0.8757497307117866\n",
      "train loss:0.9076665038694164\n",
      "train loss:0.9644623891536592\n",
      "train loss:1.1316224487923738\n",
      "train loss:0.7846595344866776\n",
      "train loss:0.8551764431885214\n",
      "train loss:1.055902351122901\n",
      "train loss:1.097246604424624\n",
      "train loss:0.7722758339387332\n",
      "train loss:0.9514940049416754\n",
      "train loss:0.891228822638097\n",
      "train loss:0.8590365307668175\n",
      "train loss:0.8298038429808052\n",
      "train loss:0.7532182090536478\n",
      "train loss:0.9452873690943742\n",
      "train loss:0.9394720426160797\n",
      "train loss:0.7966136533624072\n",
      "train loss:0.9887661584125528\n",
      "train loss:0.9788276775932256\n",
      "train loss:0.938934529159644\n",
      "train loss:0.9505680375100308\n",
      "train loss:0.9874348953171871\n",
      "train loss:0.787160893794642\n",
      "train loss:0.7757347495457698\n",
      "train loss:0.8634798132101291\n",
      "train loss:0.8859702378745565\n",
      "train loss:0.8521991652777661\n",
      "train loss:0.8952631712633405\n",
      "train loss:0.9691183059825892\n",
      "train loss:0.8364042354400341\n",
      "train loss:1.0081628171986141\n",
      "train loss:0.998718112746164\n",
      "train loss:0.9406159489142499\n",
      "train loss:1.0247869649768029\n",
      "train loss:0.9771500176566559\n",
      "train loss:0.9558850408427135\n",
      "train loss:0.9305248144279882\n",
      "train loss:0.7258505358591162\n",
      "train loss:0.8589621482088343\n",
      "train loss:0.8002209698411968\n",
      "train loss:0.7894393132361133\n",
      "train loss:0.753750764422838\n",
      "train loss:0.9985238060160958\n",
      "train loss:0.8930157335295419\n",
      "train loss:0.9228145916964552\n",
      "train loss:0.948120388026153\n",
      "train loss:0.7953355472023271\n",
      "train loss:0.9972865137190274\n",
      "train loss:0.8088803570382151\n",
      "train loss:0.7687410665768624\n",
      "train loss:0.7847545934908766\n",
      "train loss:0.8323021358397916\n",
      "train loss:0.8003246992756441\n",
      "train loss:0.8909256979084946\n",
      "train loss:0.8624360581011326\n",
      "train loss:0.7647662412833364\n",
      "train loss:1.0061013369054337\n",
      "train loss:0.8781199003709689\n",
      "train loss:0.9211416087863398\n",
      "train loss:0.7969710657487244\n",
      "train loss:0.9045101734700616\n",
      "train loss:0.8263699877494137\n",
      "train loss:0.8482688892459038\n",
      "train loss:0.952424363226537\n",
      "train loss:0.8914996512799149\n",
      "train loss:0.8842034810430409\n",
      "train loss:0.8681385411752277\n",
      "train loss:0.962548394540082\n",
      "train loss:0.8813444451645445\n",
      "train loss:0.9202818855554533\n",
      "train loss:0.9191154396055096\n",
      "train loss:0.8299453065792071\n",
      "train loss:0.9760075814366006\n",
      "train loss:0.9029298093936866\n",
      "train loss:0.8112859501809733\n",
      "train loss:0.7303495218795516\n",
      "train loss:0.8225896512975511\n",
      "train loss:0.8627644499414703\n",
      "train loss:0.7753611648300546\n",
      "train loss:0.7967699149097115\n",
      "train loss:0.727619616241884\n",
      "train loss:0.9105836916265108\n",
      "train loss:0.8214822778181733\n",
      "train loss:0.8254274739690091\n",
      "train loss:0.9734891179266181\n",
      "train loss:0.9881516508862651\n",
      "train loss:1.0583008247748886\n",
      "train loss:0.9645847223577826\n",
      "train loss:0.7109157604829602\n",
      "train loss:0.8421050614897364\n",
      "train loss:0.7891772027554202\n",
      "train loss:0.8506617738414072\n",
      "train loss:0.9543684033965809\n",
      "train loss:1.0209749011872147\n",
      "train loss:0.9408478524310562\n",
      "train loss:0.9554986410732776\n",
      "train loss:0.9777594477980586\n",
      "train loss:0.9278373837236364\n",
      "train loss:0.8296365983678825\n",
      "train loss:0.8798269800311398\n",
      "train loss:0.8478988132151366\n",
      "train loss:0.8308279178990403\n",
      "train loss:0.8550305349525691\n",
      "train loss:0.9521353567257741\n",
      "train loss:0.8138718354749528\n",
      "train loss:0.9016675977061833\n",
      "train loss:0.8320870546373128\n",
      "train loss:0.9921188119418161\n",
      "train loss:0.8425483402577876\n",
      "train loss:0.8826479329726211\n",
      "train loss:0.8963911716636569\n",
      "train loss:0.7828697868325679\n",
      "train loss:0.8800880468189811\n",
      "train loss:0.9091960748334368\n",
      "train loss:0.7574523905315629\n",
      "train loss:0.800830035362399\n",
      "train loss:0.9510241272281188\n",
      "train loss:0.9147122444457796\n",
      "train loss:0.8721209015681599\n",
      "train loss:0.7619750000818941\n",
      "train loss:0.9612512931806075\n",
      "train loss:1.0651545198083245\n",
      "train loss:1.0279759704376144\n",
      "train loss:0.9311629386889885\n",
      "train loss:0.9415026624956582\n",
      "train loss:0.7962806288915023\n",
      "train loss:0.7887105630119278\n",
      "train loss:0.8399965223417197\n",
      "train loss:0.8076267245837866\n",
      "train loss:0.9834714095234334\n",
      "train loss:1.030808525830467\n",
      "train loss:0.7996754892567141\n",
      "train loss:0.694993772521126\n",
      "train loss:0.8455640487725903\n",
      "train loss:0.8397686958791591\n",
      "train loss:0.9747444710239688\n",
      "train loss:0.8335908450189327\n",
      "train loss:0.930810315357819\n",
      "train loss:0.7827549435441676\n",
      "train loss:0.8973408257650243\n",
      "train loss:0.9631777403480425\n",
      "train loss:0.8300672359460819\n",
      "train loss:0.9315893098632211\n",
      "train loss:0.792292990726802\n",
      "train loss:0.9521180464049508\n",
      "train loss:0.9189814439987215\n",
      "train loss:1.079545474541088\n",
      "train loss:1.037790780725951\n",
      "train loss:0.9037590966144374\n",
      "train loss:0.9739774655169401\n",
      "train loss:0.8754552289318583\n",
      "train loss:0.8928887585912905\n",
      "train loss:0.8305337105559222\n",
      "train loss:0.9842919205487318\n",
      "train loss:0.7967784419215387\n",
      "train loss:0.8283897014360564\n",
      "train loss:0.8378899819811946\n",
      "train loss:0.9142374971480055\n",
      "train loss:0.903684694511142\n",
      "train loss:1.0126530782237457\n",
      "train loss:0.8704825784110729\n",
      "train loss:0.8443773444106967\n",
      "train loss:1.0227534292869662\n",
      "train loss:0.8809153814932422\n",
      "train loss:0.969491560114834\n",
      "train loss:0.8461476214167282\n",
      "train loss:0.7825638979351673\n",
      "train loss:1.0177847028898106\n",
      "train loss:0.8855331578599065\n",
      "train loss:0.9380909537834783\n",
      "train loss:0.8841902087457217\n",
      "train loss:0.8054252451523422\n",
      "train loss:0.8830744805115046\n",
      "train loss:0.8582102312802856\n",
      "train loss:0.793101883976493\n",
      "train loss:0.9250348782835164\n",
      "train loss:0.8924828545777518\n",
      "train loss:0.8816974653345983\n",
      "train loss:0.8912624470722419\n",
      "train loss:0.8048619950472969\n",
      "train loss:0.8118018976616566\n",
      "train loss:0.9540180982184908\n",
      "train loss:1.0139946047885313\n",
      "train loss:0.8309889381590553\n",
      "train loss:0.8522744181196694\n",
      "train loss:0.9408043430601358\n",
      "train loss:0.8532962941528922\n",
      "train loss:0.7463038001397961\n",
      "train loss:0.9584870950272051\n",
      "train loss:0.730489491543769\n",
      "train loss:0.8866983972951286\n",
      "train loss:0.687597258258222\n",
      "train loss:0.8706665036935317\n",
      "train loss:0.8946694586260608\n",
      "train loss:1.1476434959436732\n",
      "train loss:0.8745541469860695\n",
      "train loss:0.9088120346084712\n",
      "train loss:1.0189609607907595\n",
      "train loss:0.8533824846133261\n",
      "train loss:0.8967258616655914\n",
      "train loss:0.9197572160955981\n",
      "train loss:0.7633644136846942\n",
      "train loss:0.8918425277549653\n",
      "train loss:0.9298782738981153\n",
      "train loss:0.8058433355023159\n",
      "train loss:1.034732712546473\n",
      "train loss:0.86631151393873\n",
      "train loss:0.8534797961387786\n",
      "train loss:1.0045639468924934\n",
      "train loss:0.9276595793154269\n",
      "train loss:0.9601431577703775\n",
      "train loss:0.9508827276632965\n",
      "train loss:0.9766395107824062\n",
      "train loss:0.849905701312253\n",
      "train loss:0.8394270584914978\n",
      "train loss:0.9979572166318418\n",
      "train loss:0.907573305365384\n",
      "train loss:0.8305753521375631\n",
      "train loss:0.9368945949570295\n",
      "train loss:0.8613845800194261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.91094303649166\n",
      "train loss:0.8752994649770274\n",
      "train loss:0.943279642156476\n",
      "train loss:0.981527669210558\n",
      "train loss:0.8094740085913803\n",
      "train loss:0.8759305917676364\n",
      "train loss:0.76231176847117\n",
      "train loss:0.8205431248754909\n",
      "train loss:0.9733733902853818\n",
      "train loss:0.8263368873635376\n",
      "train loss:0.9248510042652868\n",
      "train loss:0.9359834768610459\n",
      "train loss:0.8278342959030849\n",
      "train loss:1.0461109151046342\n",
      "train loss:0.8721161733989944\n",
      "train loss:0.9221000418315372\n",
      "train loss:0.9177859316188919\n",
      "train loss:0.860781561217993\n",
      "train loss:0.8066721769271973\n",
      "train loss:1.0959586661446379\n",
      "train loss:0.8551679960214652\n",
      "train loss:0.6937874507098826\n",
      "train loss:0.8315982932959568\n",
      "train loss:0.8822888865072076\n",
      "train loss:0.7795219170233936\n",
      "train loss:1.0354943971684114\n",
      "train loss:1.0414001290714316\n",
      "train loss:1.0872270331295417\n",
      "train loss:0.9678742855187614\n",
      "train loss:0.9313890473534603\n",
      "train loss:1.075552814852405\n",
      "train loss:0.865426068471948\n",
      "train loss:0.8571035726775093\n",
      "train loss:0.7939173297673519\n",
      "train loss:0.9140974776729557\n",
      "train loss:0.981073685236391\n",
      "train loss:0.9596689984506941\n",
      "train loss:0.9570730416795381\n",
      "train loss:0.831619941335279\n",
      "train loss:0.8433405325926544\n",
      "train loss:0.9331377551813287\n",
      "train loss:0.9554338247269739\n",
      "train loss:0.8980501611737023\n",
      "train loss:0.9284911333423215\n",
      "train loss:0.8154598321576044\n",
      "train loss:0.8416889216384013\n",
      "train loss:0.9780767378504668\n",
      "train loss:0.7957293967134352\n",
      "train loss:0.8680986078746541\n",
      "train loss:0.8014058977056935\n",
      "train loss:0.8840789164784033\n",
      "train loss:0.8905625730333869\n",
      "train loss:0.9131212768879778\n",
      "train loss:0.9271026194260185\n",
      "train loss:0.9849336590692171\n",
      "train loss:0.867666101492352\n",
      "train loss:1.0065622114122301\n",
      "train loss:0.9715723849621212\n",
      "train loss:0.9810003972749369\n",
      "train loss:0.9740178844389547\n",
      "train loss:0.998133484392538\n",
      "train loss:0.8968320506546955\n",
      "train loss:0.9036788081993664\n",
      "train loss:0.8706862270277924\n",
      "train loss:0.8415110377791771\n",
      "train loss:0.792086564630627\n",
      "train loss:0.9474069411692492\n",
      "train loss:0.9411657055548649\n",
      "train loss:0.935829354163066\n",
      "train loss:0.8427523640480201\n",
      "train loss:0.8779323003104935\n",
      "train loss:0.9702644714499375\n",
      "train loss:0.7604735814457196\n",
      "train loss:0.8625553280394749\n",
      "train loss:0.8413412463968776\n",
      "train loss:0.835952449958478\n",
      "train loss:0.9240491031765353\n",
      "train loss:0.7393762880951692\n",
      "train loss:0.7993359369185336\n",
      "train loss:0.8897599317453738\n",
      "train loss:0.8320227563761958\n",
      "train loss:0.8992649810390049\n",
      "train loss:0.9842620712978315\n",
      "train loss:0.8126600562366688\n",
      "train loss:0.8490309132646614\n",
      "train loss:0.9604609418678111\n",
      "train loss:0.7812503579796319\n",
      "train loss:0.8490145267852899\n",
      "train loss:0.782283758964375\n",
      "train loss:0.8912910412073708\n",
      "train loss:0.8643925637399417\n",
      "train loss:0.9560069895684069\n",
      "train loss:0.8642221644650602\n",
      "train loss:0.873998729814766\n",
      "train loss:0.9880691731985712\n",
      "train loss:0.8436788461864657\n",
      "train loss:1.1025087667126383\n",
      "train loss:0.8003023787001817\n",
      "train loss:0.99301408108564\n",
      "train loss:0.6910001646947868\n",
      "train loss:0.8032091968362196\n",
      "train loss:0.9999139264773302\n",
      "train loss:0.800899549081073\n",
      "train loss:0.8583799347856264\n",
      "train loss:0.9517710191356475\n",
      "train loss:0.9473084209796432\n",
      "train loss:0.9893985773418826\n",
      "train loss:0.9353277831604262\n",
      "train loss:1.1483704150628913\n",
      "train loss:0.8442048662853803\n",
      "train loss:0.9371147209772759\n",
      "train loss:0.9259954544779767\n",
      "train loss:0.7187534882224262\n",
      "train loss:0.8679150628794698\n",
      "train loss:1.0042360738495273\n",
      "train loss:0.9638460441876906\n",
      "train loss:0.8164666672897524\n",
      "train loss:0.9122662754051503\n",
      "train loss:0.7840121086259387\n",
      "train loss:0.9315674309539809\n",
      "train loss:0.940092807696081\n",
      "train loss:0.9044220704851925\n",
      "train loss:0.8319402460578265\n",
      "train loss:0.8466450886225623\n",
      "train loss:0.8672450985930165\n",
      "train loss:0.9542612449289106\n",
      "train loss:0.929229651571323\n",
      "train loss:0.8102438786207131\n",
      "train loss:0.8824893241650826\n",
      "train loss:1.0786602934170122\n",
      "train loss:0.7994258053389448\n",
      "train loss:0.8812741142313009\n",
      "train loss:0.7265542858140843\n",
      "train loss:0.988320544192093\n",
      "train loss:0.9004839034894674\n",
      "train loss:0.9894824575442869\n",
      "train loss:0.8848421304533385\n",
      "train loss:0.7456570450791088\n",
      "train loss:0.8105725872087811\n",
      "train loss:0.9335314575238166\n",
      "train loss:0.8420076810607833\n",
      "train loss:0.9460644266228626\n",
      "train loss:0.8515844536904023\n",
      "train loss:0.8692616644544473\n",
      "train loss:1.0064435707222348\n",
      "train loss:1.0497646657283342\n",
      "train loss:0.8579845316728424\n",
      "train loss:0.8083701009869597\n",
      "train loss:0.9280282825679906\n",
      "train loss:0.9243450531893115\n",
      "train loss:0.8420400435722557\n",
      "train loss:1.0157324194566408\n",
      "train loss:0.8689520686231184\n",
      "train loss:0.9327249837295356\n",
      "train loss:0.8972619027590356\n",
      "train loss:0.8851475853034573\n",
      "train loss:0.7585300273705858\n",
      "train loss:0.9431159958619169\n",
      "train loss:0.8028665464639075\n",
      "train loss:0.8652951756949243\n",
      "train loss:0.7385555902228973\n",
      "train loss:0.791775438248856\n",
      "train loss:0.8165058568247793\n",
      "train loss:0.8893995905810144\n",
      "train loss:0.9775430164175845\n",
      "train loss:0.9989918194701208\n",
      "train loss:0.9312211531052706\n",
      "train loss:0.8005632964149021\n",
      "train loss:1.1361310159958273\n",
      "train loss:0.9229794496133208\n",
      "train loss:0.8971548033642872\n",
      "train loss:0.9054133636155953\n",
      "train loss:0.9069926918867705\n",
      "train loss:0.9626771852121335\n",
      "train loss:0.8934180015181933\n",
      "train loss:0.9483358002243117\n",
      "train loss:0.950831855416983\n",
      "train loss:0.7631047910219003\n",
      "train loss:0.7799298061915851\n",
      "train loss:0.7483263215855475\n",
      "train loss:1.136987001034415\n",
      "train loss:0.9128890248344439\n",
      "train loss:0.8208988043709223\n",
      "train loss:0.899834102396856\n",
      "train loss:0.7729334456055681\n",
      "train loss:0.877432471015039\n",
      "train loss:0.8719306699488656\n",
      "train loss:0.7192315176314683\n",
      "train loss:0.8332580677227142\n",
      "=== epoch:10, train acc:0.994, test acc:0.99 ===\n",
      "train loss:0.820961948559281\n",
      "train loss:0.8893793779305796\n",
      "train loss:0.9074643308024777\n",
      "train loss:1.046156599238809\n",
      "train loss:0.8431316452362004\n",
      "train loss:0.8428383732168204\n",
      "train loss:0.8519780233414356\n",
      "train loss:0.6609181639830976\n",
      "train loss:0.8618829194217362\n",
      "train loss:0.9473770599371345\n",
      "train loss:0.6868736375310007\n",
      "train loss:0.8498076539640668\n",
      "train loss:0.9830837403235162\n",
      "train loss:0.9196376072780139\n",
      "train loss:0.9902289734590791\n",
      "train loss:0.8877039324871068\n",
      "train loss:0.8642683719351968\n",
      "train loss:0.8105012257733375\n",
      "train loss:0.8132863525958023\n",
      "train loss:0.9590276271065824\n",
      "train loss:0.9732089447225392\n",
      "train loss:0.8352855915601236\n",
      "train loss:1.186304460995179\n",
      "train loss:0.9469529924774462\n",
      "train loss:0.7774061101241786\n",
      "train loss:0.8123619978171491\n",
      "train loss:0.8626649087607932\n",
      "train loss:0.8331698560424552\n",
      "train loss:0.8474643985144639\n",
      "train loss:0.8100606753131109\n",
      "train loss:0.8650963450310875\n",
      "train loss:0.8246715971904804\n",
      "train loss:0.9864050934825969\n",
      "train loss:0.911639209521462\n",
      "train loss:0.9143928209837239\n",
      "train loss:0.8867569631873464\n",
      "train loss:0.8594742399431072\n",
      "train loss:0.77609107109688\n",
      "train loss:0.6590510545725412\n",
      "train loss:0.8998485523766939\n",
      "train loss:0.8851482060928805\n",
      "train loss:0.8464486759451962\n",
      "train loss:0.8124619986027996\n",
      "train loss:0.9004448848282297\n",
      "train loss:0.8994265836433378\n",
      "train loss:0.7750533035316667\n",
      "train loss:0.9777326202011817\n",
      "train loss:0.7376271638971791\n",
      "train loss:0.8269754961730394\n",
      "train loss:0.9586588211312652\n",
      "train loss:0.7994785372404103\n",
      "train loss:0.9321073436047921\n",
      "train loss:0.8810614682176516\n",
      "train loss:0.918384782388384\n",
      "train loss:0.7848425224635253\n",
      "train loss:0.8384679195953586\n",
      "train loss:0.7839186109104717\n",
      "train loss:0.8034089238175548\n",
      "train loss:0.736532763346534\n",
      "train loss:0.7124531100152792\n",
      "train loss:0.8677790439179353\n",
      "train loss:0.802512174237259\n",
      "train loss:0.8820161875444658\n",
      "train loss:0.8799477754354862\n",
      "train loss:0.8055707285603417\n",
      "train loss:0.7238226975985022\n",
      "train loss:0.9813264440916625\n",
      "train loss:0.9059156005737014\n",
      "train loss:1.1022476109494868\n",
      "train loss:0.9845148375579246\n",
      "train loss:0.6393741630093885\n",
      "train loss:0.841710136944138\n",
      "train loss:0.9174851094015124\n",
      "train loss:0.9087495750988336\n",
      "train loss:0.7650373471316122\n",
      "train loss:0.9582222383137186\n",
      "train loss:0.9102324693722177\n",
      "train loss:0.9124435780898114\n",
      "train loss:0.7604906350109397\n",
      "train loss:0.8524360553402082\n",
      "train loss:0.8017792104414896\n",
      "train loss:0.7464635563951662\n",
      "train loss:0.8090640395347151\n",
      "train loss:0.7550634077304929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.9134794230992163\n",
      "train loss:0.9361335797528797\n",
      "train loss:0.8432402836149823\n",
      "train loss:0.7408613825659751\n",
      "train loss:0.8137875051945113\n",
      "train loss:0.9673407150757026\n",
      "train loss:1.0009688039268683\n",
      "train loss:0.8282784419262472\n",
      "train loss:0.8138759667146234\n",
      "train loss:0.8617083022181905\n",
      "train loss:0.8392450891752585\n",
      "train loss:0.8583878437901403\n",
      "train loss:0.9781100295460665\n",
      "train loss:0.8452131863146412\n",
      "train loss:0.9464496188707483\n",
      "train loss:0.9798494695369558\n",
      "train loss:0.9949773709705049\n",
      "train loss:0.8486311827941424\n",
      "train loss:0.7197692526664542\n",
      "train loss:0.7974198049949455\n",
      "train loss:0.9701691773825764\n",
      "train loss:0.8749831884603683\n",
      "train loss:0.8205848668950959\n",
      "train loss:0.9293188316723279\n",
      "train loss:1.0605910988634466\n",
      "train loss:0.8996169452346262\n",
      "train loss:0.8595230378127755\n",
      "train loss:0.9350612864877617\n",
      "train loss:0.907653748893611\n",
      "train loss:0.9216660098287907\n",
      "train loss:0.8854530478520115\n",
      "train loss:0.9450370171829653\n",
      "train loss:0.8486612586613446\n",
      "train loss:0.7688857247349269\n",
      "train loss:1.0948660384552493\n",
      "train loss:0.7691043034595744\n",
      "train loss:0.8591145098725383\n",
      "train loss:0.9199960155624278\n",
      "train loss:0.8121450127559503\n",
      "train loss:0.8161241453279588\n",
      "train loss:0.8524235303529695\n",
      "train loss:0.8706373321027343\n",
      "train loss:0.9367365237784291\n",
      "train loss:0.927110877412533\n",
      "train loss:0.9249946247885302\n",
      "train loss:0.8763146457878292\n",
      "train loss:0.9462121952395987\n",
      "train loss:0.8094953562240793\n",
      "train loss:0.8508870714676281\n",
      "train loss:0.907249737404722\n",
      "train loss:1.0308244618322044\n",
      "train loss:0.9051592764277295\n",
      "train loss:0.7264136535568884\n",
      "train loss:0.8542209385468478\n",
      "train loss:0.6264745968311994\n",
      "train loss:0.8034450743960597\n",
      "train loss:0.8981656892352993\n",
      "train loss:0.9798228352484267\n",
      "train loss:1.1423144673774681\n",
      "train loss:0.8179392050988057\n",
      "train loss:0.8097154803968643\n",
      "train loss:0.9117066082351196\n",
      "train loss:0.8878157143156976\n",
      "train loss:0.8076682850316349\n",
      "train loss:0.8920542437612504\n",
      "train loss:0.8689560747003031\n",
      "train loss:1.0972436943071668\n",
      "train loss:0.912032973800661\n",
      "train loss:0.7918861895799166\n",
      "train loss:0.9417750079103879\n",
      "train loss:0.7936117069801977\n",
      "train loss:1.0015424404971693\n",
      "train loss:1.0268365159295454\n",
      "train loss:0.9308871184119528\n",
      "train loss:0.9407984813535968\n",
      "train loss:0.8762574110669874\n",
      "train loss:0.8897578671196049\n",
      "train loss:0.9279348460310082\n",
      "train loss:0.7901204282171311\n",
      "train loss:0.7507881679129942\n",
      "train loss:1.0298295611513155\n",
      "train loss:0.8339006391458753\n",
      "train loss:0.830193347372859\n",
      "train loss:0.9210799884189265\n",
      "train loss:0.8137096377010448\n",
      "train loss:0.8757944480391799\n",
      "train loss:0.7141599522290895\n",
      "train loss:0.9137177189487883\n",
      "train loss:0.8690165287701032\n",
      "train loss:0.9788597386897152\n",
      "train loss:0.7950535104449279\n",
      "train loss:0.9266334046360417\n",
      "train loss:0.9949528094893207\n",
      "train loss:0.8565227439514507\n",
      "train loss:0.9078711586875147\n",
      "train loss:0.8336753295041096\n",
      "train loss:0.8380424896011521\n",
      "train loss:0.934548442587091\n",
      "train loss:0.9424072552352412\n",
      "train loss:0.7463881445038352\n",
      "train loss:0.8253889066296562\n",
      "train loss:1.0220604538743923\n",
      "train loss:0.902450140471422\n",
      "train loss:1.064694583569032\n",
      "train loss:0.8201217696843167\n",
      "train loss:0.899270944981007\n",
      "train loss:0.9393958229632459\n",
      "train loss:0.9011022676541152\n",
      "train loss:0.8656872523478927\n",
      "train loss:0.9934857218114501\n",
      "train loss:0.7713664716460786\n",
      "train loss:1.198136147651023\n",
      "train loss:0.7440551118330521\n",
      "train loss:0.9379514281000431\n",
      "train loss:0.8559245334972271\n",
      "train loss:0.9035904740595037\n",
      "train loss:0.6915911760586471\n",
      "train loss:0.8613932137224435\n",
      "train loss:0.8623942920338259\n",
      "train loss:0.9159157951659062\n",
      "train loss:0.9390293024587208\n",
      "train loss:0.9558105302109374\n",
      "train loss:0.735047688204266\n",
      "train loss:0.7359321320667253\n",
      "train loss:0.8919133707599746\n",
      "train loss:0.9617348034952694\n",
      "train loss:0.9432023791659466\n",
      "train loss:0.8330660028516559\n",
      "train loss:0.8199192280359417\n",
      "train loss:0.9531384272286099\n",
      "train loss:0.7024013634063369\n",
      "train loss:0.8977364543699479\n",
      "train loss:0.9163195241893493\n",
      "train loss:0.8529601559278964\n",
      "train loss:0.8675192770047034\n",
      "train loss:0.7824227851101153\n",
      "train loss:0.9527766041176947\n",
      "train loss:0.8486196527835237\n",
      "train loss:0.872324774681539\n",
      "train loss:0.8099602998651976\n",
      "train loss:0.8610216365784793\n",
      "train loss:0.8395143595612844\n",
      "train loss:0.8076289003994401\n",
      "train loss:0.9575383805133874\n",
      "train loss:0.890486888792395\n",
      "train loss:0.7600691035667343\n",
      "train loss:0.8663056827825624\n",
      "train loss:0.8758607679529073\n",
      "train loss:0.8965244891558242\n",
      "train loss:0.8494285141349934\n",
      "train loss:0.9303422819618055\n",
      "train loss:0.7824834785921243\n",
      "train loss:0.8344061172782955\n",
      "train loss:0.7752462701016326\n",
      "train loss:0.7886696115079035\n",
      "train loss:1.0005623835476467\n",
      "train loss:0.9197475820530215\n",
      "train loss:0.8586794647514799\n",
      "train loss:0.9575751960359618\n",
      "train loss:0.8149107361400896\n",
      "train loss:1.0004261336481044\n",
      "train loss:0.6630570793771113\n",
      "train loss:0.6805333398540766\n",
      "train loss:1.0300274649859233\n",
      "train loss:0.9305811552071741\n",
      "train loss:0.8532730936573923\n",
      "train loss:0.9375525200374136\n",
      "train loss:0.7500765242563219\n",
      "train loss:0.8677575156188834\n",
      "train loss:0.8936523307012308\n",
      "train loss:0.86041712457031\n",
      "train loss:0.7574002491756293\n",
      "train loss:1.0536662180624026\n",
      "train loss:0.9494868792385739\n",
      "train loss:0.7412124361515753\n",
      "train loss:0.8743555773787329\n",
      "train loss:0.7899584951854259\n",
      "train loss:0.8135666883159384\n",
      "train loss:0.6939968620266758\n",
      "train loss:0.8684690654987675\n",
      "train loss:0.8580840952796186\n",
      "train loss:0.9038036716130676\n",
      "train loss:0.8906979848062992\n",
      "train loss:0.8360091116263739\n",
      "train loss:1.0503663270537125\n",
      "train loss:0.8666359259496272\n",
      "train loss:0.7656716116851999\n",
      "train loss:0.7392951221617292\n",
      "train loss:0.9065428140622355\n",
      "train loss:0.7661786082651594\n",
      "train loss:0.9809440786376916\n",
      "train loss:0.6840115733685097\n",
      "train loss:0.9587189359648864\n",
      "train loss:0.9042673211859308\n",
      "train loss:0.9304590895654903\n",
      "train loss:0.793695496422822\n",
      "train loss:0.9293725574628345\n",
      "train loss:0.8746324645884392\n",
      "train loss:0.9828928060665283\n",
      "train loss:0.8924195063930511\n",
      "train loss:0.8226926398137624\n",
      "train loss:0.8632325438188072\n",
      "train loss:0.9703526955441997\n",
      "train loss:0.9222534014532923\n",
      "train loss:0.8325710020713578\n",
      "train loss:1.0329819500037756\n",
      "train loss:0.9148115005134829\n",
      "train loss:0.9162284661839654\n",
      "train loss:0.8856048974918749\n",
      "train loss:0.987590477864213\n",
      "train loss:0.9375894686728485\n",
      "train loss:0.8543720502445548\n",
      "train loss:0.7783953279290031\n",
      "train loss:0.8025821601596674\n",
      "train loss:0.8098397952939402\n",
      "train loss:0.8107223902707592\n",
      "train loss:0.8022105509304018\n",
      "train loss:1.1250112971488933\n",
      "train loss:0.7685121637042899\n",
      "train loss:0.8143811158503875\n",
      "train loss:0.8362648358312542\n",
      "train loss:1.119573336155215\n",
      "train loss:0.619861677905766\n",
      "train loss:0.8319760542754286\n",
      "train loss:0.8673392879176636\n",
      "train loss:0.8247227040010514\n",
      "train loss:0.9428449290629914\n",
      "train loss:0.910336216516789\n",
      "train loss:0.9829236839155182\n",
      "train loss:0.713787266000736\n",
      "train loss:0.949689856722478\n",
      "train loss:0.8810150099071709\n",
      "train loss:0.9788814927973125\n",
      "train loss:0.8241043998619741\n",
      "train loss:0.9801014363125938\n",
      "train loss:0.8773299671788142\n",
      "train loss:0.7641905062600829\n",
      "train loss:1.0526921414642032\n",
      "train loss:0.9056409548644457\n",
      "train loss:0.9388509772867013\n",
      "train loss:0.822064125782887\n",
      "train loss:0.8934058609962062\n",
      "train loss:0.9860496494621733\n",
      "train loss:0.972147285872185\n",
      "train loss:0.8109362803073142\n",
      "train loss:1.0047363941559035\n",
      "train loss:0.8658464285364751\n",
      "train loss:0.7111201932523423\n",
      "train loss:1.008633288523771\n",
      "train loss:0.8388138319710555\n",
      "train loss:0.9069852205269185\n",
      "train loss:0.8830302329508504\n",
      "train loss:0.8184779220477604\n",
      "train loss:0.8524304817657092\n",
      "train loss:0.9414885546757011\n",
      "train loss:0.8343218311925494\n",
      "train loss:0.8883869728384025\n",
      "train loss:0.8771276870400007\n",
      "train loss:0.971180066100481\n",
      "train loss:0.7873944161968338\n",
      "train loss:0.8416082263838188\n",
      "train loss:0.9126201186931503\n",
      "train loss:0.8673503750560149\n",
      "train loss:0.7868520532900574\n",
      "train loss:0.953780881894987\n",
      "train loss:0.9467232433365816\n",
      "train loss:0.8978828778914663\n",
      "train loss:0.9377714305202871\n",
      "train loss:0.8931038796923737\n",
      "train loss:0.8181054519039859\n",
      "train loss:0.7878044963600427\n",
      "train loss:0.9369508253142533\n",
      "train loss:0.8905614459872333\n",
      "train loss:0.8516689799136917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.7264302912757457\n",
      "train loss:0.7896445584128248\n",
      "train loss:1.066933888381321\n",
      "train loss:0.8867678514080753\n",
      "train loss:0.8874366880563163\n",
      "train loss:0.6540225038939523\n",
      "train loss:0.8454685771406392\n",
      "train loss:0.9835843517500135\n",
      "train loss:0.9514101962639097\n",
      "train loss:0.9439761022459363\n",
      "train loss:0.8686160623760409\n",
      "train loss:1.0177143296096711\n",
      "train loss:1.0463937566221149\n",
      "train loss:0.82831380341527\n",
      "train loss:0.7038370131442779\n",
      "train loss:0.8702428785416875\n",
      "train loss:0.909492922220133\n",
      "train loss:0.7788221436580821\n",
      "train loss:0.938252010887361\n",
      "train loss:0.7181453601717265\n",
      "train loss:1.0362025810581013\n",
      "train loss:0.7934474986668556\n",
      "train loss:0.8936524427714063\n",
      "train loss:1.0020540367028714\n",
      "train loss:0.9509931401930736\n",
      "train loss:0.8798481081803357\n",
      "train loss:0.9991381723203933\n",
      "train loss:0.787864775217981\n",
      "train loss:0.8093268512992696\n",
      "train loss:1.1871539467140533\n",
      "train loss:1.0066210267957039\n",
      "train loss:0.9734794465138497\n",
      "train loss:0.997775217699304\n",
      "train loss:0.9819306958496157\n",
      "train loss:0.8220271615526673\n",
      "train loss:0.9119646915724146\n",
      "train loss:0.9197335519773513\n",
      "train loss:1.0630017914317582\n",
      "train loss:0.853158501431847\n",
      "train loss:1.0990019930763237\n",
      "train loss:0.9396417235310942\n",
      "train loss:0.9120039798520139\n",
      "train loss:1.1332907518993551\n",
      "train loss:0.8138226186863062\n",
      "train loss:0.9972728384012121\n",
      "train loss:1.007182492399631\n",
      "train loss:1.0511257478533496\n",
      "train loss:0.6803265130136622\n",
      "train loss:0.9617004476380707\n",
      "train loss:0.9172766591409516\n",
      "train loss:0.8449893780081773\n",
      "train loss:1.0016489893809637\n",
      "train loss:0.7604822648948639\n",
      "train loss:0.8004111807132018\n",
      "train loss:1.069556940791668\n",
      "train loss:0.8490944759665325\n",
      "train loss:0.7549871703545996\n",
      "train loss:0.8631574228355405\n",
      "train loss:0.9860581184475291\n",
      "train loss:0.7907645701556142\n",
      "train loss:0.7966192964964517\n",
      "train loss:0.7567600678267232\n",
      "train loss:0.8493897949216718\n",
      "train loss:0.9487581809126061\n",
      "train loss:0.8031884501886674\n",
      "train loss:0.955643832128946\n",
      "train loss:0.8090267879820925\n",
      "train loss:0.7283502647107496\n",
      "train loss:0.9001250117765167\n",
      "train loss:0.8508984898425654\n",
      "train loss:0.6714901828824318\n",
      "train loss:0.7058969653455971\n",
      "train loss:0.7381783705487968\n",
      "train loss:0.9505403968876549\n",
      "train loss:0.8418395472940068\n",
      "train loss:0.8436914274323242\n",
      "train loss:0.8988560417253327\n",
      "train loss:1.1238555690266494\n",
      "train loss:0.9528805866983263\n",
      "train loss:0.7641463314125015\n",
      "train loss:0.9738028594773276\n",
      "train loss:0.9104151172576495\n",
      "train loss:0.9312564593150074\n",
      "train loss:0.7117630979560892\n",
      "train loss:0.9344764763522544\n",
      "train loss:0.8488524405799813\n",
      "train loss:0.9508943554078527\n",
      "train loss:0.9603655630794244\n",
      "train loss:0.8495362951664122\n",
      "train loss:0.9852207069584502\n",
      "train loss:0.846088861053089\n",
      "train loss:1.0039334771155703\n",
      "train loss:0.8774112664469675\n",
      "train loss:0.7941663421219627\n",
      "train loss:1.0614308075025476\n",
      "train loss:0.8545745558363338\n",
      "train loss:0.91718852071995\n",
      "train loss:0.7836935934120633\n",
      "train loss:0.7400913604012688\n",
      "train loss:0.8529655273875822\n",
      "train loss:0.7933764656866663\n",
      "train loss:0.9294755817262569\n",
      "train loss:0.9875520119507805\n",
      "train loss:0.8680966552389482\n",
      "train loss:0.9150930168331177\n",
      "train loss:0.910910051772232\n",
      "train loss:0.7814106860786322\n",
      "train loss:0.5931242735537584\n",
      "train loss:0.7784430461167817\n",
      "train loss:0.968174679085633\n",
      "train loss:1.0028868378983296\n",
      "train loss:0.9225444383453484\n",
      "train loss:0.8405588030131532\n",
      "train loss:0.74640074549042\n",
      "train loss:0.8046632541689174\n",
      "train loss:0.8511433068338312\n",
      "train loss:0.8379988021986884\n",
      "train loss:0.8263686020527348\n",
      "train loss:1.0189535681795172\n",
      "train loss:0.8718484728823261\n",
      "train loss:0.7727678470528205\n",
      "train loss:0.8154030861312\n",
      "train loss:0.8125819492319458\n",
      "train loss:0.9777283629552084\n",
      "train loss:0.9583908606742273\n",
      "train loss:0.6459924531029441\n",
      "train loss:0.8862915366850019\n",
      "train loss:0.7940338477704146\n",
      "train loss:0.9899372607833731\n",
      "train loss:0.8194510509888134\n",
      "train loss:0.7822323779147524\n",
      "train loss:0.8674333888456254\n",
      "train loss:0.7549849846155763\n",
      "train loss:0.834503411331657\n",
      "train loss:0.7947514056283831\n",
      "train loss:0.861692992787909\n",
      "train loss:0.9125549808767139\n",
      "train loss:0.8831964406002594\n",
      "train loss:0.725464609614822\n",
      "train loss:0.9552309140487181\n",
      "train loss:0.7394754289963451\n",
      "train loss:0.9219181237129941\n",
      "train loss:0.7958661564193037\n",
      "train loss:0.8582271858609706\n",
      "train loss:0.6424240052294874\n",
      "train loss:0.7287025982804258\n",
      "train loss:0.9701353896697542\n",
      "train loss:1.0748719234230635\n",
      "train loss:0.9018548878631463\n",
      "train loss:0.8580042019314579\n",
      "train loss:0.685051619194584\n",
      "train loss:0.8229956786589291\n",
      "train loss:0.8857525916116182\n",
      "train loss:0.8105870323558863\n",
      "train loss:0.6445158381940257\n",
      "train loss:0.8798203201002929\n",
      "train loss:0.9427290164545173\n",
      "train loss:0.8467715985324759\n",
      "train loss:0.9800929759091072\n",
      "train loss:0.8278588509892687\n",
      "train loss:0.8400725010755195\n",
      "train loss:0.8514396766822253\n",
      "train loss:0.7485073150119393\n",
      "train loss:0.9251475297761774\n",
      "train loss:0.6854198750705813\n",
      "train loss:0.8626436401089626\n",
      "train loss:0.9350361141816654\n",
      "train loss:0.9785801854095226\n",
      "train loss:0.9486668028240887\n",
      "train loss:0.7478777973021999\n",
      "train loss:0.867811927133089\n",
      "train loss:0.7803605622865333\n",
      "train loss:0.9574507057162593\n",
      "train loss:0.953889834456905\n",
      "train loss:1.0586659960490097\n",
      "train loss:0.7836897177325802\n",
      "train loss:0.8673899538562297\n",
      "train loss:0.7600700674450092\n",
      "train loss:0.8717320177393577\n",
      "train loss:0.9687932617531364\n",
      "train loss:0.8004648868787008\n",
      "train loss:1.0256180561538306\n",
      "train loss:1.036103547352523\n",
      "train loss:0.8541123200108443\n",
      "train loss:0.8545290931923563\n",
      "train loss:0.9288655574084578\n",
      "train loss:1.022969981337797\n",
      "train loss:0.8513914701814135\n",
      "train loss:0.8882512321173915\n",
      "train loss:0.839109750415039\n",
      "train loss:0.9598017400788281\n",
      "train loss:0.9469416050948187\n",
      "train loss:0.8835980971212289\n",
      "train loss:0.8611712574298374\n",
      "train loss:1.0172290936906636\n",
      "train loss:0.9575840643430547\n",
      "train loss:0.8525395608695007\n",
      "train loss:0.8016000886995386\n",
      "train loss:0.7149007507577535\n",
      "train loss:0.9044396132396783\n",
      "train loss:0.8793639494134743\n",
      "train loss:0.8725641434118035\n",
      "train loss:0.886515851749629\n",
      "train loss:0.8051939445387474\n",
      "train loss:1.0622221434615244\n",
      "train loss:1.0820371635298505\n",
      "train loss:0.9066225925588749\n",
      "train loss:0.8863054694060711\n",
      "train loss:0.7461927303410408\n",
      "train loss:0.8569920480484607\n",
      "train loss:0.9077029234090324\n",
      "train loss:0.819791257825592\n",
      "train loss:0.8715080540643908\n",
      "train loss:0.8201227411802191\n",
      "train loss:0.903863598738031\n",
      "train loss:0.82394512939543\n",
      "train loss:0.8433989335080425\n",
      "train loss:0.9263309666922678\n",
      "train loss:0.9125695190609477\n",
      "train loss:0.8183508381363077\n",
      "train loss:0.8757618250443958\n",
      "train loss:0.7573109619062721\n",
      "train loss:0.7539631950799879\n",
      "train loss:0.8454649594765423\n",
      "train loss:0.7227162631424338\n",
      "train loss:0.8667158790675258\n",
      "train loss:0.8300627843327932\n",
      "train loss:1.011454479681775\n",
      "train loss:0.9444469767190264\n",
      "train loss:0.7465433092154471\n",
      "train loss:0.8547804811073254\n",
      "train loss:0.9786763486642223\n",
      "train loss:0.9611501880970461\n",
      "train loss:0.9596024664090144\n",
      "train loss:0.6725057461843782\n",
      "train loss:0.8384829259001851\n",
      "train loss:0.903391488872024\n",
      "train loss:1.031332635282985\n",
      "train loss:1.040341641521153\n",
      "train loss:0.9161109728381228\n",
      "train loss:1.0087891063306\n",
      "train loss:0.7855257174899718\n",
      "=== epoch:11, train acc:0.997, test acc:0.991 ===\n",
      "train loss:0.8083549142419375\n",
      "train loss:0.8746156838927053\n",
      "train loss:0.8214342261257227\n",
      "train loss:0.9564858858540317\n",
      "train loss:0.7068061676742093\n",
      "train loss:0.7955578101214787\n",
      "train loss:0.8962220754789643\n",
      "train loss:0.9144839041487443\n",
      "train loss:0.8850579156492975\n",
      "train loss:0.8993812859852471\n",
      "train loss:0.7668742737305247\n",
      "train loss:0.9040243990057657\n",
      "train loss:0.8009755312310112\n",
      "train loss:0.8589762988221756\n",
      "train loss:0.7805122680976901\n",
      "train loss:0.8840525314915834\n",
      "train loss:0.8884676502602654\n",
      "train loss:0.9763633196043151\n",
      "train loss:0.9228020823389325\n",
      "train loss:0.8306800908193004\n",
      "train loss:0.8898851587699547\n",
      "train loss:0.7774389425815619\n",
      "train loss:0.8242589217391186\n",
      "train loss:0.7786164724760232\n",
      "train loss:0.9593458448388297\n",
      "train loss:0.8997024327112448\n",
      "train loss:0.9651582754909598\n",
      "train loss:0.9312899318961049\n",
      "train loss:0.9262897308826343\n",
      "train loss:0.7796262790206725\n",
      "train loss:0.8106290252529178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.9738008931577562\n",
      "train loss:0.814434368877922\n",
      "train loss:1.1024914910594257\n",
      "train loss:0.8508974413402111\n",
      "train loss:0.9563886710344618\n",
      "train loss:0.8743939910799238\n",
      "train loss:0.8006479960045435\n",
      "train loss:0.7568522339417355\n",
      "train loss:0.8399256519024426\n",
      "train loss:0.7937886028021951\n",
      "train loss:0.9142880118464568\n",
      "train loss:0.9506352742922444\n",
      "train loss:0.923817581599728\n",
      "train loss:0.7090426012136948\n",
      "train loss:0.8775052691345142\n",
      "train loss:0.7924707900844062\n",
      "train loss:0.9111517585339054\n",
      "train loss:0.9508129717095383\n",
      "train loss:0.9540090166344157\n",
      "train loss:0.933039155868774\n",
      "train loss:0.8131402128162794\n",
      "train loss:0.9529492762474056\n",
      "train loss:0.9021189307269113\n",
      "train loss:0.8013337100963531\n",
      "train loss:0.9367286392816215\n",
      "train loss:0.9511431151118453\n",
      "train loss:0.8082932214399974\n",
      "train loss:0.8663064174694308\n",
      "train loss:1.0323133586865483\n",
      "train loss:0.7494427730708498\n",
      "train loss:0.8747641867563923\n",
      "train loss:0.6577990826987373\n",
      "train loss:0.7283403125846901\n",
      "train loss:0.8259698111885357\n",
      "train loss:0.7875432555500713\n",
      "train loss:1.052061134368105\n",
      "train loss:0.8904214668025918\n",
      "train loss:0.7946844266986097\n",
      "train loss:0.8574405168645312\n",
      "train loss:0.8443715353837855\n",
      "train loss:0.7230301121756274\n",
      "train loss:0.7257196413493346\n",
      "train loss:0.8765517868927429\n",
      "train loss:0.9291518704217832\n",
      "train loss:0.8486830356680063\n",
      "train loss:0.8075123668911256\n",
      "train loss:0.8595314976362183\n",
      "train loss:0.9690794527607385\n",
      "train loss:0.9480132692933674\n",
      "train loss:0.8002159089447037\n",
      "train loss:0.8516403712342254\n",
      "train loss:0.9305227677767374\n",
      "train loss:0.9332818239815063\n",
      "train loss:0.6999951109842144\n",
      "train loss:0.9368124066644187\n",
      "train loss:0.8797871556463842\n",
      "train loss:1.0026106239336265\n",
      "train loss:1.064932958040432\n",
      "train loss:0.8496897889552811\n",
      "train loss:1.0056747765117457\n",
      "train loss:0.9283388695905379\n",
      "train loss:0.9590492208231604\n",
      "train loss:1.035292416291236\n",
      "train loss:0.8960971526186434\n",
      "train loss:0.8043670190068752\n",
      "train loss:0.8797456998712341\n",
      "train loss:0.8605837419675194\n",
      "train loss:0.8920923959059508\n",
      "train loss:0.8548153131420655\n",
      "train loss:0.8046888345233483\n",
      "train loss:0.8644209990594196\n",
      "train loss:0.9962162683785852\n",
      "train loss:0.8622613237195186\n",
      "train loss:0.8860121293477309\n",
      "train loss:0.9583010026915602\n",
      "train loss:0.9616475865934073\n",
      "train loss:0.9276401971377092\n",
      "train loss:0.8372715806045424\n",
      "train loss:0.8176757120364099\n",
      "train loss:0.8863168174097271\n",
      "train loss:1.0224385695606517\n",
      "train loss:0.6942255831935873\n",
      "train loss:0.9031658935153124\n",
      "train loss:0.7460178280545611\n",
      "train loss:1.0453519379040963\n",
      "train loss:0.8876732534922351\n",
      "train loss:0.8319879925373758\n",
      "train loss:0.8120480676889233\n",
      "train loss:0.7697003340970173\n",
      "train loss:0.8811457516812718\n",
      "train loss:0.9579913501341204\n",
      "train loss:0.860549650464683\n",
      "train loss:0.7973881885909104\n",
      "train loss:0.8081356215325789\n",
      "train loss:0.9179878310579306\n",
      "train loss:0.9912387975044089\n",
      "train loss:0.7100606637936013\n",
      "train loss:0.7271401766334725\n",
      "train loss:0.8877687240495048\n",
      "train loss:0.7166683084949089\n",
      "train loss:0.8089653068509851\n",
      "train loss:0.9261261862143852\n",
      "train loss:0.817081119361294\n",
      "train loss:0.7343090677311988\n",
      "train loss:0.8466754310690154\n",
      "train loss:0.8935056744486833\n",
      "train loss:0.8173749807885848\n",
      "train loss:0.8868127658403955\n",
      "train loss:0.6849045065462757\n",
      "train loss:0.9741871593787441\n",
      "train loss:0.8483485004614395\n",
      "train loss:0.9534434444590335\n",
      "train loss:0.9313415883603327\n",
      "train loss:0.9179621945983228\n",
      "train loss:0.7426402951242689\n",
      "train loss:0.7668090960455705\n",
      "train loss:0.8005280762570046\n",
      "train loss:0.9651047910572145\n",
      "train loss:0.7093783788622332\n",
      "train loss:0.6847014322715193\n",
      "train loss:0.8746553905825185\n",
      "train loss:0.8111512579208182\n",
      "train loss:0.9452256989838314\n",
      "train loss:1.0289574786109041\n",
      "train loss:0.9071227486045431\n",
      "train loss:0.7386056898280128\n",
      "train loss:0.8654111273323505\n",
      "train loss:0.9402656416417093\n",
      "train loss:0.8203880736893833\n",
      "train loss:0.7983808044564235\n",
      "train loss:1.2477469430376198\n",
      "train loss:0.8252598345321813\n",
      "train loss:0.8456264137869698\n",
      "train loss:0.9307659610931316\n",
      "train loss:0.8062878981535723\n",
      "train loss:0.8548285851738858\n",
      "train loss:0.7949256120856809\n",
      "train loss:0.8776021742288617\n",
      "train loss:0.9225072172600541\n",
      "train loss:0.851397297031584\n",
      "train loss:0.9960475209532043\n",
      "train loss:0.970554846838263\n",
      "train loss:0.7338639183156016\n",
      "train loss:0.9700392554500337\n",
      "train loss:1.0211728450754272\n",
      "train loss:0.7136668967526849\n",
      "train loss:0.8906395905852367\n",
      "train loss:0.8080030995816684\n",
      "train loss:0.9333780706428351\n",
      "train loss:0.8236534112358381\n",
      "train loss:0.8597676479031157\n",
      "train loss:0.9009116470852896\n",
      "train loss:0.905857176417935\n",
      "train loss:0.8338138386898934\n",
      "train loss:0.6983953430604324\n",
      "train loss:0.8177809664940697\n",
      "train loss:0.8469586827797257\n",
      "train loss:0.8458338028655372\n",
      "train loss:1.0112469169544023\n",
      "train loss:0.844295239421845\n",
      "train loss:0.9646080206680597\n",
      "train loss:0.7470953456672974\n",
      "train loss:1.0575739171613556\n",
      "train loss:0.9099234605260623\n",
      "train loss:0.7699809888321321\n",
      "train loss:0.9628659786718643\n",
      "train loss:0.8860432698939066\n",
      "train loss:0.8910149237283594\n",
      "train loss:0.8549954500959825\n",
      "train loss:1.0601805171711682\n",
      "train loss:0.9513657221967026\n",
      "train loss:0.9317534069862863\n",
      "train loss:0.8973960639684317\n",
      "train loss:0.658252323118169\n",
      "train loss:0.8696019646996281\n",
      "train loss:0.8313353069139084\n",
      "train loss:0.8670665947309745\n",
      "train loss:0.7993638192919473\n",
      "train loss:0.7478115800618923\n",
      "train loss:0.9795538812893152\n",
      "train loss:0.8074624403640055\n",
      "train loss:0.8514029143794876\n",
      "train loss:1.0233213266226422\n",
      "train loss:0.7479308921219876\n",
      "train loss:1.0002588955774134\n",
      "train loss:0.8134153787171389\n",
      "train loss:0.8631855610077841\n",
      "train loss:0.8526432162590463\n",
      "train loss:1.0015493104192328\n",
      "train loss:0.7185305651120298\n",
      "train loss:0.7307175415272934\n",
      "train loss:0.8586566715504718\n",
      "train loss:0.8911681878287157\n",
      "train loss:0.8645444014042656\n",
      "train loss:0.8049169416980446\n",
      "train loss:0.9254230258705486\n",
      "train loss:0.8522900447788043\n",
      "train loss:0.680213416349658\n",
      "train loss:0.7981862897004839\n",
      "train loss:0.8791820666485342\n",
      "train loss:0.6829408240207258\n",
      "train loss:0.9382112753317798\n",
      "train loss:1.009911553322815\n",
      "train loss:0.941184941128078\n",
      "train loss:0.8090607657233739\n",
      "train loss:0.9371597966066922\n",
      "train loss:0.858464941582308\n",
      "train loss:0.9234924924735965\n",
      "train loss:0.9173792787578344\n",
      "train loss:0.8509698428181075\n",
      "train loss:0.7568217376449894\n",
      "train loss:0.8515455702996213\n",
      "train loss:0.8697519904711518\n",
      "train loss:0.9437233979099527\n",
      "train loss:0.9264014198739069\n",
      "train loss:0.9247278329764085\n",
      "train loss:0.9652281867635483\n",
      "train loss:0.8802019978811974\n",
      "train loss:0.9660751185299458\n",
      "train loss:0.8649434387541699\n",
      "train loss:0.8962440394427543\n",
      "train loss:0.7477087249100793\n",
      "train loss:0.9677774613036381\n",
      "train loss:0.718534178739283\n",
      "train loss:0.9852001589647804\n",
      "train loss:0.9430324879168437\n",
      "train loss:0.931511209310744\n",
      "train loss:0.846687051806019\n",
      "train loss:0.7352195383545266\n",
      "train loss:0.7612295215546264\n",
      "train loss:0.9391545152379267\n",
      "train loss:0.8294160806417782\n",
      "train loss:0.8376546219981676\n",
      "train loss:0.7673969073336481\n",
      "train loss:0.8666952467724462\n",
      "train loss:0.8943036952636813\n",
      "train loss:0.9663360460908821\n",
      "train loss:0.727838097599885\n",
      "train loss:0.7578204242395847\n",
      "train loss:0.9199779492875733\n",
      "train loss:0.8887797043959915\n",
      "train loss:0.7912190904585227\n",
      "train loss:0.7468170123722585\n",
      "train loss:0.8482365083415533\n",
      "train loss:0.9282547637190435\n",
      "train loss:0.8082364358044966\n",
      "train loss:0.9837049071890146\n",
      "train loss:0.9140798832382768\n",
      "train loss:0.9901892811275146\n",
      "train loss:1.0159414222447112\n",
      "train loss:0.9826466834134693\n",
      "train loss:0.9628657169114823\n",
      "train loss:0.8605650272641858\n",
      "train loss:0.9688407549860689\n",
      "train loss:0.8362441782240402\n",
      "train loss:0.7191246790564424\n",
      "train loss:0.8452577708214468\n",
      "train loss:0.8889689904527145\n",
      "train loss:0.8831539471119236\n",
      "train loss:0.9143446244968587\n",
      "train loss:0.7834234325049039\n",
      "train loss:0.948472788271103\n",
      "train loss:0.8292359615291829\n",
      "train loss:0.8927771924360098\n",
      "train loss:0.965596869502637\n",
      "train loss:0.8937047591044324\n",
      "train loss:0.7369163232536714\n",
      "train loss:0.8693042629479603\n",
      "train loss:0.7756595152038405\n",
      "train loss:0.8516341882626856\n",
      "train loss:0.7474629613247162\n",
      "train loss:0.9176890088362629\n",
      "train loss:0.9976120387934349\n",
      "train loss:0.7986329459547215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:1.003703345598214\n",
      "train loss:0.7978146012553922\n",
      "train loss:0.957934183805659\n",
      "train loss:0.7986729197213788\n",
      "train loss:0.9814435493574742\n",
      "train loss:1.021037865142605\n",
      "train loss:0.8009588368140328\n",
      "train loss:0.9061752251950286\n",
      "train loss:0.8769279792120729\n",
      "train loss:0.7881118803502385\n",
      "train loss:0.9841136329090174\n",
      "train loss:0.8660081456320001\n",
      "train loss:0.9249498809780985\n",
      "train loss:0.943414533371797\n",
      "train loss:0.8844210841607358\n",
      "train loss:0.8918775428153098\n",
      "train loss:0.8621869384786707\n",
      "train loss:0.83648728210806\n",
      "train loss:0.8498520073989663\n",
      "train loss:0.7919031661097325\n",
      "train loss:0.8932994601571198\n",
      "train loss:0.8894229564868483\n",
      "train loss:0.9430586077664599\n",
      "train loss:0.842415632912579\n",
      "train loss:0.9353186278949192\n",
      "train loss:0.9032252609188406\n",
      "train loss:0.5645322917320182\n",
      "train loss:0.9230466472755933\n",
      "train loss:0.9189245925006017\n",
      "train loss:0.825309844418599\n",
      "train loss:0.8140168514850024\n",
      "train loss:0.7664139850287168\n",
      "train loss:0.9340186655535827\n",
      "train loss:0.8860224496410106\n",
      "train loss:0.7233739241355672\n",
      "train loss:0.9137215464571393\n",
      "train loss:0.9110361133512948\n",
      "train loss:0.8296786997266276\n",
      "train loss:0.925306060630526\n",
      "train loss:0.870344711010132\n",
      "train loss:0.9402124555232446\n",
      "train loss:0.8012091137116305\n",
      "train loss:0.8048902203009694\n",
      "train loss:0.6544304690153812\n",
      "train loss:0.9614471187440453\n",
      "train loss:0.8992570959408571\n",
      "train loss:0.9721724139550293\n",
      "train loss:0.9909232836324335\n",
      "train loss:0.8268737675808331\n",
      "train loss:0.9747455907445787\n",
      "train loss:1.065717372869873\n",
      "train loss:0.9922193716527755\n",
      "train loss:0.8991149147986336\n",
      "train loss:0.8459339035829656\n",
      "train loss:0.9736814505937752\n",
      "train loss:1.0003674372372224\n",
      "train loss:0.7973142069796395\n",
      "train loss:0.9513668969723301\n",
      "train loss:0.9014892810196161\n",
      "train loss:0.8233728655047993\n",
      "train loss:0.9375351077487407\n",
      "train loss:1.0404087067774017\n",
      "train loss:0.7003016130173143\n",
      "train loss:0.8993306108933815\n",
      "train loss:1.0412959019204704\n",
      "train loss:0.8418761791248407\n",
      "train loss:0.828888893262344\n",
      "train loss:0.8213069619686166\n",
      "train loss:0.7583545384465313\n",
      "train loss:0.9969019199684024\n",
      "train loss:0.8354603833367414\n",
      "train loss:0.8906371398765226\n",
      "train loss:0.9105719158587975\n",
      "train loss:0.8846644744614993\n",
      "train loss:0.7247610116302472\n",
      "train loss:0.9129005187774542\n",
      "train loss:0.820412448492829\n",
      "train loss:0.8356016286592305\n",
      "train loss:0.8529544171790255\n",
      "train loss:0.8025872365113691\n",
      "train loss:0.8334689686838616\n",
      "train loss:0.9785135879018729\n",
      "train loss:0.8615306016943813\n",
      "train loss:0.953319574432603\n",
      "train loss:0.8632404057445063\n",
      "train loss:0.8293028510970823\n",
      "train loss:0.9945073477024065\n",
      "train loss:0.8560653217206727\n",
      "train loss:1.0467504805522387\n",
      "train loss:0.7676768316944592\n",
      "train loss:0.7562338285089371\n",
      "train loss:0.9505422538820594\n",
      "train loss:0.863912115466817\n",
      "train loss:0.6950077535432291\n",
      "train loss:0.7102710115600636\n",
      "train loss:0.8212698920018614\n",
      "train loss:0.8079828872076447\n",
      "train loss:0.7999948565599639\n",
      "train loss:0.9113471991572628\n",
      "train loss:0.8451369626607738\n",
      "train loss:0.9016639268772451\n",
      "train loss:0.9233802739279732\n",
      "train loss:0.8208849058420157\n",
      "train loss:0.7651066019720519\n",
      "train loss:0.8098182673540961\n",
      "train loss:0.9810681588612795\n",
      "train loss:1.0999663430152913\n",
      "train loss:0.8142055961341405\n",
      "train loss:1.0225212237879087\n",
      "train loss:0.8868362061461452\n",
      "train loss:0.9948319935836409\n",
      "train loss:0.9524364274487891\n",
      "train loss:0.8649760891748\n",
      "train loss:0.9035173059925008\n",
      "train loss:0.7174170867758953\n",
      "train loss:0.8807969573968577\n",
      "train loss:0.9577473795584343\n",
      "train loss:0.9429792138480899\n",
      "train loss:0.7010698107337625\n",
      "train loss:1.081213788152221\n",
      "train loss:1.0075205563004568\n",
      "train loss:0.8104974371461324\n",
      "train loss:1.0381346764030535\n",
      "train loss:0.8137478734019262\n",
      "train loss:1.0365836090322933\n",
      "train loss:1.1440379341846376\n",
      "train loss:0.8273573245900334\n",
      "train loss:1.009543004696826\n",
      "train loss:0.7275355549983274\n",
      "train loss:0.875507571718283\n",
      "train loss:1.0725380860111546\n",
      "train loss:1.0166375239940293\n",
      "train loss:0.7851044427186834\n",
      "train loss:0.7898469238374151\n",
      "train loss:0.9373828098722862\n",
      "train loss:0.7791683930429394\n",
      "train loss:0.9341112206488756\n",
      "train loss:0.8856922361409603\n",
      "train loss:0.9602777265855061\n",
      "train loss:0.7444962134909525\n",
      "train loss:0.9213750882455796\n",
      "train loss:0.9700794854856442\n",
      "train loss:0.9067092823025427\n",
      "train loss:0.798239971989825\n",
      "train loss:0.7310634697243242\n",
      "train loss:0.8429758056940659\n",
      "train loss:0.940547900102936\n",
      "train loss:0.9702350394064091\n",
      "train loss:0.8549923216947307\n",
      "train loss:0.942693359875899\n",
      "train loss:0.8754173325685088\n",
      "train loss:0.8977604046825364\n",
      "train loss:0.9281281380174657\n",
      "train loss:0.7154507028839009\n",
      "train loss:0.8271454065242332\n",
      "train loss:0.866281202008368\n",
      "train loss:0.8996670398960157\n",
      "train loss:0.7868884830261375\n",
      "train loss:0.9776665690596501\n",
      "train loss:0.9113928445816968\n",
      "train loss:0.841806627000938\n",
      "train loss:1.0971735675482803\n",
      "train loss:0.8485933153636701\n",
      "train loss:0.8229528538413982\n",
      "train loss:0.9213074270218616\n",
      "train loss:0.8638292704573874\n",
      "train loss:0.8617402245761551\n",
      "train loss:0.7682062274285171\n",
      "train loss:0.7513431186159543\n",
      "train loss:0.9627435820874637\n",
      "train loss:0.8331693777869222\n",
      "train loss:0.9542786025683444\n",
      "train loss:0.8718434533394486\n",
      "train loss:0.9473056114088689\n",
      "train loss:0.9222773573311549\n",
      "train loss:0.8147754253039312\n",
      "train loss:0.7561097195066292\n",
      "train loss:0.8844466147757346\n",
      "train loss:0.8573233119240933\n",
      "train loss:0.8211548478804734\n",
      "train loss:0.7937927150926991\n",
      "train loss:0.7963722004298248\n",
      "train loss:0.7163971968031259\n",
      "train loss:0.8429550123706311\n",
      "train loss:1.0083077923635215\n",
      "train loss:0.6172061253449239\n",
      "train loss:0.824937328662939\n",
      "train loss:0.978953428476412\n",
      "train loss:0.9320587441577546\n",
      "train loss:1.0164048761685227\n",
      "train loss:0.8743724401879719\n",
      "train loss:0.8260350655702912\n",
      "train loss:0.7479650461466767\n",
      "train loss:0.8226800539906722\n",
      "train loss:0.7712660903993006\n",
      "train loss:0.7667779606550573\n",
      "train loss:0.916955073944333\n",
      "train loss:0.9783373817199863\n",
      "train loss:0.8920952499665235\n",
      "train loss:0.8280277078876069\n",
      "train loss:1.0577294710205587\n",
      "train loss:0.8412586943992666\n",
      "train loss:0.9761470005499566\n",
      "train loss:0.8997048693520188\n",
      "train loss:0.909159844817407\n",
      "train loss:0.9726151378919587\n",
      "train loss:0.7881237467477896\n",
      "train loss:0.8589836723718814\n",
      "train loss:0.9751767142339461\n",
      "train loss:0.7653501188116337\n",
      "train loss:0.8488048100339395\n",
      "train loss:0.9451289594108448\n",
      "train loss:0.8286535163186026\n",
      "train loss:0.8276656666799809\n",
      "train loss:0.9003113816327548\n",
      "train loss:0.7929662808597792\n",
      "train loss:0.8647147279102405\n",
      "train loss:0.9488152008079467\n",
      "train loss:0.9934409707886378\n",
      "train loss:0.859596508865605\n",
      "train loss:0.9118666482034095\n",
      "train loss:0.9953655705433319\n",
      "train loss:1.017463820440378\n",
      "train loss:0.7542173208046802\n",
      "train loss:0.7681881743941588\n",
      "train loss:0.8589765880713636\n",
      "train loss:0.9437782614751545\n",
      "train loss:1.0185081646491378\n",
      "train loss:0.8296552742789549\n",
      "train loss:0.8399072269075643\n",
      "train loss:0.7563224422501308\n",
      "train loss:0.8920950894075346\n",
      "train loss:1.0103392473439268\n",
      "train loss:0.8848677875561161\n",
      "train loss:0.9269453388072842\n",
      "train loss:0.9658939157896785\n",
      "train loss:1.0258617307630644\n",
      "train loss:1.006189243598662\n",
      "train loss:0.8926441863284558\n",
      "train loss:0.851426381700144\n",
      "train loss:0.978031558868786\n",
      "train loss:0.8748010679390881\n",
      "train loss:0.8587007450798539\n",
      "train loss:0.7284503502918895\n",
      "train loss:0.7268750957657738\n",
      "train loss:0.9182584618436307\n",
      "train loss:0.9262523101452683\n",
      "train loss:1.0119884559631622\n",
      "train loss:0.8333078555427578\n",
      "train loss:0.8996022190449893\n",
      "train loss:0.9117542473572366\n",
      "train loss:1.094998920214419\n",
      "train loss:0.9972757769583622\n",
      "train loss:0.8596080493862773\n",
      "train loss:1.0070216566651222\n",
      "train loss:0.8354634241858228\n",
      "train loss:0.8900098943074565\n",
      "train loss:0.8867236287658994\n",
      "train loss:0.8444293528487499\n",
      "train loss:1.0090723677497964\n",
      "train loss:0.8679795267586943\n",
      "train loss:0.7871776587395881\n",
      "train loss:0.8202010551959442\n",
      "train loss:0.9897313850473894\n",
      "train loss:0.9816636344448583\n",
      "train loss:0.9137310674848979\n",
      "train loss:0.7682702736656117\n",
      "train loss:0.8404503076867098\n",
      "train loss:0.9399369833830877\n",
      "train loss:0.9772936624345379\n",
      "train loss:0.7591870195855478\n",
      "train loss:0.7027779551882576\n",
      "train loss:0.7526665016403864\n",
      "train loss:0.7963417163805765\n",
      "train loss:0.8611501547636579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.9963747861801475\n",
      "train loss:0.9410390849251161\n",
      "train loss:0.9239233651628819\n",
      "train loss:0.8634613578385726\n",
      "train loss:1.002616381725942\n",
      "train loss:0.9436790378801077\n",
      "train loss:0.9846209192019759\n",
      "train loss:0.9257125549156869\n",
      "train loss:0.7862306526248561\n",
      "train loss:0.8242038122905609\n",
      "train loss:0.9529143216741666\n",
      "train loss:0.9240304674102638\n",
      "train loss:0.9967536217595074\n",
      "train loss:0.8528221073656855\n",
      "train loss:0.7829078686058736\n",
      "train loss:0.7744084857430964\n",
      "train loss:0.7496953493959302\n",
      "train loss:0.9457439873468994\n",
      "train loss:0.8921774892551813\n",
      "train loss:0.8111805439171295\n",
      "=== epoch:12, train acc:0.994, test acc:0.992 ===\n",
      "train loss:0.9623615551078237\n",
      "train loss:0.8910975505251756\n",
      "train loss:0.8298938322766511\n",
      "train loss:0.8122805343465154\n",
      "train loss:0.7166377152276392\n",
      "train loss:0.9383102349471241\n",
      "train loss:0.9118997080996226\n",
      "train loss:0.7556282293947331\n",
      "train loss:0.8455089153201832\n",
      "train loss:0.8359721419034892\n",
      "train loss:0.9711563786854902\n",
      "train loss:0.9689176731043776\n",
      "train loss:0.8262035774465818\n",
      "train loss:0.9747050062152738\n",
      "train loss:0.7474170002615724\n",
      "train loss:0.8082949931134753\n",
      "train loss:0.9062518324057878\n",
      "train loss:0.847051495534983\n",
      "train loss:0.8492359443287134\n",
      "train loss:0.9206624791782064\n",
      "train loss:0.8216268478157924\n",
      "train loss:0.8218760424356547\n",
      "train loss:0.8375913144203726\n",
      "train loss:0.9209018058005328\n",
      "train loss:0.7849947860830798\n",
      "train loss:0.8075647156984291\n",
      "train loss:0.9603569839322761\n",
      "train loss:0.9079367826601965\n",
      "train loss:0.9655822212666487\n",
      "train loss:0.7983834700223155\n",
      "train loss:0.86454782973369\n",
      "train loss:0.9620519631899169\n",
      "train loss:0.88129356833406\n",
      "train loss:0.7607184873592794\n",
      "train loss:0.937662695991527\n",
      "train loss:1.0828299990973531\n",
      "train loss:0.7550477417613715\n",
      "train loss:0.7018475611333079\n",
      "train loss:0.8105630050489426\n",
      "train loss:0.9341514691012509\n",
      "train loss:0.7904783393121222\n",
      "train loss:0.833061804967625\n",
      "train loss:0.9340083226833168\n",
      "train loss:0.8927360814313338\n",
      "train loss:0.747031641489095\n",
      "train loss:0.7911389272344802\n",
      "train loss:0.7680556090411029\n",
      "train loss:0.8336127714990313\n",
      "train loss:0.9009515440119025\n",
      "train loss:0.8499514685321315\n",
      "train loss:1.0353231645853134\n",
      "train loss:0.7932637080152586\n",
      "train loss:0.8594250407117526\n",
      "train loss:1.0523949088617948\n",
      "train loss:0.7115229852010282\n",
      "train loss:0.7191387008156486\n",
      "train loss:0.8895956388830218\n",
      "train loss:0.9241873062462497\n",
      "train loss:1.0005217563210977\n",
      "train loss:0.9191318400384635\n",
      "train loss:0.8730266540937069\n",
      "train loss:0.9046291778148737\n",
      "train loss:0.9004783969760156\n",
      "train loss:0.8243811983056735\n",
      "train loss:0.9947063549030412\n",
      "train loss:0.8845609286312173\n",
      "train loss:0.6846875064948098\n",
      "train loss:0.9677603956965923\n",
      "train loss:0.8784625986976554\n",
      "train loss:0.8153263420594149\n",
      "train loss:0.9294244175341286\n",
      "train loss:1.1289582530427151\n",
      "train loss:0.8498946636984113\n",
      "train loss:0.9531298932390289\n",
      "train loss:0.8330459675330454\n",
      "train loss:0.8601264675666126\n",
      "train loss:0.8529244307331522\n",
      "train loss:0.8906037769005156\n",
      "train loss:0.8240005250296386\n",
      "train loss:0.9562108280433914\n",
      "train loss:0.9204453137383892\n",
      "train loss:0.7395465561409962\n",
      "train loss:0.812328752228238\n",
      "train loss:0.8757517475916581\n",
      "train loss:0.9303573635149114\n",
      "train loss:0.9372575596148325\n",
      "train loss:0.9985131306098453\n",
      "train loss:0.8398190623890587\n",
      "train loss:0.9708666106264338\n",
      "train loss:1.0816051587487374\n",
      "train loss:0.8559750241981083\n",
      "train loss:0.8540667503699579\n",
      "train loss:0.8420784550007687\n",
      "train loss:0.8701921981531623\n",
      "train loss:0.9908014523202142\n",
      "train loss:0.8708215109626174\n",
      "train loss:0.8743064875891204\n",
      "train loss:0.9007128197581395\n",
      "train loss:1.1375079033223163\n",
      "train loss:0.972394691966697\n",
      "train loss:0.956873205679333\n",
      "train loss:0.7823694111824001\n",
      "train loss:0.992497061265814\n",
      "train loss:0.8881287522000468\n",
      "train loss:0.9009684754853344\n",
      "train loss:0.9773174713538265\n",
      "train loss:0.7945626892863988\n",
      "train loss:0.9220889931001081\n",
      "train loss:0.944557491911974\n",
      "train loss:0.897969336577781\n",
      "train loss:1.0098900940850255\n",
      "train loss:0.9538742875474846\n",
      "train loss:1.0011613892915678\n",
      "train loss:0.982698673070766\n",
      "train loss:1.0814683023875942\n",
      "train loss:0.8868544071756003\n",
      "train loss:0.87953807501727\n",
      "train loss:1.0792014630951252\n",
      "train loss:0.8864462458846077\n",
      "train loss:0.848256851495152\n",
      "train loss:0.7460943653444605\n",
      "train loss:0.8690137780853573\n",
      "train loss:0.7763629731706309\n",
      "train loss:1.0184257076126138\n",
      "train loss:1.0125087352130109\n",
      "train loss:1.0117493427852198\n",
      "train loss:0.895310017382408\n",
      "train loss:1.1319857852106905\n",
      "train loss:0.798096204472822\n",
      "train loss:0.8480405611989665\n",
      "train loss:0.8983304929895317\n",
      "train loss:0.7901684266375067\n",
      "train loss:0.9905826781005165\n",
      "train loss:0.8558490223085217\n",
      "train loss:0.8055777795807915\n",
      "train loss:0.9529086967676571\n",
      "train loss:0.8991297327230654\n",
      "train loss:0.8662963593144001\n",
      "train loss:1.074188640222192\n",
      "train loss:0.82013072628133\n",
      "train loss:0.8825943658084857\n",
      "train loss:0.828641433355022\n",
      "train loss:0.8733486714482984\n",
      "train loss:0.7466293989321942\n",
      "train loss:0.7621982420630483\n",
      "train loss:0.9657506555458748\n",
      "train loss:0.889991384746524\n",
      "train loss:0.9795459396236805\n",
      "train loss:1.01927038339121\n",
      "train loss:0.8126965586257765\n",
      "train loss:0.8583257466848564\n",
      "train loss:0.8454379042338306\n",
      "train loss:0.7983786023927157\n",
      "train loss:0.816486402748867\n",
      "train loss:0.8679193439727522\n",
      "train loss:0.7856699898757025\n",
      "train loss:0.9118581038994964\n",
      "train loss:0.9658800500126393\n",
      "train loss:0.7575546353477998\n",
      "train loss:0.8342321347051179\n",
      "train loss:0.8760718870079701\n",
      "train loss:0.7966036047659935\n",
      "train loss:0.8549027885061484\n",
      "train loss:0.836200465340901\n",
      "train loss:1.0852215962282106\n",
      "train loss:0.8053220967943234\n",
      "train loss:0.8565207780166182\n",
      "train loss:0.8254881200913844\n",
      "train loss:0.9690819874018919\n",
      "train loss:0.7432951322428913\n",
      "train loss:0.8151818718318643\n",
      "train loss:1.024711400692776\n",
      "train loss:0.8189290747268312\n",
      "train loss:0.7806434503827598\n",
      "train loss:0.9928515147633695\n",
      "train loss:0.7671367887539688\n",
      "train loss:0.81441192652069\n",
      "train loss:0.8338196222757027\n",
      "train loss:0.9633399753002142\n",
      "train loss:0.7019889930780151\n",
      "train loss:0.7613565230041882\n",
      "train loss:0.7448056748300812\n",
      "train loss:0.7922478046473833\n",
      "train loss:0.8112323794495576\n",
      "train loss:0.9672255940013929\n",
      "train loss:0.8821213106863413\n",
      "train loss:0.9507352991201086\n",
      "train loss:0.8760436148825802\n",
      "train loss:0.8748954599745684\n",
      "train loss:0.7276578750787651\n",
      "train loss:0.8895510496068656\n",
      "train loss:0.7281000126710441\n",
      "train loss:0.7103355626160617\n",
      "train loss:0.8693199611468586\n",
      "train loss:0.832467232921373\n",
      "train loss:0.826584241565079\n",
      "train loss:0.7916647147363703\n",
      "train loss:0.945065136785599\n",
      "train loss:0.9717268463482371\n",
      "train loss:0.8021879981652092\n",
      "train loss:0.6324531178743242\n",
      "train loss:0.880905816605997\n",
      "train loss:0.6464648344064094\n",
      "train loss:0.7723583149255527\n",
      "train loss:1.0541008572749553\n",
      "train loss:0.9139827245322186\n",
      "train loss:0.8626278153827833\n",
      "train loss:0.7719447621585904\n",
      "train loss:0.9350592774838623\n",
      "train loss:0.984537287221388\n",
      "train loss:0.7201428357875709\n",
      "train loss:0.9639768099438814\n",
      "train loss:0.8644917105568035\n",
      "train loss:0.9007086811554232\n",
      "train loss:0.7205685454409348\n",
      "train loss:0.948390646606459\n",
      "train loss:0.8972205747792876\n",
      "train loss:1.0792234610628042\n",
      "train loss:0.7729281404592827\n",
      "train loss:0.8205624076030597\n",
      "train loss:0.9220698395495684\n",
      "train loss:0.8696347169772861\n",
      "train loss:0.7489075514578252\n",
      "train loss:0.8072509888342012\n",
      "train loss:0.6499902838336544\n",
      "train loss:0.83470975605848\n",
      "train loss:0.9059605810648671\n",
      "train loss:0.920458560341865\n",
      "train loss:0.8412652108594159\n",
      "train loss:0.9612734424531517\n",
      "train loss:0.8695390664572118\n",
      "train loss:0.7695882811886186\n",
      "train loss:0.8792922996315186\n",
      "train loss:0.8956384509715127\n",
      "train loss:0.8565254104781335\n",
      "train loss:0.8888199985715393\n",
      "train loss:0.8747000085242439\n",
      "train loss:0.8417484617079061\n",
      "train loss:0.8262420304913602\n",
      "train loss:0.8250306615804901\n",
      "train loss:0.7112244026692902\n",
      "train loss:0.9621560557699137\n",
      "train loss:0.9942672569959627\n",
      "train loss:0.8234440706736444\n",
      "train loss:1.1135568755771248\n",
      "train loss:0.8805286554129439\n",
      "train loss:0.8089847129329221\n",
      "train loss:0.9192785582670665\n",
      "train loss:0.6492654753422441\n",
      "train loss:0.8442272852710916\n",
      "train loss:0.9314235903648812\n",
      "train loss:0.9877156717451594\n",
      "train loss:0.880808153981949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.7529353819645003\n",
      "train loss:0.8490785678585188\n",
      "train loss:0.9632796519750062\n",
      "train loss:0.9649318487253261\n",
      "train loss:0.8358971065679475\n",
      "train loss:0.7844299084426081\n",
      "train loss:0.9153559605409939\n",
      "train loss:0.9425029358371139\n",
      "train loss:0.8457431150025682\n",
      "train loss:1.0214884051194597\n",
      "train loss:0.8004336914139755\n",
      "train loss:0.8635957836777933\n",
      "train loss:0.8292046518940708\n",
      "train loss:0.9501851877177957\n",
      "train loss:0.9870411862807523\n",
      "train loss:0.8951354340297135\n",
      "train loss:0.8778696462038628\n",
      "train loss:0.875652148218117\n",
      "train loss:1.134995261009924\n",
      "train loss:0.9239712092960262\n",
      "train loss:0.9135843203332331\n",
      "train loss:0.9581774807268654\n",
      "train loss:0.8875464939826548\n",
      "train loss:0.9645798914551604\n",
      "train loss:0.8393678873125592\n",
      "train loss:0.8928321441600687\n",
      "train loss:0.6828421422703705\n",
      "train loss:0.7598857967895074\n",
      "train loss:0.9130134438929608\n",
      "train loss:0.6969533454037333\n",
      "train loss:0.9831108131842872\n",
      "train loss:0.8423615153191544\n",
      "train loss:0.8949816804937195\n",
      "train loss:0.9740639871673002\n",
      "train loss:0.7053986736622005\n",
      "train loss:0.9550021593176468\n",
      "train loss:0.8077269900409035\n",
      "train loss:1.0172562603014486\n",
      "train loss:0.8006095754347758\n",
      "train loss:0.959659184351679\n",
      "train loss:0.8876912319902575\n",
      "train loss:0.8403466422759192\n",
      "train loss:0.9469385927223325\n",
      "train loss:1.0932974763636674\n",
      "train loss:0.8680223293880183\n",
      "train loss:0.9606934532403741\n",
      "train loss:0.9248007009376561\n",
      "train loss:0.9556709795773359\n",
      "train loss:1.0116406624955543\n",
      "train loss:0.7950892772712502\n",
      "train loss:0.8763300163143978\n",
      "train loss:0.9071218555406131\n",
      "train loss:0.7340111817751587\n",
      "train loss:0.8131317690766879\n",
      "train loss:0.7641481303104868\n",
      "train loss:0.8572344210947981\n",
      "train loss:0.8460891787027341\n",
      "train loss:0.8496822717225153\n",
      "train loss:0.9829273439317504\n",
      "train loss:0.9246205084219578\n",
      "train loss:0.9434300722130348\n",
      "train loss:0.9191517587794911\n",
      "train loss:0.925771933413326\n",
      "train loss:0.8345828075757763\n",
      "train loss:0.973022810980603\n",
      "train loss:0.8769638477598882\n",
      "train loss:0.8468346438407474\n",
      "train loss:0.9707639061917288\n",
      "train loss:0.7977645304861918\n",
      "train loss:0.9218604124682566\n",
      "train loss:0.9369156490843831\n",
      "train loss:0.9040045942483743\n",
      "train loss:1.0038532320487839\n",
      "train loss:0.9272324523387152\n",
      "train loss:0.6860665343235576\n",
      "train loss:0.855648631046764\n",
      "train loss:0.8218209836120036\n",
      "train loss:0.8964400271416619\n",
      "train loss:1.0506265092445113\n",
      "train loss:0.8174058128963182\n",
      "train loss:0.9542378717738687\n",
      "train loss:0.9120252558376454\n",
      "train loss:0.8259325597656116\n",
      "train loss:1.0309716972020444\n",
      "train loss:0.937356096726802\n",
      "train loss:0.8987831237008542\n",
      "train loss:0.8440738405093284\n",
      "train loss:0.8522442953773863\n",
      "train loss:0.8487781931087172\n",
      "train loss:0.8989778157734025\n",
      "train loss:0.6735869088711123\n",
      "train loss:0.8640413513395044\n",
      "train loss:0.8819070118294415\n",
      "train loss:0.8203901224279408\n",
      "train loss:1.0040681632972852\n",
      "train loss:0.863747685835663\n",
      "train loss:0.7571438434873291\n",
      "train loss:0.9556198058404773\n",
      "train loss:0.8585196427846746\n",
      "train loss:0.9470604379548146\n",
      "train loss:0.7618969155393881\n",
      "train loss:0.8297721880954242\n",
      "train loss:0.7862870006318998\n",
      "train loss:0.9317656444292003\n",
      "train loss:0.9329641054771974\n",
      "train loss:0.9236385098929664\n",
      "train loss:0.8838822895959698\n",
      "train loss:1.0027030133367614\n",
      "train loss:0.8045158320495548\n",
      "train loss:0.9695119865826541\n",
      "train loss:0.9623568192204531\n",
      "train loss:0.9904836002673413\n",
      "train loss:0.8523442000063715\n",
      "train loss:0.8950927768606989\n",
      "train loss:0.8161651726621197\n",
      "train loss:0.8095175848171229\n",
      "train loss:1.025821528951481\n",
      "train loss:0.9240540871350964\n",
      "train loss:0.7973545826871151\n",
      "train loss:0.8394425936873811\n",
      "train loss:0.932298211578767\n",
      "train loss:0.8888655134283933\n",
      "train loss:1.004347413339648\n",
      "train loss:0.8595043652642134\n",
      "train loss:0.7482397369303126\n",
      "train loss:0.9958859950122643\n",
      "train loss:0.7892426868303393\n",
      "train loss:0.9402104818762491\n",
      "train loss:1.0332515128472124\n",
      "train loss:0.8219743628431773\n",
      "train loss:0.8187902105546537\n",
      "train loss:0.941239199212452\n",
      "train loss:0.7837141676265924\n",
      "train loss:0.8794878074230367\n",
      "train loss:0.831879595084943\n",
      "train loss:0.9111485282700158\n",
      "train loss:0.9004474965166189\n",
      "train loss:0.763194754118569\n",
      "train loss:0.8862384343700704\n",
      "train loss:0.8674777159631255\n",
      "train loss:0.9055840048700311\n",
      "train loss:0.5772617684921609\n",
      "train loss:0.8785581878385657\n",
      "train loss:0.8699107697739347\n",
      "train loss:0.982227531663524\n",
      "train loss:0.8188209440701106\n",
      "train loss:0.9800530763797195\n",
      "train loss:0.8021712234206235\n",
      "train loss:0.8299118290537102\n",
      "train loss:0.9231447628869525\n",
      "train loss:0.7303351403662574\n",
      "train loss:0.7868506314906307\n",
      "train loss:0.8948855543271251\n",
      "train loss:0.812444517051196\n",
      "train loss:0.8185602367858281\n",
      "train loss:0.7806665741782236\n",
      "train loss:0.9552834326178666\n",
      "train loss:0.7760855001061029\n",
      "train loss:0.9520850122461978\n",
      "train loss:0.8826108209097809\n",
      "train loss:0.8743043157998537\n",
      "train loss:0.9299767841687475\n",
      "train loss:0.9118143917094997\n",
      "train loss:0.9583796694432531\n",
      "train loss:0.8811810265495593\n",
      "train loss:0.8611536888179566\n",
      "train loss:0.8865624495193966\n",
      "train loss:0.8224984755568692\n",
      "train loss:0.876158455042937\n",
      "train loss:0.6377577343231952\n",
      "train loss:0.7839000489446468\n",
      "train loss:1.048704837558396\n",
      "train loss:0.940957228537384\n",
      "train loss:0.7406364448935703\n",
      "train loss:0.843061623039321\n",
      "train loss:0.8116349809652544\n",
      "train loss:0.9013843439018789\n",
      "train loss:0.8755088925605596\n",
      "train loss:0.8045576343898121\n",
      "train loss:0.6836760755637826\n",
      "train loss:0.848563240635119\n",
      "train loss:0.8544096950444096\n",
      "train loss:0.891477386287668\n",
      "train loss:0.8535192860779541\n",
      "train loss:0.8657703300019746\n",
      "train loss:0.8868470358693841\n",
      "train loss:0.8669921688535441\n",
      "train loss:0.7800113748537614\n",
      "train loss:0.8131030739785661\n",
      "train loss:0.876360071871118\n",
      "train loss:0.8440019891527751\n",
      "train loss:0.7756261115200437\n",
      "train loss:0.8008263533657279\n",
      "train loss:0.9002484290828404\n",
      "train loss:0.9933431641761861\n",
      "train loss:0.9247397225722955\n",
      "train loss:0.7784168512572138\n",
      "train loss:0.8536648326659517\n",
      "train loss:0.9071295571025351\n",
      "train loss:0.8502793639211241\n",
      "train loss:0.972274349542056\n",
      "train loss:0.8088660230834496\n",
      "train loss:0.9070635242096486\n",
      "train loss:0.8035978550377866\n",
      "train loss:0.8283578753123391\n",
      "train loss:0.9204112353633821\n",
      "train loss:1.0846007845467907\n",
      "train loss:0.8005675715617417\n",
      "train loss:0.7049985329787244\n",
      "train loss:0.7805066399473547\n",
      "train loss:0.709265413451208\n",
      "train loss:0.9367741850514567\n",
      "train loss:0.8210691155634942\n",
      "train loss:0.9106276112549988\n",
      "train loss:0.8012497217889942\n",
      "train loss:0.6200059535524383\n",
      "train loss:0.9076454986380904\n",
      "train loss:0.8469746761847748\n",
      "train loss:0.8568472058999422\n",
      "train loss:0.7844312162806752\n",
      "train loss:0.9228365437706322\n",
      "train loss:0.7339300858464042\n",
      "train loss:0.8869594177545049\n",
      "train loss:0.849866550061598\n",
      "train loss:0.8901003618765628\n",
      "train loss:0.820255452927073\n",
      "train loss:0.9483971606621899\n",
      "train loss:1.0369850841832953\n",
      "train loss:0.8659896621559103\n",
      "train loss:0.7112703195212445\n",
      "train loss:0.833282206567762\n",
      "train loss:0.9107862559194118\n",
      "train loss:0.928417387472161\n",
      "train loss:0.7690036355739287\n",
      "train loss:0.9751916278073355\n",
      "train loss:0.8182395005062046\n",
      "train loss:0.7871259589307527\n",
      "train loss:0.9164861830450775\n",
      "train loss:0.8580703669951468\n",
      "train loss:0.8723497531380627\n",
      "train loss:0.9462534313636186\n",
      "train loss:0.8631510007847223\n",
      "train loss:0.7790759416057024\n",
      "train loss:0.6593180969141252\n",
      "train loss:0.7758372695736299\n",
      "train loss:1.0048158985774711\n",
      "train loss:0.9402881655003954\n",
      "train loss:0.8579624107151098\n",
      "train loss:0.767880585844091\n",
      "train loss:0.964870240434391\n",
      "train loss:0.8821004651336024\n",
      "train loss:0.8143775677874691\n",
      "train loss:0.8197629814104271\n",
      "train loss:0.9735324128312048\n",
      "train loss:0.8388510066602692\n",
      "train loss:0.8513114168635703\n",
      "train loss:0.6230258602339687\n",
      "train loss:0.8368194344071549\n",
      "train loss:0.9702635690554727\n",
      "train loss:0.8621067482575704\n",
      "train loss:0.7461783050046887\n",
      "train loss:1.1555684943945497\n",
      "train loss:0.7875469601151244\n",
      "train loss:1.0632261905558862\n",
      "train loss:0.8467135619272826\n",
      "train loss:0.9755724119224877\n",
      "train loss:0.8602898477622021\n",
      "train loss:0.9177197112310662\n",
      "train loss:0.7997306969792269\n",
      "train loss:0.6195379711736609\n",
      "train loss:0.9826279341981075\n",
      "train loss:0.8748238883501638\n",
      "train loss:0.9781044685899666\n",
      "train loss:0.9715823862840063\n",
      "train loss:0.8811046705896476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.8650272437334592\n",
      "train loss:0.9243376682785285\n",
      "train loss:0.9727474935944859\n",
      "train loss:0.7936374661582173\n",
      "train loss:0.9195177644961283\n",
      "train loss:0.8679726227765121\n",
      "train loss:0.9106586101928669\n",
      "train loss:0.9295567828456265\n",
      "train loss:1.0273851160367078\n",
      "train loss:0.8898156583862188\n",
      "train loss:0.8440052188742438\n",
      "train loss:0.9518452263989076\n",
      "train loss:0.774855581313896\n",
      "train loss:0.8478732734434634\n",
      "train loss:0.7694477170003817\n",
      "train loss:0.854716103505571\n",
      "train loss:0.7977942527740416\n",
      "train loss:0.8688999628754039\n",
      "train loss:0.8029218579978987\n",
      "train loss:0.8516236609770867\n",
      "train loss:0.7875308758422592\n",
      "train loss:0.8350134379786502\n",
      "train loss:0.9288818089889824\n",
      "train loss:0.9246623293292658\n",
      "train loss:0.8346813798055104\n",
      "train loss:0.9916490555773221\n",
      "train loss:0.9285697262392634\n",
      "train loss:0.8208921691046435\n",
      "train loss:0.840399926104662\n",
      "train loss:1.1262793827783824\n",
      "train loss:0.8753243524360477\n",
      "train loss:0.8581425169952074\n",
      "train loss:0.840067937114868\n",
      "train loss:0.8025820502896427\n",
      "train loss:0.7827835723115687\n",
      "train loss:1.0083755948002326\n",
      "train loss:0.8920823671479841\n",
      "train loss:0.9864859950700882\n",
      "train loss:0.8717258494806781\n",
      "train loss:0.7793007210253916\n",
      "train loss:0.7612796812455472\n",
      "train loss:0.8688076427132729\n",
      "train loss:0.7870725440249476\n",
      "train loss:0.8830661800686453\n",
      "train loss:0.9588004681523767\n",
      "train loss:0.8339654886829385\n",
      "train loss:1.0353839061610757\n",
      "train loss:0.9452539862648109\n",
      "train loss:0.8351150431430452\n",
      "train loss:0.9163207505272399\n",
      "train loss:0.6915122152057822\n",
      "train loss:0.927605587082136\n",
      "train loss:1.021090773447088\n",
      "train loss:0.7923289640529323\n",
      "train loss:0.7566285378959587\n",
      "train loss:0.7033925766077257\n",
      "train loss:0.8442917650408889\n",
      "train loss:0.6525615480048863\n",
      "train loss:0.8547303680275111\n",
      "train loss:0.9029657066675193\n",
      "train loss:0.874904277328683\n",
      "train loss:0.8950071586112814\n",
      "train loss:0.8823651957192324\n",
      "train loss:0.6508342224458774\n",
      "train loss:0.9544468424832426\n",
      "train loss:0.8068773067464519\n",
      "train loss:0.7812170989350666\n",
      "train loss:0.8565426784055421\n",
      "train loss:0.6978287354484789\n",
      "train loss:0.9354162942382845\n",
      "train loss:0.8540124991670051\n",
      "train loss:0.7863903856527792\n",
      "=== epoch:13, train acc:0.997, test acc:0.992 ===\n",
      "train loss:0.9190154161053157\n",
      "train loss:0.758377169231168\n",
      "train loss:0.9367780991005132\n",
      "train loss:0.8495043729603795\n",
      "train loss:0.93240280995133\n",
      "train loss:0.7963907528456851\n",
      "train loss:0.9774269709218537\n",
      "train loss:0.7071340659850653\n",
      "train loss:0.7975120193899456\n",
      "train loss:0.6742600467632576\n",
      "train loss:1.0463830957340658\n",
      "train loss:0.8824939832076505\n",
      "train loss:0.9113805380138709\n",
      "train loss:0.9189622864516426\n",
      "train loss:1.0074845758612556\n",
      "train loss:0.8707452380637776\n",
      "train loss:0.6672689375114258\n",
      "train loss:1.0694289006317894\n",
      "train loss:0.932462623017541\n",
      "train loss:0.7928062104952072\n",
      "train loss:0.7850047642256799\n",
      "train loss:0.8963805993267652\n",
      "train loss:0.8053993099473797\n",
      "train loss:0.663495084666375\n",
      "train loss:0.8286579102624839\n",
      "train loss:0.9106707124560975\n",
      "train loss:0.7435756629779814\n",
      "train loss:0.8931811133988391\n",
      "train loss:0.7165836183728688\n",
      "train loss:0.7021606987758802\n",
      "train loss:0.9187136002417999\n",
      "train loss:0.8781948595536574\n",
      "train loss:0.7482207059197153\n",
      "train loss:0.85468992854654\n",
      "train loss:0.9415501870281469\n",
      "train loss:0.8228942914795938\n",
      "train loss:0.8108370510918315\n",
      "train loss:0.8299097320338454\n",
      "train loss:0.8878610360575385\n",
      "train loss:0.8837267554871427\n",
      "train loss:1.0786395637001542\n",
      "train loss:0.9088728892529139\n",
      "train loss:0.864562522737534\n",
      "train loss:0.9304540250120941\n",
      "train loss:0.9913267315507579\n",
      "train loss:0.9267758076476951\n",
      "train loss:0.8208585485014613\n",
      "train loss:0.8881812273809906\n",
      "train loss:0.8682749656279267\n",
      "train loss:0.8724636781830626\n",
      "train loss:0.6708608622753616\n",
      "train loss:0.9234641924632324\n",
      "train loss:0.930891916357189\n",
      "train loss:0.8093123015234851\n",
      "train loss:0.9091079892520552\n",
      "train loss:0.7882216509190453\n",
      "train loss:0.7915713451638208\n",
      "train loss:0.9566257501715028\n",
      "train loss:0.8690932864493465\n",
      "train loss:0.9365734338434518\n",
      "train loss:0.6779899744909065\n",
      "train loss:0.8396301390823518\n",
      "train loss:0.9065307373427045\n",
      "train loss:0.8540278978486003\n",
      "train loss:0.924216142195015\n",
      "train loss:0.7247349644440584\n",
      "train loss:0.9059535769030499\n",
      "train loss:0.912182604690597\n",
      "train loss:0.9298522275052039\n",
      "train loss:0.9710111531793149\n",
      "train loss:0.8982548523385904\n",
      "train loss:0.9491223310785242\n",
      "train loss:0.9002861094797442\n",
      "train loss:0.8021788591834926\n",
      "train loss:0.7418307994675513\n",
      "train loss:0.9144387694085988\n",
      "train loss:0.7168993930797207\n",
      "train loss:0.9527371679169997\n",
      "train loss:0.8947292381195617\n",
      "train loss:0.9233954196189019\n",
      "train loss:0.8680913051058868\n",
      "train loss:0.8055387104998186\n",
      "train loss:0.8756814643847065\n",
      "train loss:0.7678726575676192\n",
      "train loss:0.8891026969969259\n",
      "train loss:0.779102208185758\n",
      "train loss:0.768455147439496\n",
      "train loss:0.8008890204232251\n",
      "train loss:0.8169646598085442\n",
      "train loss:0.7364856808923507\n",
      "train loss:0.904735965349704\n",
      "train loss:0.7674541628799483\n",
      "train loss:0.8715932078827866\n",
      "train loss:0.9050252092316206\n",
      "train loss:0.9093404768979653\n",
      "train loss:0.8567726949126988\n",
      "train loss:0.9295015074345363\n",
      "train loss:1.0432367402396552\n",
      "train loss:0.7421906922558705\n",
      "train loss:0.8461853026988301\n",
      "train loss:1.0756213809047785\n",
      "train loss:0.7986400578911892\n",
      "train loss:0.9574418428295145\n",
      "train loss:0.9476661335982116\n",
      "train loss:0.8690992782481906\n",
      "train loss:0.8640575323893936\n",
      "train loss:0.9921812161242464\n",
      "train loss:0.8503390685722825\n",
      "train loss:0.917568876458844\n",
      "train loss:0.832458783375012\n",
      "train loss:0.8893122768362509\n",
      "train loss:0.8524199887398496\n",
      "train loss:0.8609643392053574\n",
      "train loss:0.8231611612696436\n",
      "train loss:0.8238086111028496\n",
      "train loss:0.9395699074101462\n",
      "train loss:0.8384009391057607\n",
      "train loss:0.8112252019576843\n",
      "train loss:0.9295272922121633\n",
      "train loss:0.9186224690632959\n",
      "train loss:0.8083056450974321\n",
      "train loss:0.860988581729341\n",
      "train loss:0.7096814684635052\n",
      "train loss:0.847929469770685\n",
      "train loss:0.9606000615452269\n",
      "train loss:0.8541397244118527\n",
      "train loss:0.9969337610151656\n",
      "train loss:0.926609819552261\n",
      "train loss:0.8906935964810839\n",
      "train loss:1.0169151853475757\n",
      "train loss:0.8473654596516164\n",
      "train loss:0.5796539761842116\n",
      "train loss:0.8570167364827498\n",
      "train loss:0.7617381729183862\n",
      "train loss:0.8287788678780216\n",
      "train loss:0.9495536051445101\n",
      "train loss:0.9284255392405741\n",
      "train loss:1.0140499706685084\n",
      "train loss:0.9889424466246741\n",
      "train loss:1.03735432577484\n",
      "train loss:0.8482474311496178\n",
      "train loss:0.8317269096338075\n",
      "train loss:0.6940605342778251\n",
      "train loss:0.8412703011044834\n",
      "train loss:1.04588397318314\n",
      "train loss:0.88973814564233\n",
      "train loss:0.769230970211218\n",
      "train loss:0.8179882038910864\n",
      "train loss:0.7506183984643765\n",
      "train loss:0.8128061256048673\n",
      "train loss:0.8220004216093563\n",
      "train loss:0.8924130806640622\n",
      "train loss:0.6539832390094638\n",
      "train loss:0.6856462952817536\n",
      "train loss:0.9402153844121309\n",
      "train loss:0.8443352334067663\n",
      "train loss:0.937463684790297\n",
      "train loss:0.9207932844922797\n",
      "train loss:0.8392658771808041\n",
      "train loss:0.8156454513120415\n",
      "train loss:0.9124858885329412\n",
      "train loss:0.8771952873606856\n",
      "train loss:0.9295777383703396\n",
      "train loss:0.8820445208816763\n",
      "train loss:0.8340305434463159\n",
      "train loss:0.7444945975420815\n",
      "train loss:0.757356053339249\n",
      "train loss:0.8502693575597631\n",
      "train loss:0.9005555271849457\n",
      "train loss:0.7531666648159184\n",
      "train loss:0.8583630206752798\n",
      "train loss:0.9244866033624511\n",
      "train loss:0.8906285972884055\n",
      "train loss:0.8922537714049406\n",
      "train loss:0.9545986152776551\n",
      "train loss:0.9421411327574031\n",
      "train loss:0.9098362062924589\n",
      "train loss:0.8684377890779235\n",
      "train loss:0.7113456760509164\n",
      "train loss:0.8237708614571048\n",
      "train loss:0.8224045067787387\n",
      "train loss:0.9244052196196764\n",
      "train loss:0.9059356400921765\n",
      "train loss:1.0519799559514145\n",
      "train loss:0.7394018284240235\n",
      "train loss:0.8224593700488799\n",
      "train loss:0.7308932575335366\n",
      "train loss:0.8765326515714409\n",
      "train loss:0.8069682160174466\n",
      "train loss:0.8159888268226585\n",
      "train loss:0.8000153025871956\n",
      "train loss:0.8710068377935407\n",
      "train loss:0.8545030307004798\n",
      "train loss:0.8109292636983783\n",
      "train loss:0.9181265780267448\n",
      "train loss:0.923446923761318\n",
      "train loss:0.830835408879108\n",
      "train loss:0.9107379507059532\n",
      "train loss:0.8869576340270799\n",
      "train loss:0.7953314130215999\n",
      "train loss:1.0396137692211485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.8258749398158894\n",
      "train loss:0.9040730858276723\n",
      "train loss:0.9996349573509525\n",
      "train loss:0.8310248777070066\n",
      "train loss:0.9429377693152285\n",
      "train loss:0.9691111445242323\n",
      "train loss:0.7091610259171911\n",
      "train loss:0.7845702922730043\n",
      "train loss:0.7141811459624336\n",
      "train loss:0.9470014442334599\n",
      "train loss:0.8596379805813662\n",
      "train loss:0.7399704549692518\n",
      "train loss:0.9044761351798424\n",
      "train loss:0.8791763446460169\n",
      "train loss:0.9122336887763588\n",
      "train loss:0.8935910006826815\n",
      "train loss:0.8956645061439183\n",
      "train loss:0.7958645998203683\n",
      "train loss:0.8297805506501439\n",
      "train loss:0.9961604375582961\n",
      "train loss:0.8793348224800023\n",
      "train loss:0.6779534730088648\n",
      "train loss:0.7560896162835141\n",
      "train loss:0.9670853569763868\n",
      "train loss:0.8717184928094427\n",
      "train loss:0.832694833042423\n",
      "train loss:0.851115348688398\n",
      "train loss:0.7578208582854247\n",
      "train loss:0.9846370180958375\n",
      "train loss:1.0465867027390081\n",
      "train loss:0.8935658984215357\n",
      "train loss:0.933781890606455\n",
      "train loss:0.8588854544519008\n",
      "train loss:0.9050207333659088\n",
      "train loss:0.8712039712870957\n",
      "train loss:0.8217792970214087\n",
      "train loss:0.6864128724813368\n",
      "train loss:0.8314692467554171\n",
      "train loss:0.7843295338571831\n",
      "train loss:0.9633707694107905\n",
      "train loss:0.8582127875792611\n",
      "train loss:1.0104746522609163\n",
      "train loss:0.856545146210413\n",
      "train loss:0.7803939713475389\n",
      "train loss:0.7955231039297642\n",
      "train loss:0.8820904321029839\n",
      "train loss:0.891307778498322\n",
      "train loss:0.8421830886438225\n",
      "train loss:0.7415278761456727\n",
      "train loss:1.0342945970795776\n",
      "train loss:0.8465550106714158\n",
      "train loss:0.9252149779694011\n",
      "train loss:0.8372048299334923\n",
      "train loss:0.826732523866513\n",
      "train loss:0.952561877342642\n",
      "train loss:0.8834249446273152\n",
      "train loss:0.9032772817311548\n",
      "train loss:0.904379971119006\n",
      "train loss:0.9204337699323552\n",
      "train loss:0.9320109225222635\n",
      "train loss:0.9089193119587581\n",
      "train loss:0.8153218479134778\n",
      "train loss:0.8462285170243125\n",
      "train loss:0.9494388162659192\n",
      "train loss:0.8112973302941876\n",
      "train loss:0.9268940063501279\n",
      "train loss:0.9677409076355721\n",
      "train loss:0.7353970959503259\n",
      "train loss:0.8155436659888121\n",
      "train loss:0.820667384535808\n",
      "train loss:0.8486480551142079\n",
      "train loss:0.7655531899552398\n",
      "train loss:1.014893152801077\n",
      "train loss:0.8473692581030164\n",
      "train loss:0.83268649154179\n",
      "train loss:0.7535626308333525\n",
      "train loss:0.9077234087800201\n",
      "train loss:0.9225016006943899\n",
      "train loss:0.8705819111542574\n",
      "train loss:0.8260915973480552\n",
      "train loss:0.8612436279814207\n",
      "train loss:1.0167135783616306\n",
      "train loss:0.8263039381667541\n",
      "train loss:0.7160855540047266\n",
      "train loss:0.8958078348687567\n",
      "train loss:0.8519228144230722\n",
      "train loss:0.94281635644903\n",
      "train loss:0.7607810260618082\n",
      "train loss:0.7959920940409262\n",
      "train loss:0.803947821948058\n",
      "train loss:0.8499379582776398\n",
      "train loss:0.891239548929563\n",
      "train loss:0.9549185250395573\n",
      "train loss:0.9955712900672324\n",
      "train loss:0.9394137134152427\n",
      "train loss:0.7791503624275684\n",
      "train loss:0.8032930826903817\n",
      "train loss:0.7989792768147984\n",
      "train loss:0.8759250206205073\n",
      "train loss:0.8962499969704605\n",
      "train loss:0.8536363325432638\n",
      "train loss:0.9477354555365678\n",
      "train loss:0.8974768165190267\n",
      "train loss:0.886391827327618\n",
      "train loss:0.900447776869348\n",
      "train loss:0.8016513850205622\n",
      "train loss:0.7607924067384577\n",
      "train loss:0.9597705315635813\n",
      "train loss:0.8752751164025829\n",
      "train loss:0.843947717118159\n",
      "train loss:0.7954170558336461\n",
      "train loss:0.8632172191000355\n",
      "train loss:0.7859826100477566\n",
      "train loss:0.9973007105851933\n",
      "train loss:0.9217025768830506\n",
      "train loss:0.9061507268770811\n",
      "train loss:0.7110674157952548\n",
      "train loss:0.9220329853402259\n",
      "train loss:0.9024185767913719\n",
      "train loss:0.7276409987392752\n",
      "train loss:0.860348898472662\n",
      "train loss:0.6556852862802103\n",
      "train loss:0.6727199378571207\n",
      "train loss:0.8979120384420842\n",
      "train loss:0.7616022037392882\n",
      "train loss:0.9605397775970055\n",
      "train loss:0.8158573669714866\n",
      "train loss:0.6811219403731755\n",
      "train loss:0.9039741488527531\n",
      "train loss:0.9437462426617889\n",
      "train loss:0.9975802736421413\n",
      "train loss:0.8630965924430479\n",
      "train loss:0.804508155701336\n",
      "train loss:0.8676861900790849\n",
      "train loss:0.7502356268715173\n",
      "train loss:0.8390837123009705\n",
      "train loss:1.1489510725678063\n",
      "train loss:0.7695805461329539\n",
      "train loss:0.8187174181130369\n",
      "train loss:1.0696935729888521\n",
      "train loss:0.7782954324042793\n",
      "train loss:0.6433244600592749\n",
      "train loss:1.0301006855561448\n",
      "train loss:0.7818399630721277\n",
      "train loss:0.7432522332051709\n",
      "train loss:1.0238338017856123\n",
      "train loss:0.832415937863111\n",
      "train loss:0.8948589810480722\n",
      "train loss:0.8634624127987258\n",
      "train loss:0.7614407565224858\n",
      "train loss:0.9516819237071438\n",
      "train loss:0.6751807281675649\n",
      "train loss:0.9011716764375555\n",
      "train loss:0.888401849537481\n",
      "train loss:0.925431904073945\n",
      "train loss:0.6409951163652798\n",
      "train loss:0.856934843035415\n",
      "train loss:0.7617466526036607\n",
      "train loss:0.9133522389206441\n",
      "train loss:0.9598308953395878\n",
      "train loss:1.128324849296974\n",
      "train loss:0.9654579265159116\n",
      "train loss:0.887795834759816\n",
      "train loss:0.8447340426404806\n",
      "train loss:0.8308130982238862\n",
      "train loss:0.7451007690350334\n",
      "train loss:0.9334092760151808\n",
      "train loss:0.902610000172113\n",
      "train loss:0.8790082716085482\n",
      "train loss:0.9075714921907331\n",
      "train loss:0.9242069008748588\n",
      "train loss:0.8151009523434641\n",
      "train loss:0.7908234991050129\n",
      "train loss:0.731797499560843\n",
      "train loss:0.7659722522619906\n",
      "train loss:0.887832148825973\n",
      "train loss:0.7640687444910219\n",
      "train loss:0.9994398491678786\n",
      "train loss:0.756237105100911\n",
      "train loss:0.8413089481411191\n",
      "train loss:0.9217513158451682\n",
      "train loss:0.820069554967678\n",
      "train loss:0.9205127847556609\n",
      "train loss:0.7979680924642253\n",
      "train loss:0.8045833130225865\n",
      "train loss:0.8658205077075194\n",
      "train loss:0.7969718028526003\n",
      "train loss:0.6812655360603987\n",
      "train loss:0.8200820572842844\n",
      "train loss:0.9398305969577317\n",
      "train loss:0.986486775604224\n",
      "train loss:0.8515083324731075\n",
      "train loss:0.8681184009654046\n",
      "train loss:0.9164408476062319\n",
      "train loss:0.9236995206839616\n",
      "train loss:0.8354057383968763\n",
      "train loss:0.9918267776016052\n",
      "train loss:0.9005383533474651\n",
      "train loss:0.8390756928301843\n",
      "train loss:0.9348143927957427\n",
      "train loss:0.8433471103862709\n",
      "train loss:0.7988355850268861\n",
      "train loss:0.7941937964809204\n",
      "train loss:0.8517942566279976\n",
      "train loss:0.7914744990008739\n",
      "train loss:1.0011766610028672\n",
      "train loss:0.9371042118857923\n",
      "train loss:0.8146791457210786\n",
      "train loss:0.8222416447469781\n",
      "train loss:0.8238211713771758\n",
      "train loss:1.016602764477083\n",
      "train loss:0.7260122831496783\n",
      "train loss:0.7843200535548327\n",
      "train loss:0.8811686199953543\n",
      "train loss:1.0391010668958105\n",
      "train loss:0.8114139862697146\n",
      "train loss:0.6448203707222797\n",
      "train loss:0.9586090906637525\n",
      "train loss:0.8439511240550425\n",
      "train loss:0.7482463409924109\n",
      "train loss:1.1582384913874413\n",
      "train loss:0.9593901552244806\n",
      "train loss:0.958794946001908\n",
      "train loss:0.7515041426042712\n",
      "train loss:0.9146439873331978\n",
      "train loss:0.8302270295883883\n",
      "train loss:1.0017168382349093\n",
      "train loss:0.7717067403509884\n",
      "train loss:0.874747533513953\n",
      "train loss:0.8963519163634159\n",
      "train loss:0.9671697710231658\n",
      "train loss:0.6509491892335336\n",
      "train loss:0.7665155478727346\n",
      "train loss:0.8240901605391778\n",
      "train loss:0.8922365000417402\n",
      "train loss:0.931138727939875\n",
      "train loss:0.8128838044948775\n",
      "train loss:0.7118740677761913\n",
      "train loss:0.7847142971626632\n",
      "train loss:1.0091073655012035\n",
      "train loss:0.8747148458349747\n",
      "train loss:0.8484622011062024\n",
      "train loss:0.9911235703794021\n",
      "train loss:0.7990097290025063\n",
      "train loss:0.8144341255750632\n",
      "train loss:0.9694807373157004\n",
      "train loss:0.8916948619050649\n",
      "train loss:0.8643166032364126\n",
      "train loss:0.7296336294309858\n",
      "train loss:0.8921520841566689\n",
      "train loss:0.7407521830794304\n",
      "train loss:0.8915900014666711\n",
      "train loss:0.9209210014472872\n",
      "train loss:0.937838163052057\n",
      "train loss:1.0315754357914404\n",
      "train loss:1.0161928096373352\n",
      "train loss:0.9240627915890015\n",
      "train loss:0.8508319759819856\n",
      "train loss:0.8140679597883224\n",
      "train loss:0.9730319728754061\n",
      "train loss:0.834719853668296\n",
      "train loss:0.7560577650664321\n",
      "train loss:0.7326606860724411\n",
      "train loss:0.847397648726958\n",
      "train loss:0.8347358347617321\n",
      "train loss:0.7511947003735309\n",
      "train loss:0.7793968567533436\n",
      "train loss:0.9744189010183711\n",
      "train loss:0.9155422216262895\n",
      "train loss:0.9367576250882935\n",
      "train loss:1.0243754339644513\n",
      "train loss:0.8216464704457925\n",
      "train loss:0.7466972533390093\n",
      "train loss:0.7148372106694328\n",
      "train loss:0.7843154320552648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.9778277178195127\n",
      "train loss:0.7605384603004662\n",
      "train loss:0.6674758036419997\n",
      "train loss:0.9672070134069627\n",
      "train loss:0.9813897659520957\n",
      "train loss:0.8166646968929495\n",
      "train loss:0.7252028063560627\n",
      "train loss:0.7916224983087083\n",
      "train loss:0.8158004207540828\n",
      "train loss:0.8617794878180061\n",
      "train loss:0.9674650470519421\n",
      "train loss:0.74554232119451\n",
      "train loss:0.9185635111966277\n",
      "train loss:0.863645754734486\n",
      "train loss:0.8081616372073992\n",
      "train loss:0.8099317619415316\n",
      "train loss:0.8221671500873807\n",
      "train loss:0.9867919395697184\n",
      "train loss:0.8138146639521132\n",
      "train loss:0.8176907962436026\n",
      "train loss:0.8868713087379999\n",
      "train loss:0.7356236576684522\n",
      "train loss:0.9190785343752842\n",
      "train loss:0.9380420076013621\n",
      "train loss:0.7208071775582912\n",
      "train loss:0.7981952812636653\n",
      "train loss:0.6764169369131132\n",
      "train loss:0.8887503678678946\n",
      "train loss:0.8180739981043437\n",
      "train loss:0.8895683599750419\n",
      "train loss:0.8023326245255792\n",
      "train loss:0.8130200177434779\n",
      "train loss:0.8793076801915026\n",
      "train loss:0.6898362293827972\n",
      "train loss:0.8219349526790244\n",
      "train loss:0.7400589018898849\n",
      "train loss:0.8619014080186664\n",
      "train loss:0.6563528933472945\n",
      "train loss:0.9225914040792658\n",
      "train loss:0.8011954404121718\n",
      "train loss:0.856122631173685\n",
      "train loss:0.8487725732546548\n",
      "train loss:0.8606245902180756\n",
      "train loss:0.917908619522151\n",
      "train loss:0.9843345511859313\n",
      "train loss:0.8340750008040869\n",
      "train loss:0.802806696909779\n",
      "train loss:0.9897556860855768\n",
      "train loss:0.9266101247534279\n",
      "train loss:0.8170662721030942\n",
      "train loss:0.9732845034874735\n",
      "train loss:0.9747927835515103\n",
      "train loss:0.8664317161039125\n",
      "train loss:0.8979136890550293\n",
      "train loss:1.0039240951330948\n",
      "train loss:0.9516268860221018\n",
      "train loss:0.9789685333764047\n",
      "train loss:0.9614119572293075\n",
      "train loss:0.9883807761525246\n",
      "train loss:0.8887837773565375\n",
      "train loss:0.8109649364834578\n",
      "train loss:0.8694278118061368\n",
      "train loss:0.9835982180625686\n",
      "train loss:0.7807537123589928\n",
      "train loss:0.9486704043730744\n",
      "train loss:0.9849551413894411\n",
      "train loss:0.8613308331105304\n",
      "train loss:0.7335072119149595\n",
      "train loss:0.850615224350999\n",
      "train loss:0.799358656473454\n",
      "train loss:0.8768365341716974\n",
      "train loss:0.6410536126621216\n",
      "train loss:0.8245375391257969\n",
      "train loss:0.6826754491483956\n",
      "train loss:0.8582801932606792\n",
      "train loss:0.8094494571399341\n",
      "train loss:0.8848435508060635\n",
      "train loss:0.7884947940953643\n",
      "train loss:0.8151958050177254\n",
      "train loss:0.8121772119720215\n",
      "train loss:0.7341138524175115\n",
      "train loss:0.6774909433882573\n",
      "train loss:1.1233920049616142\n",
      "train loss:0.8996223433944845\n",
      "train loss:0.9300277545666282\n",
      "train loss:0.8338884234452237\n",
      "train loss:1.0572559240102481\n",
      "train loss:0.9656468015071842\n",
      "train loss:0.8979605555844352\n",
      "train loss:0.8171976058729897\n",
      "train loss:0.7696088796969857\n",
      "train loss:0.8794397511693259\n",
      "train loss:0.7436529494815123\n",
      "train loss:0.8714790269572261\n",
      "train loss:0.9260889635615382\n",
      "train loss:0.8371866548705392\n",
      "train loss:0.8069592792709643\n",
      "train loss:0.8048860532825626\n",
      "train loss:0.6662222722814054\n",
      "train loss:0.9207867854033512\n",
      "train loss:0.7857225390528473\n",
      "train loss:0.9592967215230042\n",
      "train loss:0.9594975947212718\n",
      "train loss:0.8778217578531806\n",
      "train loss:0.9946644925322589\n",
      "train loss:0.8171166942993722\n",
      "train loss:1.0394568375119413\n",
      "train loss:0.9044466051777498\n",
      "train loss:0.9098199589609915\n",
      "train loss:0.8702881922035617\n",
      "train loss:0.7992785345876675\n",
      "train loss:0.82379775753969\n",
      "train loss:0.8638528325143442\n",
      "train loss:0.8489929090413755\n",
      "train loss:0.8213016632038448\n",
      "train loss:0.9856662523416169\n",
      "train loss:0.8101427597982672\n",
      "train loss:0.859673827868648\n",
      "train loss:0.7563450484036878\n",
      "train loss:0.7956879228025829\n",
      "train loss:0.9685914135803874\n",
      "train loss:0.8400429788502481\n",
      "train loss:0.9238546586119696\n",
      "train loss:0.9333664119055863\n",
      "=== epoch:14, train acc:0.998, test acc:0.994 ===\n",
      "train loss:0.7925619841290394\n",
      "train loss:0.7267379660878583\n",
      "train loss:0.888524620599458\n",
      "train loss:0.9497668621427132\n",
      "train loss:0.8005474774876545\n",
      "train loss:0.8372247429391063\n",
      "train loss:0.8985934766369705\n",
      "train loss:0.9768257408897653\n",
      "train loss:0.8680549273742671\n",
      "train loss:0.9005338514142607\n",
      "train loss:0.8637368856513039\n",
      "train loss:0.8104515620787796\n",
      "train loss:0.6667700379669852\n",
      "train loss:1.0147765298430593\n",
      "train loss:0.8503495569773886\n",
      "train loss:0.9059227346119352\n",
      "train loss:0.8082992678107445\n",
      "train loss:0.9236504382389037\n",
      "train loss:0.8324761332949082\n",
      "train loss:1.164650818970832\n",
      "train loss:0.9141781476719048\n",
      "train loss:0.7035812019584953\n",
      "train loss:0.9459824883855574\n",
      "train loss:0.7928383850567652\n",
      "train loss:0.7413190989945937\n",
      "train loss:0.8479722553632036\n",
      "train loss:0.861188620477868\n",
      "train loss:1.0179447514779414\n",
      "train loss:0.8722352776996938\n",
      "train loss:0.8754353518763351\n",
      "train loss:0.8801861875857666\n",
      "train loss:0.8366898486215593\n",
      "train loss:0.8078689070421163\n",
      "train loss:0.8205455057489508\n",
      "train loss:0.6988629330995652\n",
      "train loss:0.8185938976927257\n",
      "train loss:0.9648513725141197\n",
      "train loss:0.8159058445747113\n",
      "train loss:0.8780165250430326\n",
      "train loss:0.7305248299529901\n",
      "train loss:0.6358272617387196\n",
      "train loss:0.908522437487753\n",
      "train loss:1.0634203411950096\n",
      "train loss:0.7667686067187596\n",
      "train loss:0.8538359728013062\n",
      "train loss:1.0087372576874316\n",
      "train loss:0.9558108618215678\n",
      "train loss:0.8272028266918184\n",
      "train loss:0.9909030580197272\n",
      "train loss:0.7655183724194157\n",
      "train loss:0.7516069249076875\n",
      "train loss:0.9325049954468545\n",
      "train loss:0.8489787348381551\n",
      "train loss:0.8515377995843458\n",
      "train loss:0.8146889912979516\n",
      "train loss:0.8726495829546748\n",
      "train loss:0.9156579727455672\n",
      "train loss:0.8330563602859192\n",
      "train loss:0.6753788638014455\n",
      "train loss:0.7350062506804843\n",
      "train loss:0.9032324086557446\n",
      "train loss:0.8557854495877006\n",
      "train loss:0.9071870050296964\n",
      "train loss:0.876994909720952\n",
      "train loss:0.8768447707598004\n",
      "train loss:0.7463842386967982\n",
      "train loss:0.7822348909751647\n",
      "train loss:0.8786918714944499\n",
      "train loss:0.8175955504090063\n",
      "train loss:1.0007601284650804\n",
      "train loss:0.8584695062728\n",
      "train loss:0.8147747524123519\n",
      "train loss:0.8344991947914547\n",
      "train loss:0.8543236428872225\n",
      "train loss:0.8891694091720578\n",
      "train loss:0.9020506786349284\n",
      "train loss:0.7821258229689417\n",
      "train loss:0.8274516738526585\n",
      "train loss:0.9004448707091154\n",
      "train loss:0.8673752206472594\n",
      "train loss:0.7759204581300605\n",
      "train loss:0.8827857495353295\n",
      "train loss:0.9268759305451347\n",
      "train loss:0.9611404060389225\n",
      "train loss:0.9502181483550742\n",
      "train loss:0.8862190175631642\n",
      "train loss:0.9823141134045871\n",
      "train loss:1.0118576228896483\n",
      "train loss:1.0288060478207002\n",
      "train loss:0.727262967734517\n",
      "train loss:0.7495668217994644\n",
      "train loss:0.8085563598444776\n",
      "train loss:0.874138925421904\n",
      "train loss:0.7892464048835686\n",
      "train loss:0.7986900128245703\n",
      "train loss:1.0056028051931074\n",
      "train loss:1.0403650104133664\n",
      "train loss:0.9536063272589942\n",
      "train loss:0.8313280238102885\n",
      "train loss:0.8429846671063785\n",
      "train loss:0.9682604971500862\n",
      "train loss:0.8228120619329375\n",
      "train loss:0.8634873828850245\n",
      "train loss:0.9772696466477345\n",
      "train loss:0.8379829435948575\n",
      "train loss:0.9508625179272034\n",
      "train loss:0.8657527418957229\n",
      "train loss:0.9915813802404262\n",
      "train loss:0.9029273893388355\n",
      "train loss:0.6564326213211997\n",
      "train loss:0.8325574939411375\n",
      "train loss:0.8948749132960239\n",
      "train loss:0.7011041050269656\n",
      "train loss:0.7835455982546183\n",
      "train loss:0.8810848772968548\n",
      "train loss:0.8655881175882074\n",
      "train loss:0.8981959101185543\n",
      "train loss:0.9062389692649844\n",
      "train loss:0.7000801950780046\n",
      "train loss:0.7926765444108418\n",
      "train loss:0.8466898102190881\n",
      "train loss:0.9876947223080136\n",
      "train loss:0.7436863242106321\n",
      "train loss:1.0359419085344783\n",
      "train loss:0.9140457100845636\n",
      "train loss:0.6784708692032493\n",
      "train loss:0.7467544909216778\n",
      "train loss:0.837073684459822\n",
      "train loss:0.9528922290707055\n",
      "train loss:0.7586248199358258\n",
      "train loss:0.9125997050648779\n",
      "train loss:0.7939553795183995\n",
      "train loss:0.8094107119405947\n",
      "train loss:0.9958690529241153\n",
      "train loss:0.8589098037104855\n",
      "train loss:0.7943701177557331\n",
      "train loss:0.8434060588279341\n",
      "train loss:0.8993494457128085\n",
      "train loss:0.8256160796892918\n",
      "train loss:0.8575269253179967\n",
      "train loss:1.0397982939108887\n",
      "train loss:0.6600353734896933\n",
      "train loss:0.8459657031284319\n",
      "train loss:0.7833466103705226\n",
      "train loss:0.941304163229601\n",
      "train loss:0.8343926695438283\n",
      "train loss:0.7104670128909882\n",
      "train loss:0.7625095122244173\n",
      "train loss:0.9378127415034241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.9565001958831941\n",
      "train loss:0.8352632071136641\n",
      "train loss:0.7201606393781383\n",
      "train loss:0.8635994490445971\n",
      "train loss:0.7428135448525504\n",
      "train loss:0.8390417456337228\n",
      "train loss:0.8449239771413976\n",
      "train loss:0.8472912229872223\n",
      "train loss:0.894787505910828\n",
      "train loss:0.8535307087932594\n",
      "train loss:0.7920031056409157\n",
      "train loss:0.9497265961978143\n",
      "train loss:0.9333553767308088\n",
      "train loss:0.7845152127205255\n",
      "train loss:0.9669015972757079\n",
      "train loss:0.789790952506399\n",
      "train loss:1.0348323037046259\n",
      "train loss:0.813134954000293\n",
      "train loss:0.9649998498414751\n",
      "train loss:0.8653367849983812\n",
      "train loss:1.0324366968120435\n",
      "train loss:0.7719830911320311\n",
      "train loss:0.924606425041642\n",
      "train loss:0.9906052846180128\n",
      "train loss:0.8692625439762104\n",
      "train loss:0.8985820691190741\n",
      "train loss:0.9808711281498097\n",
      "train loss:0.7526088929096078\n",
      "train loss:0.8189332957095701\n",
      "train loss:0.9090648023030541\n",
      "train loss:0.97201527002225\n",
      "train loss:0.7706942235287029\n",
      "train loss:0.8491910972705032\n",
      "train loss:0.8468643917867174\n",
      "train loss:0.9079064842215655\n",
      "train loss:0.8666871978380118\n",
      "train loss:0.8869568683343333\n",
      "train loss:0.8922315585913814\n",
      "train loss:0.8231958935404129\n",
      "train loss:0.8764738911121607\n",
      "train loss:0.5974021185667191\n",
      "train loss:0.7863763646925662\n",
      "train loss:0.8968232016023678\n",
      "train loss:1.0480867213011662\n",
      "train loss:0.874256585367494\n",
      "train loss:0.8636157379691274\n",
      "train loss:0.9290181740417229\n",
      "train loss:0.9528118792656969\n",
      "train loss:0.8634227715520625\n",
      "train loss:0.8080005855394596\n",
      "train loss:0.8521783274971892\n",
      "train loss:0.7171044404945477\n",
      "train loss:0.8700865492814224\n",
      "train loss:0.9236377078068719\n",
      "train loss:0.9089152800378055\n",
      "train loss:0.9321023400610738\n",
      "train loss:0.750702179109821\n",
      "train loss:0.7679983718195722\n",
      "train loss:0.6814488133076366\n",
      "train loss:1.038830260442231\n",
      "train loss:0.7883277850554629\n",
      "train loss:1.0433418117085622\n",
      "train loss:0.7679004427673108\n",
      "train loss:0.8571140068619039\n",
      "train loss:0.8225120063997362\n",
      "train loss:0.7659968474666438\n",
      "train loss:1.0823459409523268\n",
      "train loss:0.746202367554903\n",
      "train loss:0.9150117455736553\n",
      "train loss:0.9033320371266411\n",
      "train loss:0.7617808421978784\n",
      "train loss:0.9376385128655452\n",
      "train loss:0.9313264444754185\n",
      "train loss:0.6326113503948316\n",
      "train loss:0.8392722835891658\n",
      "train loss:0.893042452392584\n",
      "train loss:0.7542923894895256\n",
      "train loss:1.0469559764581955\n",
      "train loss:0.9444797971516894\n",
      "train loss:0.8915129620448351\n",
      "train loss:0.9822173543099327\n",
      "train loss:0.7178543866981789\n",
      "train loss:0.9127349687141213\n",
      "train loss:0.8841956134418981\n",
      "train loss:0.9221525490674144\n",
      "train loss:0.6854124355068809\n",
      "train loss:0.8941751731211692\n",
      "train loss:1.0219136624652745\n",
      "train loss:0.8801167505272355\n",
      "train loss:0.9414383468304792\n",
      "train loss:0.9423416250516246\n",
      "train loss:1.0427017088426915\n",
      "train loss:0.7606066745679625\n",
      "train loss:0.753928666358126\n",
      "train loss:0.8921444255700689\n",
      "train loss:0.8128698158335942\n",
      "train loss:0.9248042900020996\n",
      "train loss:0.7808042687779304\n",
      "train loss:0.8172872749755807\n",
      "train loss:0.7518677138256252\n",
      "train loss:0.8688625595225252\n",
      "train loss:0.7413131833021389\n",
      "train loss:0.8569086114184988\n",
      "train loss:0.8318036835652461\n",
      "train loss:0.8602243754337566\n",
      "train loss:0.8413898880130912\n",
      "train loss:0.8742742765917175\n",
      "train loss:0.730656749057174\n",
      "train loss:0.857565122760104\n",
      "train loss:0.7904184049147795\n",
      "train loss:0.8013161494911852\n",
      "train loss:0.9297924583688871\n",
      "train loss:0.8840429499628667\n",
      "train loss:0.7822672445692066\n",
      "train loss:0.7851038062150651\n",
      "train loss:1.0960927022590754\n",
      "train loss:0.8131814425668388\n",
      "train loss:0.7849281463464483\n",
      "train loss:0.8298869135399006\n",
      "train loss:1.0722836501835482\n",
      "train loss:0.7139967840525953\n",
      "train loss:0.9283489128449653\n",
      "train loss:0.8219251666879345\n",
      "train loss:0.6835174783684091\n",
      "train loss:0.866716558628596\n",
      "train loss:1.0218150278642761\n",
      "train loss:0.9584878944993446\n",
      "train loss:0.8222644549720965\n",
      "train loss:1.00525887049161\n",
      "train loss:0.7500319547734458\n",
      "train loss:0.849759317948334\n",
      "train loss:0.7272428559193793\n",
      "train loss:0.9707649862958742\n",
      "train loss:0.7631473584215175\n",
      "train loss:0.9563941603098666\n",
      "train loss:0.8388453467956402\n",
      "train loss:0.9704966633077992\n",
      "train loss:0.8162848387209916\n",
      "train loss:0.6624514219610705\n",
      "train loss:0.8718144160700035\n",
      "train loss:0.8697896682981591\n",
      "train loss:0.9250975842233974\n",
      "train loss:0.8675394077021669\n",
      "train loss:0.8564395892854662\n",
      "train loss:0.8054567769184322\n",
      "train loss:0.8446309569770443\n",
      "train loss:0.8052477921378411\n",
      "train loss:0.8626525329447494\n",
      "train loss:0.9619049790952423\n",
      "train loss:0.8828546369080101\n",
      "train loss:0.7964390110906335\n",
      "train loss:0.8924794331559843\n",
      "train loss:0.8217036284307584\n",
      "train loss:0.9524484673317418\n",
      "train loss:0.8998299844640969\n",
      "train loss:0.8098647419883409\n",
      "train loss:0.6890813302945741\n",
      "train loss:0.9374746331307695\n",
      "train loss:0.9658267433778558\n",
      "train loss:0.8974290037868158\n",
      "train loss:0.935373242150314\n",
      "train loss:0.8677253899857377\n",
      "train loss:0.8225245807274694\n",
      "train loss:0.8965344694433266\n",
      "train loss:0.938788436203366\n",
      "train loss:0.8220358242384853\n",
      "train loss:0.7445074387159173\n",
      "train loss:0.7248399800415979\n",
      "train loss:0.9088598196931581\n",
      "train loss:0.7779637890407719\n",
      "train loss:0.873645871671447\n",
      "train loss:0.8806411693241377\n",
      "train loss:0.9842071359228853\n",
      "train loss:0.9747909652460744\n",
      "train loss:0.8337209701188284\n",
      "train loss:0.8243047029871949\n",
      "train loss:0.7812751602639899\n",
      "train loss:1.0203903245929318\n",
      "train loss:0.9140586638376056\n",
      "train loss:0.6057985650572654\n",
      "train loss:0.846104650263967\n",
      "train loss:0.8572327840067993\n",
      "train loss:0.8275501301971139\n",
      "train loss:0.9006204137403796\n",
      "train loss:0.8485489153646903\n",
      "train loss:0.7727296386737806\n",
      "train loss:0.9931834203052784\n",
      "train loss:0.7180316418231826\n",
      "train loss:0.7461270166725775\n",
      "train loss:0.7333195604389708\n",
      "train loss:0.841055824746042\n",
      "train loss:0.8708516733106932\n",
      "train loss:0.8146400828465513\n",
      "train loss:0.8042823849987891\n",
      "train loss:0.9924601114900624\n",
      "train loss:0.8084213251308167\n",
      "train loss:0.8708868140651336\n",
      "train loss:0.872711149338091\n",
      "train loss:0.8886671867651805\n",
      "train loss:0.9332513623640776\n",
      "train loss:0.9973321925105032\n",
      "train loss:0.8613520153234628\n",
      "train loss:0.994352904665924\n",
      "train loss:1.004493644257473\n",
      "train loss:0.9243723356624521\n",
      "train loss:0.7925007617389166\n",
      "train loss:0.8336258953841148\n",
      "train loss:0.8068250056299394\n",
      "train loss:0.7855779571699318\n",
      "train loss:0.737202555718601\n",
      "train loss:0.9281374780950951\n",
      "train loss:1.1424047891191227\n",
      "train loss:1.040891693150325\n",
      "train loss:0.8033076161099585\n",
      "train loss:0.8756665574000395\n",
      "train loss:0.8192673511046816\n",
      "train loss:0.8160049906832184\n",
      "train loss:1.0487198185885176\n",
      "train loss:0.9041234685700205\n",
      "train loss:0.8846659759570643\n",
      "train loss:0.8707695176462582\n",
      "train loss:0.6823527594676423\n",
      "train loss:0.9573420561506549\n",
      "train loss:0.8749685702294037\n",
      "train loss:0.8343382238131616\n",
      "train loss:0.89658818796097\n",
      "train loss:0.8564472329310341\n",
      "train loss:1.0989811790898387\n",
      "train loss:0.918419608284967\n",
      "train loss:0.9542137434745296\n",
      "train loss:0.8539242861758615\n",
      "train loss:0.9820544965764466\n",
      "train loss:1.0282808238817855\n",
      "train loss:0.7468843807208623\n",
      "train loss:0.7310537787204325\n",
      "train loss:0.812335473291768\n",
      "train loss:0.8770664718267436\n",
      "train loss:0.9761926811061673\n",
      "train loss:0.9969534845933566\n",
      "train loss:0.7769275214915945\n",
      "train loss:0.8099557783835539\n",
      "train loss:0.9835233236429229\n",
      "train loss:0.9450418630117698\n",
      "train loss:0.9447087263942268\n",
      "train loss:0.8826669616097678\n",
      "train loss:0.9089079563441027\n",
      "train loss:0.8958410428658471\n",
      "train loss:1.0757033708124055\n",
      "train loss:0.9249006409073623\n",
      "train loss:0.8732533594708441\n",
      "train loss:0.6647039846318955\n",
      "train loss:0.8873868605851724\n",
      "train loss:0.9428708371967756\n",
      "train loss:0.689064031958161\n",
      "train loss:0.7148993038191772\n",
      "train loss:0.9153485375840469\n",
      "train loss:0.9606077164169702\n",
      "train loss:0.8454809463209456\n",
      "train loss:0.9133471280113283\n",
      "train loss:0.9576867309579657\n",
      "train loss:0.7618466111188191\n",
      "train loss:0.8549344458631865\n",
      "train loss:0.8994085884623704\n",
      "train loss:0.7715565462262485\n",
      "train loss:0.8793037979695849\n",
      "train loss:0.7795048265505226\n",
      "train loss:0.6574944740339196\n",
      "train loss:0.6894318668427993\n",
      "train loss:0.913469918202364\n",
      "train loss:0.885112038199738\n",
      "train loss:0.9665680636318821\n",
      "train loss:0.8983626319079292\n",
      "train loss:0.7631415573560205\n",
      "train loss:0.9507407769454034\n",
      "train loss:0.812873371212069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.92574341200744\n",
      "train loss:0.8025824730855134\n",
      "train loss:0.9397104149572729\n",
      "train loss:0.8801173265252727\n",
      "train loss:0.9054832830381169\n",
      "train loss:0.9215382446429351\n",
      "train loss:0.9723290187346165\n",
      "train loss:0.9830443237198765\n",
      "train loss:0.8665447803794345\n",
      "train loss:0.7523149679118704\n",
      "train loss:0.7433275469735311\n",
      "train loss:0.9281444368838373\n",
      "train loss:0.9047931241583798\n",
      "train loss:0.902633607017765\n",
      "train loss:0.868732919802058\n",
      "train loss:0.932155508351681\n",
      "train loss:0.9055765318007194\n",
      "train loss:0.8753822128534278\n",
      "train loss:0.8752641382301227\n",
      "train loss:0.8430450498861041\n",
      "train loss:0.9188022420704217\n",
      "train loss:0.8523378967304847\n",
      "train loss:0.7435788587776009\n",
      "train loss:0.9777036201419952\n",
      "train loss:0.8614681103541144\n",
      "train loss:0.8905119413150006\n",
      "train loss:0.7927168667875868\n",
      "train loss:0.7432365944395848\n",
      "train loss:0.8760389793521374\n",
      "train loss:1.1015088234099708\n",
      "train loss:0.7977233744190215\n",
      "train loss:0.7210864636751576\n",
      "train loss:0.8316662108156743\n",
      "train loss:0.8759050060981608\n",
      "train loss:0.8879603870272144\n",
      "train loss:0.6917590879830976\n",
      "train loss:0.8644125363306253\n",
      "train loss:0.8464260967670743\n",
      "train loss:0.7790045436700348\n",
      "train loss:0.9756230986220128\n",
      "train loss:0.8158717077888068\n",
      "train loss:0.7692248178087329\n",
      "train loss:0.6984709778046769\n",
      "train loss:0.6854559198598489\n",
      "train loss:0.7943565982699019\n",
      "train loss:0.6790701720369806\n",
      "train loss:1.0586023551553492\n",
      "train loss:0.9012767465046778\n",
      "train loss:0.898120416515183\n",
      "train loss:0.7399159054928274\n",
      "train loss:0.9796886287952978\n",
      "train loss:0.9058552484794976\n",
      "train loss:0.901805434061899\n",
      "train loss:0.8242330794814654\n",
      "train loss:0.9669830276880935\n",
      "train loss:0.9730720333196894\n",
      "train loss:0.9943154613206479\n",
      "train loss:0.8286510689965978\n",
      "train loss:0.8817758895713704\n",
      "train loss:1.0050639537895045\n",
      "train loss:0.8543401672991608\n",
      "train loss:1.2063399967291528\n",
      "train loss:0.9521338532313282\n",
      "train loss:0.8531124634704499\n",
      "train loss:0.8555288949516661\n",
      "train loss:0.9458322276097054\n",
      "train loss:0.9977292351571022\n",
      "train loss:0.8969524845619345\n",
      "train loss:0.820867575804598\n",
      "train loss:0.7862809264484736\n",
      "train loss:0.9588568467553733\n",
      "train loss:1.0406091792348697\n",
      "train loss:0.9469301883916011\n",
      "train loss:0.9702750007465387\n",
      "train loss:0.7510379649606446\n",
      "train loss:0.9028474883884763\n",
      "train loss:0.8250627550999785\n",
      "train loss:0.9948079228879356\n",
      "train loss:0.8556018620289876\n",
      "train loss:1.0025897065189793\n",
      "train loss:0.7828412007482142\n",
      "train loss:0.913570841638947\n",
      "train loss:0.8811083894157749\n",
      "train loss:0.7426743952470041\n",
      "train loss:0.7946701479523307\n",
      "train loss:0.8173030865717376\n",
      "train loss:1.130442988912284\n",
      "train loss:0.883618963230259\n",
      "train loss:0.8126263817011521\n",
      "train loss:1.0007882515588895\n",
      "train loss:0.9396996645413271\n",
      "train loss:0.8609521027495868\n",
      "train loss:0.8277801308006096\n",
      "train loss:0.8810526818040103\n",
      "train loss:0.6714072462034659\n",
      "train loss:0.8537649076291542\n",
      "train loss:0.7198543885883499\n",
      "train loss:0.9596216250721986\n",
      "train loss:0.8899433674643195\n",
      "train loss:0.8543136669881269\n",
      "train loss:0.6729235780944947\n",
      "train loss:0.8575507993145979\n",
      "train loss:0.8212536638434659\n",
      "train loss:0.6736491413588808\n",
      "train loss:0.831155214959436\n",
      "train loss:0.855760057914203\n",
      "train loss:0.9608943400268276\n",
      "train loss:0.8097617514037833\n",
      "train loss:0.9537122957158644\n",
      "train loss:0.8397592395510098\n",
      "train loss:0.8154329512231787\n",
      "train loss:0.9534301752613614\n",
      "train loss:0.92990543122014\n",
      "train loss:0.7590885264291196\n",
      "train loss:1.1813085090906081\n",
      "train loss:0.7814569784952125\n",
      "train loss:0.7673494211087497\n",
      "train loss:0.8778859497460835\n",
      "train loss:0.8386092184529049\n",
      "train loss:0.8238139416829208\n",
      "train loss:0.8487340953073509\n",
      "train loss:0.837610545543183\n",
      "train loss:0.9242358376054882\n",
      "train loss:0.8675247381466048\n",
      "train loss:0.7310851111869962\n",
      "train loss:0.995063785919006\n",
      "train loss:0.893052420599432\n",
      "train loss:0.7863354302121657\n",
      "train loss:0.6851084024354948\n",
      "train loss:0.8156554092295749\n",
      "train loss:0.821977058102407\n",
      "train loss:0.858539985900807\n",
      "train loss:0.8773921599843352\n",
      "train loss:0.8694346375320982\n",
      "train loss:0.9015825222718478\n",
      "train loss:1.035012328821315\n",
      "train loss:0.8753249462607485\n",
      "train loss:0.9410806631570148\n",
      "train loss:0.7335035099189787\n",
      "train loss:0.6666587292768297\n",
      "train loss:0.7935142434650325\n",
      "train loss:0.8774428733575641\n",
      "train loss:1.0818395683224127\n",
      "train loss:0.9778585929317444\n",
      "train loss:1.1188915544635847\n",
      "train loss:0.8673274793859476\n",
      "train loss:0.9414843331733451\n",
      "train loss:0.9183865290199398\n",
      "train loss:0.754250590259303\n",
      "train loss:0.9010916850991826\n",
      "train loss:0.8903778940244493\n",
      "train loss:0.8564849160868071\n",
      "train loss:0.9558009633369177\n",
      "train loss:0.7124003645692751\n",
      "train loss:1.0978795222675763\n",
      "train loss:0.824595733416927\n",
      "train loss:0.8189123207103388\n",
      "train loss:0.8144538419167136\n",
      "train loss:1.009373436300961\n",
      "train loss:1.0261791049385764\n",
      "train loss:1.0682183069326283\n",
      "train loss:0.8557445390119395\n",
      "train loss:0.7735626179752083\n",
      "train loss:0.9048168481547547\n",
      "train loss:0.8415991026879319\n",
      "train loss:0.7350615809236086\n",
      "train loss:0.7646456008276507\n",
      "train loss:0.8485021715813044\n",
      "train loss:0.990566642406499\n",
      "train loss:0.753008059541116\n",
      "train loss:0.9368355859882149\n",
      "train loss:0.8446722960284194\n",
      "train loss:0.8647442627244346\n",
      "train loss:0.8231111489437475\n",
      "train loss:1.0103110937432214\n",
      "train loss:0.9474165344677253\n",
      "=== epoch:15, train acc:0.994, test acc:0.993 ===\n",
      "train loss:0.8140670324196652\n",
      "train loss:0.7274733422143772\n",
      "train loss:0.6430312831313713\n",
      "train loss:0.7361340871049277\n",
      "train loss:0.745428153323032\n",
      "train loss:0.9858701518380397\n",
      "train loss:0.8575688512638737\n",
      "train loss:0.8252531692151388\n",
      "train loss:0.8288495054636827\n",
      "train loss:0.8432852305139632\n",
      "train loss:0.8297491164103445\n",
      "train loss:0.9451724269862245\n",
      "train loss:0.8162944006407779\n",
      "train loss:0.7512374799128968\n",
      "train loss:0.9021133160480558\n",
      "train loss:0.803105943448058\n",
      "train loss:0.7908218472028178\n",
      "train loss:0.9089089381432955\n",
      "train loss:0.7508327894143914\n",
      "train loss:0.8527781693199493\n",
      "train loss:0.9099285283417666\n",
      "train loss:0.9057691106540602\n",
      "train loss:0.9092268659370016\n",
      "train loss:0.9224701381289282\n",
      "train loss:0.9021127883146246\n",
      "train loss:0.7074170368478583\n",
      "train loss:0.9137671420750975\n",
      "train loss:0.8400890613980024\n",
      "train loss:0.7052614737548604\n",
      "train loss:0.7985528244210073\n",
      "train loss:0.85892101636821\n",
      "train loss:0.8248513466748523\n",
      "train loss:0.714892558403767\n",
      "train loss:0.7792728014499914\n",
      "train loss:0.7490123555199407\n",
      "train loss:0.8648187115993181\n",
      "train loss:0.8599139297806968\n",
      "train loss:0.833045834374342\n",
      "train loss:0.7235011172090752\n",
      "train loss:0.8845217015495951\n",
      "train loss:0.9874396780128112\n",
      "train loss:0.9556943518289528\n",
      "train loss:0.8115179608868915\n",
      "train loss:0.9411467746684431\n",
      "train loss:0.8132192608330914\n",
      "train loss:0.9891643756797157\n",
      "train loss:0.8928887874632276\n",
      "train loss:0.8167367812801679\n",
      "train loss:0.8949541882175269\n",
      "train loss:0.9940720545095174\n",
      "train loss:0.8261954932040819\n",
      "train loss:0.8954408920308782\n",
      "train loss:0.8754538355118696\n",
      "train loss:0.921072143468674\n",
      "train loss:0.762144849607682\n",
      "train loss:0.7929635289675895\n",
      "train loss:0.7614509202605023\n",
      "train loss:0.8325713747281099\n",
      "train loss:0.8001672236441015\n",
      "train loss:0.8532124194055993\n",
      "train loss:0.895717306970117\n",
      "train loss:0.9271868507334058\n",
      "train loss:0.8880736884498321\n",
      "train loss:0.7584733505092269\n",
      "train loss:0.7985919217679737\n",
      "train loss:0.8455122059851321\n",
      "train loss:0.7992898523652294\n",
      "train loss:0.9774575537076419\n",
      "train loss:0.9250893034499826\n",
      "train loss:0.9539801776287579\n",
      "train loss:0.8456730588165854\n",
      "train loss:0.8980796661955835\n",
      "train loss:0.8826168035963963\n",
      "train loss:0.9043711566650349\n",
      "train loss:0.8499985133469451\n",
      "train loss:0.9261991249603133\n",
      "train loss:0.8052795398348819\n",
      "train loss:0.8288309762520568\n",
      "train loss:0.79098999070943\n",
      "train loss:0.749483996250934\n",
      "train loss:0.8071125810825945\n",
      "train loss:0.9134487807759385\n",
      "train loss:0.9022143814466966\n",
      "train loss:0.8040573283139377\n",
      "train loss:1.0648072101941457\n",
      "train loss:0.923346995488098\n",
      "train loss:0.9395521118673631\n",
      "train loss:1.0282282314994091\n",
      "train loss:1.0126181722654726\n",
      "train loss:0.9712086012040672\n",
      "train loss:0.901235958917883\n",
      "train loss:0.7919452465289898\n",
      "train loss:0.84921186556823\n",
      "train loss:0.8685785782877851\n",
      "train loss:0.7818058162724324\n",
      "train loss:0.9366094460921718\n",
      "train loss:0.8316424148167098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.7407987031601021\n",
      "train loss:0.8055307304907958\n",
      "train loss:0.9065907818524562\n",
      "train loss:0.811335826409636\n",
      "train loss:0.7829172584165768\n",
      "train loss:0.8950831877993715\n",
      "train loss:0.8092627545020263\n",
      "train loss:0.8188142869530182\n",
      "train loss:0.9532930705492378\n",
      "train loss:0.7810019179345654\n",
      "train loss:0.9065670307371937\n",
      "train loss:1.0325546147389215\n",
      "train loss:0.8017480952444145\n",
      "train loss:0.9823628549619297\n",
      "train loss:0.9407958973046301\n",
      "train loss:1.1218378406112235\n",
      "train loss:0.8187894876175343\n",
      "train loss:0.9330356617778606\n",
      "train loss:0.812216590687165\n",
      "train loss:0.8261276401610504\n",
      "train loss:0.8562752443345012\n",
      "train loss:0.7717964308777878\n",
      "train loss:0.9668640878001463\n",
      "train loss:0.7740925628214196\n",
      "train loss:0.8371740997392709\n",
      "train loss:0.8623872108744354\n",
      "train loss:0.7449674504713701\n",
      "train loss:0.8189122244300081\n",
      "train loss:0.847339775849185\n",
      "train loss:0.9027971263052831\n",
      "train loss:0.7601237365899519\n",
      "train loss:0.8453405877073312\n",
      "train loss:0.9041618657534299\n",
      "train loss:0.853577884867982\n",
      "train loss:0.858323667947893\n",
      "train loss:0.8876912156072636\n",
      "train loss:0.8624127572498113\n",
      "train loss:0.9826479443800272\n",
      "train loss:0.8341775471007078\n",
      "train loss:0.7816097368350812\n",
      "train loss:0.8794469007094894\n",
      "train loss:0.8434026592058718\n",
      "train loss:0.9643058210710503\n",
      "train loss:0.9949227486089304\n",
      "train loss:0.6772457675294156\n",
      "train loss:0.8805780637272673\n",
      "train loss:0.9319284538509863\n",
      "train loss:0.8702077060103427\n",
      "train loss:0.9946199113055602\n",
      "train loss:0.8112730443972204\n",
      "train loss:0.8978163384008977\n",
      "train loss:0.8464146601659315\n",
      "train loss:0.8106942264418622\n",
      "train loss:0.9313963508583375\n",
      "train loss:0.891159770606071\n",
      "train loss:0.9289126992821382\n",
      "train loss:0.7902827436731386\n",
      "train loss:0.9487693908859509\n",
      "train loss:0.6660802092889668\n",
      "train loss:0.8636948204682519\n",
      "train loss:0.9069450263662096\n",
      "train loss:0.8586658327200232\n",
      "train loss:0.7778248018480844\n",
      "train loss:0.8016270869940207\n",
      "train loss:0.878883752137784\n",
      "train loss:0.7944292045727945\n",
      "train loss:0.8813265310899119\n",
      "train loss:0.755906382218018\n",
      "train loss:0.7370149126439149\n",
      "train loss:0.9337763185768942\n",
      "train loss:0.8778361869236159\n",
      "train loss:0.9529211155010602\n",
      "train loss:0.940476004400395\n",
      "train loss:0.9442099383336802\n",
      "train loss:0.8472529594756772\n",
      "train loss:0.8811842931440562\n",
      "train loss:0.8225389716664947\n",
      "train loss:0.7946112954319992\n",
      "train loss:0.8638734082193957\n",
      "train loss:0.8597458983916632\n",
      "train loss:0.9381314599240533\n",
      "train loss:0.8816332913438149\n",
      "train loss:0.8088513491298747\n",
      "train loss:0.99281403323765\n",
      "train loss:0.7360457918709852\n",
      "train loss:0.8890376082942499\n",
      "train loss:0.9195397838237398\n",
      "train loss:0.7050509319751598\n",
      "train loss:1.0105100629530654\n",
      "train loss:0.7732816463541349\n",
      "train loss:1.034601218790644\n",
      "train loss:0.7999950527058212\n",
      "train loss:0.7572826580157787\n",
      "train loss:0.6532118726001162\n",
      "train loss:0.8270481522269584\n",
      "train loss:1.1102708359635762\n",
      "train loss:0.9398395627244598\n",
      "train loss:0.9485918919344597\n",
      "train loss:0.8532080353607532\n",
      "train loss:0.8732730396994196\n",
      "train loss:0.8377028199880155\n",
      "train loss:0.8009144695295093\n",
      "train loss:0.6179400253519685\n",
      "train loss:0.9581117653355778\n",
      "train loss:0.8785926135424925\n",
      "train loss:0.8191944640407077\n",
      "train loss:0.7467153106271184\n",
      "train loss:0.8696957104682292\n",
      "train loss:0.8375057467171186\n",
      "train loss:0.917896837495191\n",
      "train loss:0.8771408734068248\n",
      "train loss:0.8226242446611804\n",
      "train loss:0.8046374365069099\n",
      "train loss:0.8884385788926284\n",
      "train loss:1.109193719528688\n",
      "train loss:0.8302356765084982\n",
      "train loss:1.0866134884170109\n",
      "train loss:0.8349612300814723\n",
      "train loss:0.806931174941195\n",
      "train loss:0.9929826619822086\n",
      "train loss:0.8906877791093887\n",
      "train loss:0.77667481593346\n",
      "train loss:0.7210533952096227\n",
      "train loss:0.8164000357319209\n",
      "train loss:0.9539155787601183\n",
      "train loss:0.905641706238022\n",
      "train loss:0.7258926622425855\n",
      "train loss:0.9543315061182007\n",
      "train loss:0.8024228250445337\n",
      "train loss:0.9020990198542286\n",
      "train loss:0.7712986179358099\n",
      "train loss:0.8734664619258963\n",
      "train loss:0.8397785025448772\n",
      "train loss:0.8725202413469216\n",
      "train loss:0.9760204342040036\n",
      "train loss:0.8135116855425493\n",
      "train loss:0.9438255997841519\n",
      "train loss:0.9426442788158187\n",
      "train loss:0.9372329570525798\n",
      "train loss:0.7961210462755435\n",
      "train loss:0.8433881598313859\n",
      "train loss:1.0572487692597985\n",
      "train loss:0.7553448685995299\n",
      "train loss:0.8253979104913384\n",
      "train loss:0.9285994466089929\n",
      "train loss:0.8559730211070794\n",
      "train loss:0.8637534485889118\n",
      "train loss:0.8596140313260796\n",
      "train loss:0.767331397933311\n",
      "train loss:0.9700484642182902\n",
      "train loss:0.5510636587931211\n",
      "train loss:0.7453686200920329\n",
      "train loss:0.8788902818931258\n",
      "train loss:0.8265367083749294\n",
      "train loss:0.8001662556197903\n",
      "train loss:0.7988294802747721\n",
      "train loss:0.9182627437065648\n",
      "train loss:0.6748685117798964\n",
      "train loss:0.8144061021795613\n",
      "train loss:0.9372005478688095\n",
      "train loss:0.7267295243100678\n",
      "train loss:0.7949816769469225\n",
      "train loss:0.7548920599152186\n",
      "train loss:0.9037728169492525\n",
      "train loss:0.9053228819249433\n",
      "train loss:0.8424828068626323\n",
      "train loss:0.9775214634407758\n",
      "train loss:0.9289540304242553\n",
      "train loss:0.743468284707824\n",
      "train loss:0.8874669282532278\n",
      "train loss:0.8549649649556689\n",
      "train loss:0.8995146814671372\n",
      "train loss:0.9611596787718908\n",
      "train loss:0.828117354668797\n",
      "train loss:0.7504130923892208\n",
      "train loss:1.0249252601739425\n",
      "train loss:0.9185174285052676\n",
      "train loss:0.8874340511681086\n",
      "train loss:0.8610017385933904\n",
      "train loss:0.9039910746672705\n",
      "train loss:0.9155293797236062\n",
      "train loss:0.7289023743987145\n",
      "train loss:0.7931848519613063\n",
      "train loss:1.0284149182367543\n",
      "train loss:0.7685942383105107\n",
      "train loss:0.8897703968829552\n",
      "train loss:0.8607017414606051\n",
      "train loss:1.007330240197938\n",
      "train loss:0.8158808072580378\n",
      "train loss:0.8212281811374516\n",
      "train loss:0.8796632416391625\n",
      "train loss:0.7694372104713088\n",
      "train loss:0.7513483632645009\n",
      "train loss:0.8428536787137716\n",
      "train loss:0.8987617051367522\n",
      "train loss:0.9065077676811565\n",
      "train loss:0.9692406165698593\n",
      "train loss:0.7910456316093887\n",
      "train loss:0.8286383624029322\n",
      "train loss:0.8773913963943548\n",
      "train loss:0.9998856248469185\n",
      "train loss:0.9822899278628371\n",
      "train loss:0.8627606659212852\n",
      "train loss:0.9530210838904167\n",
      "train loss:1.0070928136311534\n",
      "train loss:0.9947224633276174\n",
      "train loss:0.9282335604830924\n",
      "train loss:0.747778757966603\n",
      "train loss:0.7789392770990052\n",
      "train loss:0.7369282105815093\n",
      "train loss:0.9192948147390558\n",
      "train loss:1.0571854412546768\n",
      "train loss:0.8716900769345416\n",
      "train loss:0.9032563308913037\n",
      "train loss:0.875173706229145\n",
      "train loss:0.9216478334416196\n",
      "train loss:0.8052884779781294\n",
      "train loss:0.871552371112189\n",
      "train loss:1.0278240952463558\n",
      "train loss:0.9306582413007131\n",
      "train loss:0.8669110212522781\n",
      "train loss:0.9881276130525688\n",
      "train loss:0.8445326865563227\n",
      "train loss:0.844743302359415\n",
      "train loss:0.8633298025532468\n",
      "train loss:0.8480761633657263\n",
      "train loss:0.8406832192814109\n",
      "train loss:1.0132770439632188\n",
      "train loss:0.9278513327731566\n",
      "train loss:0.8579587746339206\n",
      "train loss:0.8001822252149471\n",
      "train loss:0.8948903240038473\n",
      "train loss:1.0503869882798835\n",
      "train loss:0.9802815794646328\n",
      "train loss:0.8909023896966456\n",
      "train loss:0.8381217745946512\n",
      "train loss:0.8411865588853844\n",
      "train loss:0.782448156536701\n",
      "train loss:0.8458193705867862\n",
      "train loss:0.894509214601226\n",
      "train loss:0.80124853158751\n",
      "train loss:0.9304087733966449\n",
      "train loss:0.6795681336044777\n",
      "train loss:0.8163273946862714\n",
      "train loss:0.939010863595113\n",
      "train loss:0.7944066477471956\n",
      "train loss:0.8021891870933108\n",
      "train loss:0.8046469024744433\n",
      "train loss:0.8984293025435561\n",
      "train loss:0.8674558512602634\n",
      "train loss:0.7736127227667435\n",
      "train loss:0.8434806383096003\n",
      "train loss:0.8365090700732755\n",
      "train loss:0.8253725175718546\n",
      "train loss:0.8145913625445328\n",
      "train loss:0.7846741692983566\n",
      "train loss:0.9038040226665028\n",
      "train loss:0.833628181392037\n",
      "train loss:0.8892636545943727\n",
      "train loss:0.9840696118796595\n",
      "train loss:0.7747652777130996\n",
      "train loss:0.7903415989647482\n",
      "train loss:0.9505903570774785\n",
      "train loss:0.928917205911058\n",
      "train loss:0.9534265322838164\n",
      "train loss:0.9051678990329092\n",
      "train loss:0.7578949414804085\n",
      "train loss:0.8021451821283727\n",
      "train loss:0.9490804801856931\n",
      "train loss:0.7646546344276668\n",
      "train loss:0.830420841058458\n",
      "train loss:0.9255845221003863\n",
      "train loss:0.8991293591589655\n",
      "train loss:0.91579726463854\n",
      "train loss:0.8367166295316606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.9945439802550409\n",
      "train loss:0.7539860342321422\n",
      "train loss:0.7573112479125292\n",
      "train loss:0.8795789379542077\n",
      "train loss:0.8308538917494563\n",
      "train loss:0.8384031445023922\n",
      "train loss:0.9680594741742524\n",
      "train loss:0.7717637029631729\n",
      "train loss:0.7864070897677258\n",
      "train loss:0.8031961612248371\n",
      "train loss:0.736369459398336\n",
      "train loss:0.7245469677322025\n",
      "train loss:0.9845905124943388\n",
      "train loss:0.8376284671700208\n",
      "train loss:0.8917091578659008\n",
      "train loss:0.8671077708538075\n",
      "train loss:0.7077349187408437\n",
      "train loss:0.9797655838833036\n",
      "train loss:0.8136853418570011\n",
      "train loss:0.8066940330187081\n",
      "train loss:0.8152863942848522\n",
      "train loss:0.6900138698445272\n",
      "train loss:0.8069908827440628\n",
      "train loss:0.7661452280295213\n",
      "train loss:0.8506637110332196\n",
      "train loss:0.9255531770424377\n",
      "train loss:0.6890128338243054\n",
      "train loss:0.9672401527586986\n",
      "train loss:0.9714722161440449\n",
      "train loss:0.8916018616942659\n",
      "train loss:0.9701299641060014\n",
      "train loss:0.8601817335299375\n",
      "train loss:0.7721777154346522\n",
      "train loss:0.8931225382500849\n",
      "train loss:1.0488430582860961\n",
      "train loss:0.9163154617069666\n",
      "train loss:0.8650202688528826\n",
      "train loss:0.8560455585865127\n",
      "train loss:1.0479585841756394\n",
      "train loss:0.890205769439577\n",
      "train loss:0.9445125291978559\n",
      "train loss:0.8994058215980221\n",
      "train loss:0.7473212851163195\n",
      "train loss:0.8093722011932512\n",
      "train loss:1.017579767509764\n",
      "train loss:0.934212225175348\n",
      "train loss:0.8315673913710423\n",
      "train loss:0.9704058569847754\n",
      "train loss:0.8614902853002104\n",
      "train loss:0.9602343612280113\n",
      "train loss:0.8866266961115233\n",
      "train loss:0.9388406520754483\n",
      "train loss:1.0300300835523155\n",
      "train loss:0.8643276524956336\n",
      "train loss:0.9465776995299963\n",
      "train loss:0.8442690926561599\n",
      "train loss:0.7795728992354539\n",
      "train loss:0.9051741518610876\n",
      "train loss:0.9226516810294207\n",
      "train loss:0.9418122765234525\n",
      "train loss:0.7433149705769218\n",
      "train loss:0.9030873300711056\n",
      "train loss:0.832995876719951\n",
      "train loss:1.0028016251557794\n",
      "train loss:0.7693996065765009\n",
      "train loss:0.761329701433054\n",
      "train loss:0.980457226839428\n",
      "train loss:0.7347191865354484\n",
      "train loss:0.6850231500546723\n",
      "train loss:0.9576798480833263\n",
      "train loss:0.8767655651208854\n",
      "train loss:0.8609194610244444\n",
      "train loss:0.8299679911474562\n",
      "train loss:0.7565578007841998\n",
      "train loss:0.8889984927788612\n",
      "train loss:0.8576310255836759\n",
      "train loss:0.8888313769388276\n",
      "train loss:0.8164036929412606\n",
      "train loss:0.7841688111246491\n",
      "train loss:0.9853331474735484\n",
      "train loss:1.050385412119351\n",
      "train loss:0.9100608704702107\n",
      "train loss:0.9000976040806363\n",
      "train loss:1.0357054150586753\n",
      "train loss:0.9724914851789159\n",
      "train loss:0.8818153469410558\n",
      "train loss:0.9580396375976418\n",
      "train loss:0.8860535310168365\n",
      "train loss:0.8436780837842535\n",
      "train loss:0.8939835384890329\n",
      "train loss:0.8314978088129245\n",
      "train loss:0.8149280165497068\n",
      "train loss:1.0485333447442846\n",
      "train loss:0.9924056520518016\n",
      "train loss:0.8851479203950916\n",
      "train loss:0.7755210692352661\n",
      "train loss:0.7817444847938417\n",
      "train loss:0.8417037576942151\n",
      "train loss:0.8937980721181289\n",
      "train loss:0.8430599094792964\n",
      "train loss:0.7533395801921763\n",
      "train loss:0.8914109548828083\n",
      "train loss:0.9148263302978357\n",
      "train loss:0.8784108839639495\n",
      "train loss:0.8972907637511034\n",
      "train loss:0.8872231521870628\n",
      "train loss:1.0247093081476204\n",
      "train loss:0.8638579506518793\n",
      "train loss:0.7450218682102933\n",
      "train loss:0.7567779406755903\n",
      "train loss:0.8376911719017522\n",
      "train loss:0.9297471884053844\n",
      "train loss:0.8922502129315322\n",
      "train loss:1.0182064638110153\n",
      "train loss:0.9349943643926129\n",
      "train loss:0.7026620413483192\n",
      "train loss:0.8134638443655453\n",
      "train loss:0.8018560886064167\n",
      "train loss:0.8971094850323547\n",
      "train loss:0.8564869285048208\n",
      "train loss:0.8699265874757667\n",
      "train loss:0.7754786376002586\n",
      "train loss:0.8026075599584194\n",
      "train loss:0.8230518758780463\n",
      "train loss:0.7550140462739319\n",
      "train loss:0.7749584981657552\n",
      "train loss:0.8197753477457747\n",
      "train loss:0.9634523934680176\n",
      "train loss:0.9647252162482488\n",
      "train loss:0.9267008495612705\n",
      "train loss:0.6945113932983321\n",
      "train loss:0.9223298536406304\n",
      "train loss:0.833635633260315\n",
      "train loss:0.750610115860635\n",
      "train loss:0.7142434088151908\n",
      "train loss:0.74874355880404\n",
      "train loss:0.9132639339993027\n",
      "train loss:0.9138959778677399\n",
      "train loss:0.9652739185436225\n",
      "train loss:0.9451967550540682\n",
      "train loss:0.9730288543597138\n",
      "train loss:1.088818104475383\n",
      "train loss:0.7798265610227925\n",
      "train loss:0.7864248876967629\n",
      "train loss:0.9101993009456726\n",
      "train loss:0.7115389748252816\n",
      "train loss:0.9123757793292034\n",
      "train loss:0.8768192359938994\n",
      "train loss:0.8120669505972371\n",
      "train loss:0.836555948760134\n",
      "train loss:0.9747054345382\n",
      "train loss:0.8026434052144522\n",
      "train loss:0.6979531822490337\n",
      "train loss:0.8208170775386953\n",
      "train loss:0.9227413746585021\n",
      "train loss:1.0044796029130914\n",
      "train loss:0.7576118172713874\n",
      "train loss:0.814749111545975\n",
      "train loss:0.8765686292504976\n",
      "train loss:0.9538189812413979\n",
      "train loss:0.8583352398807804\n",
      "train loss:0.7275129527661428\n",
      "train loss:0.8341451999424023\n",
      "train loss:0.9385987485590982\n",
      "train loss:0.7543781954916342\n",
      "train loss:0.8299164044016192\n",
      "train loss:0.7458047973377147\n",
      "train loss:0.7721639550616881\n",
      "train loss:0.7277699298013465\n",
      "train loss:0.7222445204009557\n",
      "train loss:0.7368369539350619\n",
      "train loss:0.7871408436543256\n",
      "train loss:0.8421982330010777\n",
      "train loss:0.7705145601905775\n",
      "train loss:1.0481089244256154\n",
      "train loss:0.7320197653319512\n",
      "train loss:0.8626195918409431\n",
      "train loss:0.9531869015976986\n",
      "train loss:0.7549176891571502\n",
      "train loss:0.8054571060789419\n",
      "train loss:0.8643831711694007\n",
      "train loss:0.8201629708016526\n",
      "train loss:0.7457192171622481\n",
      "train loss:0.870441169237738\n",
      "train loss:0.6579106293116831\n",
      "train loss:0.8341799675891923\n",
      "train loss:0.8093550181980408\n",
      "train loss:0.8499449011698418\n",
      "train loss:0.7656115756985676\n",
      "train loss:0.8796574028859822\n",
      "train loss:0.719239271156854\n",
      "train loss:0.8350285983526485\n",
      "train loss:0.9417476971140576\n",
      "train loss:0.9356947817120855\n",
      "train loss:0.8587240732793049\n",
      "train loss:0.9598436930214035\n",
      "train loss:0.9874931226228305\n",
      "train loss:0.89438676222006\n",
      "train loss:0.7778472182937558\n",
      "train loss:0.9757385463487614\n",
      "train loss:0.9127628429283555\n",
      "train loss:0.9937823195660141\n",
      "train loss:0.8787106669831782\n",
      "train loss:0.911611080553798\n",
      "train loss:0.6227584901381032\n",
      "train loss:0.8285066182948804\n",
      "train loss:0.7831030706297138\n",
      "train loss:0.7976835388674692\n",
      "train loss:0.8738189891735166\n",
      "train loss:0.8775647946177253\n",
      "train loss:0.9579493206095177\n",
      "train loss:0.881439848145005\n",
      "train loss:0.9634291265945507\n",
      "train loss:0.8279128810065902\n",
      "train loss:0.7791491189102243\n",
      "train loss:0.9357016181953451\n",
      "train loss:0.922581247076306\n",
      "train loss:1.0235394946560963\n",
      "train loss:0.673026217923469\n",
      "train loss:0.8743464293274217\n",
      "train loss:0.8165281394205198\n",
      "train loss:0.7974694372556346\n",
      "train loss:0.8096162387266175\n",
      "train loss:0.8497357871542865\n",
      "train loss:0.8597933392605991\n",
      "train loss:0.8925754860988662\n",
      "train loss:0.9070037808167186\n",
      "train loss:0.7333097518646676\n",
      "=== epoch:16, train acc:0.998, test acc:0.993 ===\n",
      "train loss:0.7705868990301358\n",
      "train loss:1.0677745403481032\n",
      "train loss:0.8574261505858781\n",
      "train loss:0.8544336778156868\n",
      "train loss:0.7128727439768976\n",
      "train loss:0.7443771734465113\n",
      "train loss:0.8283711381626065\n",
      "train loss:1.009365497156626\n",
      "train loss:0.9540984566040883\n",
      "train loss:0.8626086813145046\n",
      "train loss:0.8856237419042924\n",
      "train loss:0.8163635395153861\n",
      "train loss:0.862816741083509\n",
      "train loss:0.8353370424028579\n",
      "train loss:0.9469740518664779\n",
      "train loss:0.7788714152595361\n",
      "train loss:0.9852705879360713\n",
      "train loss:0.8823157019042366\n",
      "train loss:0.9328245000495269\n",
      "train loss:0.9327574744974069\n",
      "train loss:0.8540701317860213\n",
      "train loss:0.825780335679527\n",
      "train loss:0.7814524231983613\n",
      "train loss:0.9558114741355672\n",
      "train loss:0.9270197574869903\n",
      "train loss:0.9017955336231632\n",
      "train loss:0.8774079846649792\n",
      "train loss:0.8796643575061976\n",
      "train loss:0.7570042364876882\n",
      "train loss:0.957251097919907\n",
      "train loss:0.8979299928253495\n",
      "train loss:0.9352979452897288\n",
      "train loss:0.8036564204273939\n",
      "train loss:0.8939042069691396\n",
      "train loss:0.9288775276369573\n",
      "train loss:0.7189387753683251\n",
      "train loss:0.84366656938191\n",
      "train loss:1.012515980286952\n",
      "train loss:0.8121914098036814\n",
      "train loss:0.7278061572171124\n",
      "train loss:0.855553207397724\n",
      "train loss:0.9027745166858362\n",
      "train loss:0.7605566330889602\n",
      "train loss:0.9215685690531528\n",
      "train loss:0.9439254890035668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.8858537517892584\n",
      "train loss:1.0721725352205058\n",
      "train loss:0.7925685823253397\n",
      "train loss:1.0042992606542804\n",
      "train loss:0.8176032202351028\n",
      "train loss:0.7407803061918784\n",
      "train loss:0.8018438231785028\n",
      "train loss:0.8198528898151458\n",
      "train loss:0.6932213861135051\n",
      "train loss:1.007011316365543\n",
      "train loss:0.6908743114075396\n",
      "train loss:0.9395792975809362\n",
      "train loss:0.837766378342486\n",
      "train loss:0.8620340867384888\n",
      "train loss:0.7028583322907299\n",
      "train loss:0.9614231397234954\n",
      "train loss:1.036784495128893\n",
      "train loss:0.8232899711057594\n",
      "train loss:0.8615011462541926\n",
      "train loss:0.7869017639235244\n",
      "train loss:0.8825718544303739\n",
      "train loss:0.8418235735701088\n",
      "train loss:0.7621906785961098\n",
      "train loss:1.045955331272122\n",
      "train loss:0.9711540844196496\n",
      "train loss:0.7674927565118221\n",
      "train loss:0.8141835758152645\n",
      "train loss:0.7110705554728222\n",
      "train loss:0.8879498388105915\n",
      "train loss:0.9001370430643258\n",
      "train loss:0.7785180921885946\n",
      "train loss:0.9061395745112659\n",
      "train loss:0.6864150294284886\n",
      "train loss:0.8150829153026099\n",
      "train loss:0.8843395190815552\n",
      "train loss:0.9383750087201935\n",
      "train loss:0.9850457311648323\n",
      "train loss:0.6877583354329421\n",
      "train loss:0.9541481508741474\n",
      "train loss:0.9338519776393404\n",
      "train loss:0.9670838186275157\n",
      "train loss:0.9495098649330928\n",
      "train loss:1.0212013044874737\n",
      "train loss:0.9427264648239191\n",
      "train loss:0.7070027854763794\n",
      "train loss:0.7606325893859175\n",
      "train loss:0.777436211989557\n",
      "train loss:0.7093059489269733\n",
      "train loss:0.9024052379587857\n",
      "train loss:0.8088186358571349\n",
      "train loss:0.8059483888441525\n",
      "train loss:0.9071982879774937\n",
      "train loss:0.9159814255519361\n",
      "train loss:0.8445926211079682\n",
      "train loss:0.6789145694774009\n",
      "train loss:0.9089143183816333\n",
      "train loss:0.8374065538593084\n",
      "train loss:0.8215551198906692\n",
      "train loss:0.8201283340569501\n",
      "train loss:0.7410844167829818\n",
      "train loss:0.7914798646224963\n",
      "train loss:0.7907073241071763\n",
      "train loss:0.7532592819171569\n",
      "train loss:0.6983673939197496\n",
      "train loss:0.745323064558466\n",
      "train loss:0.6953739058248748\n",
      "train loss:0.8731924317746993\n",
      "train loss:0.8757076161090654\n",
      "train loss:0.8437866328184545\n",
      "train loss:0.776853792899628\n",
      "train loss:0.8389433782492745\n",
      "train loss:0.8290413379155581\n",
      "train loss:0.9400748127491072\n",
      "train loss:0.7286667324711712\n",
      "train loss:0.8657141097817781\n",
      "train loss:0.7862249853109796\n",
      "train loss:0.8171487769913246\n",
      "train loss:0.9181617901594333\n",
      "train loss:0.9089993151014835\n",
      "train loss:0.875755447652231\n",
      "train loss:0.796913273340423\n",
      "train loss:0.9911355670222107\n",
      "train loss:0.8460925392546832\n",
      "train loss:0.8277860387741381\n",
      "train loss:0.8652019777483528\n",
      "train loss:0.7740535166618281\n",
      "train loss:0.9401683521837159\n",
      "train loss:0.8546488903973998\n",
      "train loss:0.9096052129067584\n",
      "train loss:0.8521343769916936\n",
      "train loss:0.7958550735612233\n",
      "train loss:0.7070809582076049\n",
      "train loss:0.710109151891383\n",
      "train loss:0.8437300623950508\n",
      "train loss:0.8153617011230557\n",
      "train loss:0.9931768797447827\n",
      "train loss:0.7905561898984053\n",
      "train loss:0.7670665530927309\n",
      "train loss:0.6210886662448563\n",
      "train loss:0.8922244700285414\n",
      "train loss:0.777185973099593\n",
      "train loss:0.9715693609662359\n",
      "train loss:0.7875655107279391\n",
      "train loss:0.9018726724291101\n",
      "train loss:0.8798101946671156\n",
      "train loss:0.8541960708622065\n",
      "train loss:0.7671989256083843\n",
      "train loss:1.0447029483444341\n",
      "train loss:0.8919946989241483\n",
      "train loss:1.0176885740017199\n",
      "train loss:0.7405212293928533\n",
      "train loss:0.9247904225763065\n",
      "train loss:0.9704239286640997\n",
      "train loss:0.792755294904884\n",
      "train loss:0.8759489122533671\n",
      "train loss:0.8028720276749723\n",
      "train loss:0.916320237719436\n",
      "train loss:0.8855195819084725\n",
      "train loss:0.9208552588676898\n",
      "train loss:0.6321201047656291\n",
      "train loss:0.8630860024081544\n",
      "train loss:0.996925399641354\n",
      "train loss:0.8296722107368433\n",
      "train loss:0.7222359965880426\n",
      "train loss:0.9221028604203012\n",
      "train loss:1.0340690936239065\n",
      "train loss:0.9872845466651979\n",
      "train loss:0.9665579515282182\n",
      "train loss:0.8491809497254232\n",
      "train loss:0.740479884725011\n",
      "train loss:0.9059210882620826\n",
      "train loss:0.718269949279004\n",
      "train loss:0.8899302471111892\n",
      "train loss:0.8973793055636256\n",
      "train loss:0.8909883799710098\n",
      "train loss:0.9459661218303304\n",
      "train loss:0.760753975130633\n",
      "train loss:0.785350546818052\n",
      "train loss:0.9341615243112485\n",
      "train loss:0.9592945489868311\n",
      "train loss:0.7084857738142104\n",
      "train loss:0.800544386128827\n",
      "train loss:0.9154956541039432\n",
      "train loss:0.6355222025663544\n",
      "train loss:0.8334028946852529\n",
      "train loss:0.8006719425558838\n",
      "train loss:0.8508497174901025\n",
      "train loss:0.7894264608537276\n",
      "train loss:0.7120135700912777\n",
      "train loss:0.8175954190378911\n",
      "train loss:0.8454052296683651\n",
      "train loss:0.9311413381500102\n",
      "train loss:0.8590671279660868\n",
      "train loss:0.8816280907957881\n",
      "train loss:0.6972789567554133\n",
      "train loss:0.9713394583761992\n",
      "train loss:0.80553818678741\n",
      "train loss:0.9091842095448702\n",
      "train loss:0.9546886810569842\n",
      "train loss:0.8862660868076508\n",
      "train loss:0.8809717473028834\n",
      "train loss:0.7979092406928834\n",
      "train loss:0.712301973205795\n",
      "train loss:0.8135977616759028\n",
      "train loss:0.7778657644450252\n",
      "train loss:0.8176558604708463\n",
      "train loss:0.7738730472361884\n",
      "train loss:0.7959822511947171\n",
      "train loss:0.6679450900336669\n",
      "train loss:0.863285806562692\n",
      "train loss:0.9937193778358889\n",
      "train loss:0.8540957898971926\n",
      "train loss:0.7994855388427188\n",
      "train loss:1.0519620423138631\n",
      "train loss:0.8721496389379796\n",
      "train loss:0.7436536934818497\n",
      "train loss:0.8782541693912148\n",
      "train loss:1.0487371415543174\n",
      "train loss:0.8774864950959085\n",
      "train loss:1.0114374756929168\n",
      "train loss:0.9147411062315727\n",
      "train loss:0.7982868815369728\n",
      "train loss:0.8404747020965252\n",
      "train loss:0.9160473246593277\n",
      "train loss:0.8191753606803751\n",
      "train loss:0.7863372419002927\n",
      "train loss:0.8718110459012354\n",
      "train loss:0.8916256506403195\n",
      "train loss:0.6875281276030552\n",
      "train loss:0.8396813977388298\n",
      "train loss:0.8357473433415784\n",
      "train loss:0.9156419064009395\n",
      "train loss:0.9115990290114394\n",
      "train loss:0.6729341230901167\n",
      "train loss:0.7931317342897719\n",
      "train loss:1.0210103308119027\n",
      "train loss:0.8692270187111582\n",
      "train loss:0.931818137407625\n",
      "train loss:0.7880605555376974\n",
      "train loss:0.8821818065988635\n",
      "train loss:0.923508318664226\n",
      "train loss:0.9733402518350965\n",
      "train loss:0.8647844794713714\n",
      "train loss:0.737996031865826\n",
      "train loss:0.9059638004777496\n",
      "train loss:0.8997425283255671\n",
      "train loss:0.8957906492222978\n",
      "train loss:0.8245230049118879\n",
      "train loss:0.8989476402718867\n",
      "train loss:0.9933513662568175\n",
      "train loss:0.811338919168334\n",
      "train loss:0.8211566468058591\n",
      "train loss:0.8297821498810801\n",
      "train loss:1.0030579294909554\n",
      "train loss:1.0634505782493697\n",
      "train loss:0.9689512807419733\n",
      "train loss:1.0112332407106501\n",
      "train loss:0.9903331167944898\n",
      "train loss:1.007808793760023\n",
      "train loss:0.7489456738973574\n",
      "train loss:0.7362431019759632\n",
      "train loss:0.8781032981584406\n",
      "train loss:0.7956225186580794\n",
      "train loss:0.9418248954240895\n",
      "train loss:0.8933246838131416\n",
      "train loss:0.7120983941743952\n",
      "train loss:0.9214818522281703\n",
      "train loss:0.7804125243896407\n",
      "train loss:0.974378090171842\n",
      "train loss:0.9518429345088858\n",
      "train loss:0.7772094085426131\n",
      "train loss:0.9653998508903476\n",
      "train loss:0.9013878194849002\n",
      "train loss:0.9504222472878625\n",
      "train loss:0.9605477126262799\n",
      "train loss:0.8571200887113549\n",
      "train loss:0.8399740235821909\n",
      "train loss:0.8438457493705962\n",
      "train loss:0.8917457381677066\n",
      "train loss:0.910987494472915\n",
      "train loss:0.7966381094396685\n",
      "train loss:1.0049549302321261\n",
      "train loss:0.8828779296799992\n",
      "train loss:0.94639943013644\n",
      "train loss:0.7121212626761855\n",
      "train loss:0.8613474451019587\n",
      "train loss:0.9710034542493011\n",
      "train loss:0.9572919832174521\n",
      "train loss:0.8865101821305614\n",
      "train loss:0.7192728427507366\n",
      "train loss:0.7602215091160142\n",
      "train loss:0.7248013448039149\n",
      "train loss:0.9783566951261601\n",
      "train loss:0.7476430792498586\n",
      "train loss:0.9426858966868659\n",
      "train loss:1.0048688362851061\n",
      "train loss:0.8337578280509048\n",
      "train loss:0.8672496438879963\n",
      "train loss:0.8289964849653398\n",
      "train loss:0.8931845773685947\n",
      "train loss:0.6128397482893131\n",
      "train loss:0.8069118889863853\n",
      "train loss:1.0060815231364897\n",
      "train loss:1.0042707866929237\n",
      "train loss:0.8553470287712079\n",
      "train loss:0.8143204583374594\n",
      "train loss:0.8950799656609999\n",
      "train loss:0.8799255840111413\n",
      "train loss:0.9041103506835357\n",
      "train loss:0.9296433353939753\n",
      "train loss:0.7160198882148783\n",
      "train loss:0.929057805358987\n",
      "train loss:0.9032905852280474\n",
      "train loss:0.7620471837629514\n",
      "train loss:0.7837727106177601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.8464162589293359\n",
      "train loss:0.9583099938991126\n",
      "train loss:0.7545902034593764\n",
      "train loss:0.9947065530881304\n",
      "train loss:0.7684889405907666\n",
      "train loss:0.9442929639057251\n",
      "train loss:0.8488493434339073\n",
      "train loss:0.8930755973242449\n",
      "train loss:0.909597230186264\n",
      "train loss:0.829889038789655\n",
      "train loss:1.0171201155386118\n",
      "train loss:0.9416531979337988\n",
      "train loss:0.8621512291051673\n",
      "train loss:0.8801390815866479\n",
      "train loss:0.7697347568041468\n",
      "train loss:0.7627084240972002\n",
      "train loss:0.9911625033768374\n",
      "train loss:0.797899032138438\n",
      "train loss:0.8091670142752655\n",
      "train loss:0.7688717087357041\n",
      "train loss:0.7942350385765904\n",
      "train loss:0.8147537401793525\n",
      "train loss:0.9361780230032586\n",
      "train loss:0.9774775190403305\n",
      "train loss:1.0039733455579487\n",
      "train loss:0.9396660811284576\n",
      "train loss:0.7981658964966246\n",
      "train loss:0.81559175894149\n",
      "train loss:0.900643582575819\n",
      "train loss:0.7949148350775996\n",
      "train loss:0.9584020975281092\n",
      "train loss:0.8698543940975854\n",
      "train loss:0.7511317485325273\n",
      "train loss:0.8302023354813158\n",
      "train loss:0.8587330991719447\n",
      "train loss:0.935439560856438\n",
      "train loss:0.7546653700783379\n",
      "train loss:0.8987650730518608\n",
      "train loss:0.9325485703348054\n",
      "train loss:0.9502609254214549\n",
      "train loss:0.7878583313713754\n",
      "train loss:0.8508839688935121\n",
      "train loss:1.056011076880265\n",
      "train loss:0.9080188671078266\n",
      "train loss:0.8778389808962734\n",
      "train loss:0.8652653358578627\n",
      "train loss:0.950931381628871\n",
      "train loss:0.6644115951098345\n",
      "train loss:0.8647570464426427\n",
      "train loss:0.9155655585152611\n",
      "train loss:0.8686622413336196\n",
      "train loss:1.015222743394253\n",
      "train loss:0.8958073718882649\n",
      "train loss:0.9658912276251859\n",
      "train loss:0.9863361330507834\n",
      "train loss:0.9236890016522095\n",
      "train loss:0.9425085139706495\n",
      "train loss:0.8420890024872472\n",
      "train loss:0.909659833700098\n",
      "train loss:0.8886935151456384\n",
      "train loss:0.8690887669177616\n",
      "train loss:0.9168004926618116\n",
      "train loss:0.8814348130745158\n",
      "train loss:0.7728031354775814\n",
      "train loss:0.8173364566193452\n",
      "train loss:0.6264965149471071\n",
      "train loss:0.7929332861017377\n",
      "train loss:0.874752342435804\n",
      "train loss:1.075634785233429\n",
      "train loss:0.8777155719877107\n",
      "train loss:0.7537457902759591\n",
      "train loss:0.7165007598094638\n",
      "train loss:0.6792481173529232\n",
      "train loss:0.9293360658415843\n",
      "train loss:1.0363569953520662\n",
      "train loss:0.8415576021116116\n",
      "train loss:0.9373582531600033\n",
      "train loss:0.6594406060152488\n",
      "train loss:0.8749266362672812\n",
      "train loss:0.9843300845357287\n",
      "train loss:0.9378457546113449\n",
      "train loss:0.8295057663214458\n",
      "train loss:1.0135448507572895\n",
      "train loss:0.8645034285500826\n",
      "train loss:0.8202245764244206\n",
      "train loss:0.7931496824180515\n",
      "train loss:0.9336014881049638\n",
      "train loss:0.9110270603938928\n",
      "train loss:0.9464692555132764\n",
      "train loss:0.9248435795220068\n",
      "train loss:0.8350059688239861\n",
      "train loss:0.7703256211772466\n",
      "train loss:0.7908428027496827\n",
      "train loss:1.0797777253505523\n",
      "train loss:0.776867182871016\n",
      "train loss:0.9898223441345047\n",
      "train loss:0.7837884042871768\n",
      "train loss:0.7972623595858547\n",
      "train loss:0.6881844500054056\n",
      "train loss:0.7968902989959373\n",
      "train loss:0.8753672500023143\n",
      "train loss:0.9822810828865894\n",
      "train loss:0.8247011746926266\n",
      "train loss:0.8009027492160773\n",
      "train loss:0.8855818528534097\n",
      "train loss:0.7549780087000572\n",
      "train loss:0.8722925202522983\n",
      "train loss:0.788942416289332\n",
      "train loss:0.7045065058146736\n",
      "train loss:0.8611466045196142\n",
      "train loss:0.8349323507053577\n",
      "train loss:0.7598547939787642\n",
      "train loss:0.9264475648810236\n",
      "train loss:0.8938808012568318\n",
      "train loss:0.9960222608393317\n",
      "train loss:0.9732699249813673\n",
      "train loss:0.9292796435493085\n",
      "train loss:0.9680194627174789\n",
      "train loss:0.7972038115686427\n",
      "train loss:0.8552574447012168\n",
      "train loss:0.9245141023587564\n",
      "train loss:0.8646806874140749\n",
      "train loss:0.70800513286462\n",
      "train loss:0.9618460552301252\n",
      "train loss:0.8862241219618112\n",
      "train loss:0.8681252627344239\n",
      "train loss:0.8692814102084427\n",
      "train loss:0.7297236473384848\n",
      "train loss:0.8932832954997468\n",
      "train loss:0.8272608765335308\n",
      "train loss:1.0607089337233446\n",
      "train loss:0.8921357143174683\n",
      "train loss:0.8415125642852818\n",
      "train loss:0.8691123957801692\n",
      "train loss:0.9057353219836303\n",
      "train loss:0.785356558028339\n",
      "train loss:0.7235214114226182\n",
      "train loss:0.9562046703300429\n",
      "train loss:0.7730624820985537\n",
      "train loss:0.9599836651482179\n",
      "train loss:0.8266484042912817\n",
      "train loss:0.677663016370851\n",
      "train loss:0.8409939660042026\n",
      "train loss:0.769895815579948\n",
      "train loss:0.7488982074194969\n",
      "train loss:0.7411482390854238\n",
      "train loss:0.7752981040873067\n",
      "train loss:1.0023704470506096\n",
      "train loss:0.8743770494303411\n",
      "train loss:0.8493883640118625\n",
      "train loss:0.7892394670141074\n",
      "train loss:0.7772930243699195\n",
      "train loss:0.8924762235839435\n",
      "train loss:0.7689762553791235\n",
      "train loss:0.8427037279076788\n",
      "train loss:0.8784570748636508\n",
      "train loss:0.8101075448623003\n",
      "train loss:0.8745568128817887\n",
      "train loss:0.9904965292793066\n",
      "train loss:0.784952777624432\n",
      "train loss:0.761500113090768\n",
      "train loss:0.9228622787797386\n",
      "train loss:0.7710268718837544\n",
      "train loss:0.8761943419895236\n",
      "train loss:0.9041981284564768\n",
      "train loss:0.8566884369010432\n",
      "train loss:0.8285070008259278\n",
      "train loss:0.8318267280845926\n",
      "train loss:0.8639423137970123\n",
      "train loss:0.9822609261701932\n",
      "train loss:1.0017600715470194\n",
      "train loss:0.8746791114577961\n",
      "train loss:0.897761094070114\n",
      "train loss:0.8252678235828751\n",
      "train loss:0.7109121601758325\n",
      "train loss:0.892798972583465\n",
      "train loss:0.8120650870756192\n",
      "train loss:0.8890919518639587\n",
      "train loss:1.0647538322547563\n",
      "train loss:1.000463187070267\n",
      "train loss:0.8353053936434113\n",
      "train loss:0.913860961358508\n",
      "train loss:0.7590975285033988\n",
      "train loss:0.8631267962120264\n",
      "train loss:0.6564574123409099\n",
      "train loss:0.9943280621681063\n",
      "train loss:0.8131580538539184\n",
      "train loss:0.9108226657073076\n",
      "train loss:0.8960527554283375\n",
      "train loss:0.8256716022290737\n",
      "train loss:0.982414644149181\n",
      "train loss:0.8516138992873209\n",
      "train loss:0.881483581651182\n",
      "train loss:0.9711437098760994\n",
      "train loss:0.8157557291036162\n",
      "train loss:0.9699793316129507\n",
      "train loss:0.8408563201649131\n",
      "train loss:0.8789885414124808\n",
      "train loss:0.9218406715538738\n",
      "train loss:0.8483622735658861\n",
      "train loss:0.782912360840502\n",
      "train loss:0.9736775347957828\n",
      "train loss:0.8403896942926129\n",
      "train loss:0.9602426902487544\n",
      "train loss:0.8639230202878672\n",
      "train loss:0.8582297869329006\n",
      "train loss:0.8924312361978584\n",
      "train loss:1.056338816531942\n",
      "train loss:0.9440613096750491\n",
      "train loss:0.8605591057713994\n",
      "train loss:0.6666884740529148\n",
      "train loss:0.7560966606307287\n",
      "train loss:0.8271717399912474\n",
      "train loss:0.894274177120316\n",
      "train loss:0.7985810125610819\n",
      "train loss:0.7843093389921664\n",
      "train loss:0.9466547349107504\n",
      "train loss:0.8600434318803367\n",
      "train loss:0.6866797151392399\n",
      "train loss:0.7411761706202965\n",
      "train loss:1.137873079892775\n",
      "train loss:0.9003237800163665\n",
      "train loss:0.8803538617972267\n",
      "train loss:0.9200956295064673\n",
      "train loss:0.7064459698193116\n",
      "train loss:0.8468962221160359\n",
      "train loss:0.8399849443378871\n",
      "train loss:0.776544462012691\n",
      "train loss:0.7764594924260776\n",
      "train loss:0.8516105324847538\n",
      "train loss:0.9860940640673096\n",
      "train loss:0.9334155772874335\n",
      "train loss:1.0351609766950753\n",
      "train loss:0.7951889386913855\n",
      "train loss:0.9245412979701161\n",
      "train loss:0.8641099514338993\n",
      "train loss:0.8277818890850591\n",
      "train loss:0.9952372037890005\n",
      "train loss:0.870434739885272\n",
      "train loss:0.956664348919752\n",
      "train loss:0.8776881709577693\n",
      "train loss:0.8949522655972129\n",
      "train loss:0.905548254324427\n",
      "train loss:0.7806982954238535\n",
      "train loss:1.0023721556245258\n",
      "train loss:0.8006546121072732\n",
      "train loss:1.1269239552562416\n",
      "train loss:0.8727653761586049\n",
      "train loss:0.9528398632878828\n",
      "train loss:0.8907939098352107\n",
      "train loss:0.9335283832813946\n",
      "train loss:1.0144317499670874\n",
      "train loss:0.7907413467387288\n",
      "train loss:0.7171863723200761\n",
      "train loss:1.002517533782452\n",
      "train loss:0.8898586003633153\n",
      "train loss:0.9207697232917681\n",
      "train loss:0.8847112260367236\n",
      "train loss:0.8151313377274235\n",
      "train loss:0.7579272307189026\n",
      "train loss:0.8503560748025895\n",
      "train loss:0.8824520390949906\n",
      "train loss:1.0708667811094474\n",
      "train loss:0.874010876722625\n",
      "train loss:0.8001290380902927\n",
      "train loss:0.8988612947883686\n",
      "train loss:0.9335791978157988\n",
      "train loss:0.880688148475424\n",
      "train loss:0.8884563329227271\n",
      "train loss:0.8813451428362931\n",
      "train loss:0.8281304236794768\n",
      "train loss:0.9397853840014381\n",
      "train loss:0.9136423283610534\n",
      "train loss:0.8377659163218436\n",
      "train loss:0.7741737335776151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.8345310290429011\n",
      "train loss:0.8401522124259684\n",
      "train loss:0.899895542704363\n",
      "train loss:0.890631775638601\n",
      "train loss:0.8825078600397169\n",
      "=== epoch:17, train acc:0.992, test acc:0.986 ===\n",
      "train loss:0.5394927345737414\n",
      "train loss:0.8613490682500565\n",
      "train loss:0.7799435795511548\n",
      "train loss:0.8497481529324443\n",
      "train loss:0.7980354514642565\n",
      "train loss:0.828371193600423\n",
      "train loss:0.8529635283631224\n",
      "train loss:0.7907421245139982\n",
      "train loss:0.8541805701389196\n",
      "train loss:0.9753400756222075\n",
      "train loss:0.9764832380487932\n",
      "train loss:0.9064654794653576\n",
      "train loss:0.9625944471450457\n",
      "train loss:0.7859091921193767\n",
      "train loss:0.9339587774335741\n",
      "train loss:0.8629951294023189\n",
      "train loss:0.8022725103870474\n",
      "train loss:0.8979786080187578\n",
      "train loss:0.8160563164277457\n",
      "train loss:0.7969752739941817\n",
      "train loss:0.9109917924422632\n",
      "train loss:1.0747914438108854\n",
      "train loss:0.8372292872754247\n",
      "train loss:0.8979540671254946\n",
      "train loss:0.9776055244749614\n",
      "train loss:0.8240482329465749\n",
      "train loss:0.9819415290315449\n",
      "train loss:0.98723760486213\n",
      "train loss:0.7302165782291342\n",
      "train loss:0.8803788724182511\n",
      "train loss:0.9293152402960936\n",
      "train loss:0.9703392248950011\n",
      "train loss:0.7654031081034012\n",
      "train loss:0.8225719599364578\n",
      "train loss:0.8191917053682204\n",
      "train loss:0.787760750991433\n",
      "train loss:0.8870277033170936\n",
      "train loss:0.8086462206236206\n",
      "train loss:0.9448717631935662\n",
      "train loss:1.0031217209362544\n",
      "train loss:1.0000062057388661\n",
      "train loss:0.8219489205840763\n",
      "train loss:0.9889270410534298\n",
      "train loss:0.9405315374881209\n",
      "train loss:0.88859381757129\n",
      "train loss:0.860742964580449\n",
      "train loss:0.8121537073114905\n",
      "train loss:0.8195257466251875\n",
      "train loss:0.9557748338425864\n",
      "train loss:0.8334032527193925\n",
      "train loss:0.791443670475064\n",
      "train loss:0.7841496456777008\n",
      "train loss:0.8642114674365656\n",
      "train loss:1.0042234790213636\n",
      "train loss:0.9270155469450698\n",
      "train loss:0.9553392925876746\n",
      "train loss:0.916316174937883\n",
      "train loss:0.8271377998260663\n",
      "train loss:0.7468790265136124\n",
      "train loss:0.9346489062392428\n",
      "train loss:0.837824437434505\n",
      "train loss:0.8509684572804211\n",
      "train loss:0.7816265409952624\n",
      "train loss:0.7506181676269128\n",
      "train loss:0.7868851480727095\n",
      "train loss:0.8643571363172414\n",
      "train loss:0.9450082277086785\n",
      "train loss:0.8518115439542542\n",
      "train loss:0.8673305453745581\n",
      "train loss:0.8367511688716927\n",
      "train loss:0.7620519252765259\n",
      "train loss:0.9123172408625762\n",
      "train loss:0.9128561322868178\n",
      "train loss:0.8892002786110386\n",
      "train loss:1.027089717472929\n",
      "train loss:0.752011106096672\n",
      "train loss:0.8845746471101742\n",
      "train loss:0.9316792194263958\n",
      "train loss:0.8566365377941852\n",
      "train loss:0.8980160096085633\n",
      "train loss:0.9154934318057408\n",
      "train loss:0.912844447708599\n",
      "train loss:0.9315551954662338\n",
      "train loss:0.79386202072217\n",
      "train loss:0.7612315103116576\n",
      "train loss:0.8331471038156449\n",
      "train loss:0.858676057927871\n",
      "train loss:1.046314213872892\n",
      "train loss:0.7931129402606445\n",
      "train loss:1.0911060042172804\n",
      "train loss:0.8681471786287949\n",
      "train loss:0.9907032247342411\n",
      "train loss:0.8984721992121468\n",
      "train loss:0.8162579869423893\n",
      "train loss:1.0105807633527428\n",
      "train loss:0.815991705507921\n",
      "train loss:0.9760352181509474\n",
      "train loss:0.9104012471738554\n",
      "train loss:0.917263952182888\n",
      "train loss:0.9072495036414465\n",
      "train loss:0.8594320636910466\n",
      "train loss:0.8283008884810508\n",
      "train loss:0.7514085998259425\n",
      "train loss:0.7931300926703887\n",
      "train loss:0.8698517193748992\n",
      "train loss:0.9508686613743619\n",
      "train loss:0.8966161889887446\n",
      "train loss:0.8982244510901645\n",
      "train loss:0.8200387887592813\n",
      "train loss:0.7768431323702444\n",
      "train loss:0.8708299758829474\n",
      "train loss:0.7738583225961735\n",
      "train loss:0.8090475009656655\n",
      "train loss:0.884177267384579\n",
      "train loss:0.884506498250295\n",
      "train loss:0.9590620092644889\n",
      "train loss:0.7378315201948802\n",
      "train loss:0.7060223432306383\n",
      "train loss:0.945243086666965\n",
      "train loss:0.7958023054308809\n",
      "train loss:0.7929254236191936\n",
      "train loss:0.7459473915738009\n",
      "train loss:0.9263052075476189\n",
      "train loss:0.8461818563943462\n",
      "train loss:0.7978525942357098\n",
      "train loss:0.8627814826824189\n",
      "train loss:0.9325979178691723\n",
      "train loss:0.7689395881261484\n",
      "train loss:0.8781657799889041\n",
      "train loss:0.8866492587966865\n",
      "train loss:0.793691647359386\n",
      "train loss:0.9699437157371043\n",
      "train loss:0.9440472603816517\n",
      "train loss:0.8205099985354767\n",
      "train loss:0.7272158165136999\n",
      "train loss:0.8616248781678578\n",
      "train loss:1.089266823244373\n",
      "train loss:0.7665251428928314\n",
      "train loss:0.7860572398382896\n",
      "train loss:0.8325296480185626\n",
      "train loss:0.7436775958311074\n",
      "train loss:0.8484168979675806\n",
      "train loss:0.9731094129886704\n",
      "train loss:0.8558154356774524\n",
      "train loss:0.9528383039066665\n",
      "train loss:0.8407747087249646\n",
      "train loss:0.789141807797882\n",
      "train loss:0.9557557507073604\n",
      "train loss:1.018268951270787\n",
      "train loss:0.8163713558241871\n",
      "train loss:0.9390194087450423\n",
      "train loss:0.8229313055515144\n",
      "train loss:0.8033969246945049\n",
      "train loss:0.954502642722018\n",
      "train loss:0.8676604657747476\n",
      "train loss:0.7969560541950363\n",
      "train loss:0.9002774435907009\n",
      "train loss:0.9102205438628863\n",
      "train loss:0.8140890000201734\n",
      "train loss:0.9296984919750227\n",
      "train loss:1.0750907051408793\n",
      "train loss:0.8412065898359278\n",
      "train loss:0.780265949804421\n",
      "train loss:0.8952130546307022\n",
      "train loss:0.8790550685083164\n",
      "train loss:0.867587256002762\n",
      "train loss:0.788537371329959\n",
      "train loss:0.9632060521314333\n",
      "train loss:0.9034311512262195\n",
      "train loss:0.8640810078630621\n",
      "train loss:0.8341757598926898\n",
      "train loss:1.0316433876709672\n",
      "train loss:0.7843158674189735\n",
      "train loss:0.8947187214664902\n",
      "train loss:0.8285169727724182\n",
      "train loss:1.0260738038672839\n",
      "train loss:0.7644236843228616\n",
      "train loss:0.8584685342136917\n",
      "train loss:0.9928596829634446\n",
      "train loss:0.7407742152969989\n",
      "train loss:0.6783836124223047\n",
      "train loss:0.9336559499495355\n",
      "train loss:0.8461699531578502\n",
      "train loss:0.8203026602021888\n",
      "train loss:0.8438307109637868\n",
      "train loss:1.0348897088447577\n",
      "train loss:0.7728895661869903\n",
      "train loss:0.877218280006414\n",
      "train loss:0.948838219559592\n",
      "train loss:0.8992279865139565\n",
      "train loss:0.8150886832282646\n",
      "train loss:0.6939027536912351\n",
      "train loss:0.7415318661254616\n",
      "train loss:0.833767354923506\n",
      "train loss:0.8243926281741801\n",
      "train loss:1.0630286208597821\n",
      "train loss:0.8487580761169792\n",
      "train loss:0.8522579547659686\n",
      "train loss:0.9276387749754653\n",
      "train loss:0.8246728661968905\n",
      "train loss:0.8104180024951471\n",
      "train loss:0.8545146635990197\n",
      "train loss:0.906278604979084\n",
      "train loss:0.880705920301732\n",
      "train loss:0.7451512061846747\n",
      "train loss:0.9488630239173331\n",
      "train loss:0.7780028933016275\n",
      "train loss:0.7835270582318918\n",
      "train loss:0.9190188446085585\n",
      "train loss:0.8556827280764822\n",
      "train loss:0.9287659377750836\n",
      "train loss:0.8980535559172179\n",
      "train loss:0.914069835987937\n",
      "train loss:0.8692005303022742\n",
      "train loss:0.9088002379828924\n",
      "train loss:0.7093143506594495\n",
      "train loss:0.8200963755224595\n",
      "train loss:0.9101027260602659\n",
      "train loss:0.7866253472981108\n",
      "train loss:0.8082399577450095\n",
      "train loss:0.7714304864839793\n",
      "train loss:0.8189724607620454\n",
      "train loss:0.7820755610826796\n",
      "train loss:0.955176288247817\n",
      "train loss:0.85361197132205\n",
      "train loss:1.0337394801211293\n",
      "train loss:0.8210583765567202\n",
      "train loss:0.8092744653650346\n",
      "train loss:0.8912774735123749\n",
      "train loss:0.7359681280593168\n",
      "train loss:0.8819329928283122\n",
      "train loss:1.0066200323161585\n",
      "train loss:0.7275393147834768\n",
      "train loss:0.923293104621222\n",
      "train loss:0.6551260578179616\n",
      "train loss:0.8389549911092337\n",
      "train loss:0.8498689267548768\n",
      "train loss:0.7496137468762132\n",
      "train loss:0.6565580455300054\n",
      "train loss:0.9449466793273467\n",
      "train loss:0.8829600531046489\n",
      "train loss:0.994097232308878\n",
      "train loss:0.8185991633683762\n",
      "train loss:0.7082436535372849\n",
      "train loss:0.9988391593298274\n",
      "train loss:0.8872392300525351\n",
      "train loss:0.8955187240544724\n",
      "train loss:0.9313402066648746\n",
      "train loss:0.7345441010718536\n",
      "train loss:0.8865393799368584\n",
      "train loss:0.8746820106972923\n",
      "train loss:0.8156748644029964\n",
      "train loss:1.069264750272025\n",
      "train loss:0.8246388863185343\n",
      "train loss:0.9315926059288586\n",
      "train loss:0.8636788796835602\n",
      "train loss:0.804353402446919\n",
      "train loss:0.8948531281791525\n",
      "train loss:0.9482815721739146\n",
      "train loss:0.8317823676611479\n",
      "train loss:0.9343077232266451\n",
      "train loss:1.0379675506084447\n",
      "train loss:0.9944853454945505\n",
      "train loss:0.8304835376468637\n",
      "train loss:0.9630005866509758\n",
      "train loss:0.8800781781511919\n",
      "train loss:0.8277707394698726\n",
      "train loss:0.8490139511190766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.8118736670316277\n",
      "train loss:0.6973540044396553\n",
      "train loss:0.8562893545735553\n",
      "train loss:0.7883792138248314\n",
      "train loss:0.7814151645191152\n",
      "train loss:0.9599070329080301\n",
      "train loss:0.9258388704232372\n",
      "train loss:0.8724438666187169\n",
      "train loss:0.891266079635042\n",
      "train loss:0.8675706807155492\n",
      "train loss:1.1050704232998316\n",
      "train loss:0.9215733767916829\n",
      "train loss:0.8288851258901841\n",
      "train loss:0.8994829373518539\n",
      "train loss:0.8623770178949209\n",
      "train loss:0.7553858873586573\n",
      "train loss:0.6341161583185572\n",
      "train loss:0.9074767108028549\n",
      "train loss:0.917154782737268\n",
      "train loss:0.9895162290848077\n",
      "train loss:0.9279669193135776\n",
      "train loss:0.9217150970757111\n",
      "train loss:0.8756315908046735\n",
      "train loss:0.9453276030480419\n",
      "train loss:0.8318348129135401\n",
      "train loss:1.0072814259910632\n",
      "train loss:0.8302898268314932\n",
      "train loss:0.8145394937981482\n",
      "train loss:0.804022431895129\n",
      "train loss:0.8704367348822357\n",
      "train loss:0.8852655989966876\n",
      "train loss:0.7259613893141588\n",
      "train loss:0.9392560998112189\n",
      "train loss:0.8733367480863091\n",
      "train loss:0.9136133601999833\n",
      "train loss:0.9028631625033953\n",
      "train loss:1.0119720978215812\n",
      "train loss:0.9329291005812181\n",
      "train loss:0.9759581283080315\n",
      "train loss:0.9358867145339098\n",
      "train loss:0.9131241108054318\n",
      "train loss:0.9709087513997033\n",
      "train loss:0.8897222185821217\n",
      "train loss:0.9002893261514666\n",
      "train loss:0.8084221076543976\n",
      "train loss:0.7737388756211836\n",
      "train loss:0.8044237915005552\n",
      "train loss:0.9050612908112338\n",
      "train loss:0.86557596575133\n",
      "train loss:0.9398687987231298\n",
      "train loss:0.965175333571506\n",
      "train loss:0.9133459008899014\n",
      "train loss:0.854245340598948\n",
      "train loss:0.9556101019502536\n",
      "train loss:0.9093460261510571\n",
      "train loss:0.9229891211649341\n",
      "train loss:0.9323613410352989\n",
      "train loss:0.9829437623136272\n",
      "train loss:0.9050013063159582\n",
      "train loss:0.8192767894549589\n",
      "train loss:0.7671785665303313\n",
      "train loss:1.0355429193296615\n",
      "train loss:0.986958737382507\n",
      "train loss:1.0316597251592763\n",
      "train loss:1.0309349009842033\n",
      "train loss:0.809660245641626\n",
      "train loss:0.8039927132248269\n",
      "train loss:0.897519470634177\n",
      "train loss:0.9235060490390598\n",
      "train loss:1.0338726363766881\n",
      "train loss:0.7962799434411394\n",
      "train loss:0.9057977554349372\n",
      "train loss:0.8225810379383005\n",
      "train loss:0.793658398446473\n",
      "train loss:0.9153383490467276\n",
      "train loss:0.6476899807066866\n",
      "train loss:0.8910041638396171\n",
      "train loss:0.9374680446522241\n",
      "train loss:0.9059886342025187\n",
      "train loss:0.7866247744997759\n",
      "train loss:0.934432808082933\n",
      "train loss:1.0431927274751458\n",
      "train loss:0.8290669267994717\n",
      "train loss:0.9770390897804312\n",
      "train loss:0.9152559760580284\n",
      "train loss:0.8889497049097669\n",
      "train loss:0.8324857862164502\n",
      "train loss:1.0414177807359262\n",
      "train loss:0.9025075980078947\n",
      "train loss:0.9408153587628051\n",
      "train loss:0.9092447909360406\n",
      "train loss:0.7814667023943348\n",
      "train loss:0.9080831182882011\n",
      "train loss:0.9781262202807581\n",
      "train loss:0.9680380805875511\n",
      "train loss:0.9236604621976232\n",
      "train loss:0.8695155176811076\n",
      "train loss:0.7806965809091589\n",
      "train loss:0.8380939170083305\n",
      "train loss:0.9201638503506654\n",
      "train loss:0.945943875984307\n",
      "train loss:0.991834235043891\n",
      "train loss:0.8056119707555525\n",
      "train loss:0.733121662842513\n",
      "train loss:0.9793204647373365\n",
      "train loss:0.8431247143123951\n",
      "train loss:0.7896913118332975\n",
      "train loss:0.8724280079692635\n",
      "train loss:0.8233505836549732\n",
      "train loss:0.8394019109946801\n",
      "train loss:0.977008419931895\n",
      "train loss:0.7795710290459033\n",
      "train loss:0.9462278147553626\n",
      "train loss:0.7974286411177897\n",
      "train loss:0.9437931877458628\n",
      "train loss:0.8420372724965118\n",
      "train loss:0.7448879109715536\n",
      "train loss:0.7380513737815604\n",
      "train loss:0.8583387157682109\n",
      "train loss:0.8965887015705596\n",
      "train loss:0.8492210321596794\n",
      "train loss:0.8358046850806923\n",
      "train loss:0.752504170389347\n",
      "train loss:0.930989701523539\n",
      "train loss:0.8323145449253384\n",
      "train loss:0.8554061598804037\n",
      "train loss:0.962603705329007\n",
      "train loss:0.9977986122158442\n",
      "train loss:0.9946380901437784\n",
      "train loss:0.8527964421179096\n",
      "train loss:0.8736137280852713\n",
      "train loss:0.9664965455472554\n",
      "train loss:0.955168701367754\n",
      "train loss:0.8540427990484781\n",
      "train loss:0.7099488413344571\n",
      "train loss:0.9246117961558801\n",
      "train loss:0.7526732971567036\n",
      "train loss:0.8146070019014364\n",
      "train loss:0.7514187705048605\n",
      "train loss:0.8014164586175139\n",
      "train loss:0.806033977938574\n",
      "train loss:0.8919005490081477\n",
      "train loss:0.7678998485207618\n",
      "train loss:0.825995439979456\n",
      "train loss:0.7104061656763788\n",
      "train loss:1.0362759988844628\n",
      "train loss:0.9162352178911665\n",
      "train loss:0.9668893198604893\n",
      "train loss:0.9163237619064947\n",
      "train loss:0.9398357870498739\n",
      "train loss:1.0700591289387291\n",
      "train loss:0.9382822520858906\n",
      "train loss:0.8159925137732231\n",
      "train loss:0.8510066364668318\n",
      "train loss:0.960672518753656\n",
      "train loss:0.8613494106505857\n",
      "train loss:0.9175300269965335\n",
      "train loss:0.9367704587223942\n",
      "train loss:0.8563267663915439\n",
      "train loss:0.789903927174361\n",
      "train loss:0.7912878488815653\n",
      "train loss:0.7778812589337817\n",
      "train loss:0.7143842051216549\n",
      "train loss:0.8106969432694396\n",
      "train loss:0.9049857587838248\n",
      "train loss:0.7157645904214976\n",
      "train loss:0.9454810296696173\n",
      "train loss:0.9398490272267642\n",
      "train loss:0.7848859374432477\n",
      "train loss:0.9144482584844839\n",
      "train loss:0.8834273734542328\n",
      "train loss:0.9377539044452923\n",
      "train loss:0.7832841109005696\n",
      "train loss:0.7541687250011236\n",
      "train loss:0.9399551752283731\n",
      "train loss:0.9253496667389236\n",
      "train loss:0.5253258386163325\n",
      "train loss:0.8257577197607923\n",
      "train loss:0.8808877370384164\n",
      "train loss:0.8638365088071958\n",
      "train loss:0.8484868850393634\n",
      "train loss:0.8336950353575991\n",
      "train loss:0.8149662747875565\n",
      "train loss:0.9571969452854292\n",
      "train loss:0.7583577588496351\n",
      "train loss:0.7644832959102046\n",
      "train loss:0.7484559305695673\n",
      "train loss:0.8443497162150794\n",
      "train loss:0.9653464195253665\n",
      "train loss:0.9876003873887191\n",
      "train loss:0.8957660171053874\n",
      "train loss:0.733413058731823\n",
      "train loss:0.8949417348101345\n",
      "train loss:0.8356667640591041\n",
      "train loss:0.9191335697214855\n",
      "train loss:0.8539964789090488\n",
      "train loss:0.8256901758257544\n",
      "train loss:0.9344719247023684\n",
      "train loss:0.8453436213483531\n",
      "train loss:1.0375890055019814\n",
      "train loss:0.764180316499073\n",
      "train loss:0.8762124792001978\n",
      "train loss:0.8062361041976506\n",
      "train loss:0.7565032557787399\n",
      "train loss:0.6870379131254407\n",
      "train loss:0.7104645071134315\n",
      "train loss:0.8990696208249075\n",
      "train loss:0.7883228270735979\n",
      "train loss:0.8917828589652818\n",
      "train loss:0.8739819959329512\n",
      "train loss:0.6820912510677065\n",
      "train loss:0.8980464524658348\n",
      "train loss:0.924285184453103\n",
      "train loss:0.8058990209656776\n",
      "train loss:0.7924956526649031\n",
      "train loss:0.8133532583923361\n",
      "train loss:0.9181495175401229\n",
      "train loss:0.9226170460311764\n",
      "train loss:0.7716070670398194\n",
      "train loss:0.887750264781419\n",
      "train loss:0.8984476406772292\n",
      "train loss:0.8163988078719844\n",
      "train loss:0.8222385526013372\n",
      "train loss:0.8442705150941414\n",
      "train loss:0.7751553233800468\n",
      "train loss:0.7183263691133791\n",
      "train loss:0.9457332767004971\n",
      "train loss:1.0267719219528906\n",
      "train loss:0.9786717499949324\n",
      "train loss:1.0424219196861622\n",
      "train loss:0.9501748508364649\n",
      "train loss:0.7902185492004251\n",
      "train loss:0.9406879959781723\n",
      "train loss:0.8789370701608356\n",
      "train loss:0.8219423441287667\n",
      "train loss:0.9486547401498362\n",
      "train loss:0.9690141015353696\n",
      "train loss:0.741012222987075\n",
      "train loss:0.9176304490530282\n",
      "train loss:0.8895895954664843\n",
      "train loss:0.9909898094862989\n",
      "train loss:0.7978193538388926\n",
      "train loss:0.926591819376462\n",
      "train loss:1.0450077460269669\n",
      "train loss:0.8338718100056566\n",
      "train loss:0.9597550496666684\n",
      "train loss:0.601146171271482\n",
      "train loss:0.7581126932291685\n",
      "train loss:0.8262570896561346\n",
      "train loss:0.8454845713656642\n",
      "train loss:0.9338835123040522\n",
      "train loss:0.9569583608304016\n",
      "train loss:0.9307583948039997\n",
      "train loss:0.9120787908719616\n",
      "train loss:0.8698684130457489\n",
      "train loss:0.8515475858983719\n",
      "train loss:0.7851067989823132\n",
      "train loss:0.8984692369152592\n",
      "train loss:0.8247677513595691\n",
      "train loss:0.7609872220267025\n",
      "train loss:0.7295569058913189\n",
      "train loss:0.7931724624837609\n",
      "train loss:0.7305730615909118\n",
      "train loss:0.8433470087651314\n",
      "train loss:0.854470177938851\n",
      "train loss:0.9025822217803336\n",
      "train loss:0.7974348607457631\n",
      "train loss:0.6931660771945962\n",
      "train loss:0.9221585433822769\n",
      "train loss:0.9288003678520269\n",
      "train loss:0.856582189348794\n",
      "train loss:0.8563195797801316\n",
      "train loss:0.8276299244364025\n",
      "train loss:1.011920424481405\n",
      "train loss:0.9427432894522638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.864808090525196\n",
      "train loss:0.8722491188749053\n",
      "train loss:0.7989830729559446\n",
      "train loss:0.9675907189193232\n",
      "train loss:0.8552789196830445\n",
      "train loss:0.9175386734693736\n",
      "train loss:0.7110755065591718\n",
      "train loss:0.7250612577805735\n",
      "train loss:0.873816082238675\n",
      "train loss:0.9543610564306922\n",
      "train loss:0.8392307199066478\n",
      "train loss:0.7615028568584453\n",
      "train loss:1.0276763876739674\n",
      "train loss:0.8222530299670275\n",
      "train loss:0.8518109145992522\n",
      "train loss:0.7860135443082084\n",
      "train loss:0.8332098354306983\n",
      "train loss:0.8788496925714808\n",
      "train loss:0.7264248185282561\n",
      "train loss:0.8745678580505738\n",
      "train loss:0.7993569147410983\n",
      "train loss:0.852797074608874\n",
      "train loss:0.871377607411313\n",
      "train loss:0.8213010620561166\n",
      "train loss:0.7862745860350054\n",
      "train loss:0.9580666663337215\n",
      "train loss:0.900052431352836\n",
      "train loss:0.9877615212481017\n",
      "train loss:0.809342058614734\n",
      "train loss:0.6977552206941914\n",
      "train loss:1.0092504143830576\n",
      "train loss:0.8641711987383259\n",
      "train loss:0.9608531325162378\n",
      "train loss:0.8745425415815795\n",
      "train loss:0.9743316940627278\n",
      "train loss:0.8917914584575856\n",
      "train loss:0.7758245249187102\n",
      "train loss:0.8436700616848657\n",
      "train loss:1.1422177868262535\n",
      "train loss:0.8861424992103235\n",
      "train loss:0.9073036124433637\n",
      "train loss:0.9486350393785423\n",
      "train loss:0.9148136573708263\n",
      "train loss:0.7858088830458765\n",
      "train loss:0.9124214240215202\n",
      "train loss:0.7744711950589113\n",
      "train loss:0.9607881650585677\n",
      "train loss:0.957391106597008\n",
      "train loss:0.8890708295888597\n",
      "train loss:0.8158689455146785\n",
      "train loss:0.9267787168884829\n",
      "train loss:0.9216195174918752\n",
      "train loss:0.9096664090594093\n",
      "train loss:0.7724868857830333\n",
      "train loss:0.8305366765370171\n",
      "train loss:0.7598246346896894\n",
      "train loss:1.0045185293448637\n",
      "=== epoch:18, train acc:0.998, test acc:0.992 ===\n",
      "train loss:0.810226421410199\n",
      "train loss:0.7551353652978712\n",
      "train loss:0.9194443432657784\n",
      "train loss:0.7633755924456382\n",
      "train loss:0.8056766512853966\n",
      "train loss:0.839166756698884\n",
      "train loss:1.0664331713441841\n",
      "train loss:1.0258326784740297\n",
      "train loss:0.7975000111141171\n",
      "train loss:0.8453534041054931\n",
      "train loss:0.8972416472409391\n",
      "train loss:0.7221092618886403\n",
      "train loss:0.8128078361071907\n",
      "train loss:0.7774139553668844\n",
      "train loss:0.9516044392218035\n",
      "train loss:0.9202126073524785\n",
      "train loss:0.8922428008047416\n",
      "train loss:0.7951156318496235\n",
      "train loss:0.8075808709761563\n",
      "train loss:1.026183267649554\n",
      "train loss:0.91001902931243\n",
      "train loss:0.7761116560275144\n",
      "train loss:0.7995814868384852\n",
      "train loss:0.7891009964638264\n",
      "train loss:0.750092433137591\n",
      "train loss:0.9977346347977796\n",
      "train loss:0.9447003063155482\n",
      "train loss:0.8422412407008689\n",
      "train loss:0.7193215833581778\n",
      "train loss:0.8927912559789319\n",
      "train loss:0.8867181869586588\n",
      "train loss:0.8106774353792114\n",
      "train loss:0.7654377140277685\n",
      "train loss:0.8506505804041602\n",
      "train loss:0.7694278296598338\n",
      "train loss:0.8287563982485858\n",
      "train loss:0.7505831837895204\n",
      "train loss:0.9121610911248108\n",
      "train loss:0.8649146327076173\n",
      "train loss:0.8560451192588303\n",
      "train loss:0.9831931127606662\n",
      "train loss:0.8232129716315306\n",
      "train loss:0.9083926936684732\n",
      "train loss:0.832666600618921\n",
      "train loss:0.8591895180051491\n",
      "train loss:0.7453920904154531\n",
      "train loss:0.9776354174196519\n",
      "train loss:0.9216503230764259\n",
      "train loss:0.8662119779303432\n",
      "train loss:0.7627515203486611\n",
      "train loss:1.0393043925079908\n",
      "train loss:0.6689150955816748\n",
      "train loss:1.0082359518959043\n",
      "train loss:0.9658674303580593\n",
      "train loss:0.9458440837919888\n",
      "train loss:0.801898076578442\n",
      "train loss:0.758974431245976\n",
      "train loss:0.8983849244867159\n",
      "train loss:1.07416486993954\n",
      "train loss:0.646632476904813\n",
      "train loss:0.9480645551235605\n",
      "train loss:0.7002526197807151\n",
      "train loss:0.732940954741494\n",
      "train loss:0.7914160624874468\n",
      "train loss:0.7917721733963313\n",
      "train loss:0.996195867354801\n",
      "train loss:0.9977054271383824\n",
      "train loss:0.9264889449161982\n",
      "train loss:0.6872924601878572\n",
      "train loss:0.8839966401639262\n",
      "train loss:0.8506282572940895\n",
      "train loss:0.7547353252146255\n",
      "train loss:0.9286497128693543\n",
      "train loss:0.7393002028600744\n",
      "train loss:0.8675161666044285\n",
      "train loss:0.8778720309277162\n",
      "train loss:0.7494440375999377\n",
      "train loss:0.9239905426409775\n",
      "train loss:0.9927819386586522\n",
      "train loss:0.6944707502034578\n",
      "train loss:0.8714646204559007\n",
      "train loss:0.7801318453178407\n",
      "train loss:0.8757062620806731\n",
      "train loss:0.891167407031356\n",
      "train loss:0.6458911278556161\n",
      "train loss:0.9242993380312715\n",
      "train loss:0.7389101787195466\n",
      "train loss:1.0777541107176396\n",
      "train loss:0.9293422522278247\n",
      "train loss:0.8487079990537575\n",
      "train loss:0.8420082299852364\n",
      "train loss:1.171492448731253\n",
      "train loss:0.7943218834481458\n",
      "train loss:0.972708133805736\n",
      "train loss:0.9439444403302825\n",
      "train loss:0.9474107191688078\n",
      "train loss:0.8966895711930372\n",
      "train loss:0.9032861982098143\n",
      "train loss:0.8055106366854382\n",
      "train loss:0.811562503694356\n",
      "train loss:0.9816223032812178\n",
      "train loss:0.9580599754713915\n",
      "train loss:0.8477984152575533\n",
      "train loss:0.966290742281219\n",
      "train loss:1.009071830493353\n",
      "train loss:0.879522077371069\n",
      "train loss:0.8967861847573692\n",
      "train loss:0.7843951816111883\n",
      "train loss:0.8921340580929324\n",
      "train loss:0.9669421153331887\n",
      "train loss:0.9507810126473442\n",
      "train loss:0.9179193577812803\n",
      "train loss:0.8462178481312336\n",
      "train loss:0.977683241711022\n",
      "train loss:0.786479521414623\n",
      "train loss:0.8508948212335758\n",
      "train loss:0.7633615334078014\n",
      "train loss:0.747567411532593\n",
      "train loss:0.9449052942486372\n",
      "train loss:0.7852717945174006\n",
      "train loss:0.8492565982597968\n",
      "train loss:1.004460705621446\n",
      "train loss:0.7225512101945122\n",
      "train loss:0.8073482447038282\n",
      "train loss:0.7299320188481806\n",
      "train loss:0.7103021853962148\n",
      "train loss:0.8693084288695521\n",
      "train loss:0.8305531194368412\n",
      "train loss:0.745323988919739\n",
      "train loss:0.8064825061376004\n",
      "train loss:0.8923535361378296\n",
      "train loss:0.8751610649248488\n",
      "train loss:0.9137953537488069\n",
      "train loss:0.8754445186670577\n",
      "train loss:1.0040517069728845\n",
      "train loss:0.8282160509775411\n",
      "train loss:0.976846384569905\n",
      "train loss:0.9304783376431895\n",
      "train loss:0.9582408172277358\n",
      "train loss:0.7531734902198975\n",
      "train loss:0.6527053432094015\n",
      "train loss:0.7905172003657599\n",
      "train loss:0.8671605841974613\n",
      "train loss:0.8558260054597292\n",
      "train loss:0.7468976273683022\n",
      "train loss:0.8586332766440528\n",
      "train loss:0.9646928720703553\n",
      "train loss:0.882763848742495\n",
      "train loss:0.9198384680505799\n",
      "train loss:0.9206978134318708\n",
      "train loss:0.8474680930090435\n",
      "train loss:0.9166527930060593\n",
      "train loss:0.9227711181905403\n",
      "train loss:0.9427406893468304\n",
      "train loss:0.8218713268376899\n",
      "train loss:0.775147331832459\n",
      "train loss:0.8575701884989613\n",
      "train loss:0.8362681445560919\n",
      "train loss:0.816944401271794\n",
      "train loss:0.8344438202588615\n",
      "train loss:0.9303510269375685\n",
      "train loss:0.9057412318594732\n",
      "train loss:0.841233651934787\n",
      "train loss:0.8902530241138824\n",
      "train loss:0.8169067779832042\n",
      "train loss:0.6998772518027202\n",
      "train loss:0.937218406785384\n",
      "train loss:0.7910962576903289\n",
      "train loss:0.8685696555341437\n",
      "train loss:0.7529307022714248\n",
      "train loss:1.0147216094682066\n",
      "train loss:0.8680803746723688\n",
      "train loss:0.8459819461272245\n",
      "train loss:0.8782086923608513\n",
      "train loss:0.814554700079961\n",
      "train loss:0.8440143677175221\n",
      "train loss:0.7470749590437186\n",
      "train loss:0.8316004309370655\n",
      "train loss:0.9365943228645545\n",
      "train loss:0.8847548860532949\n",
      "train loss:0.8389594752715738\n",
      "train loss:0.8906606987203253\n",
      "train loss:0.794907340614063\n",
      "train loss:0.7502562676104045\n",
      "train loss:0.9302095420840965\n",
      "train loss:0.7222488249990184\n",
      "train loss:0.841031624342356\n",
      "train loss:0.8185460449786673\n",
      "train loss:0.9043050392980131\n",
      "train loss:0.8107922676112438\n",
      "train loss:0.8348547427341673\n",
      "train loss:0.8333861827973621\n",
      "train loss:0.804242712168981\n",
      "train loss:0.9096777581080925\n",
      "train loss:0.9014199387303096\n",
      "train loss:0.9070670875255488\n",
      "train loss:0.7233242509228266\n",
      "train loss:0.8672519234765825\n",
      "train loss:0.9466040070046176\n",
      "train loss:0.9296858135226092\n",
      "train loss:0.8972358283363444\n",
      "train loss:0.7929004938229308\n",
      "train loss:1.0209720056096951\n",
      "train loss:0.9256553798652627\n",
      "train loss:0.9506758108705051\n",
      "train loss:0.9583310508499041\n",
      "train loss:0.9017431753782459\n",
      "train loss:0.9625884368087256\n",
      "train loss:0.8802924081022643\n",
      "train loss:0.8608606485711754\n",
      "train loss:0.8295754233504131\n",
      "train loss:0.9063817200677947\n",
      "train loss:0.8386267413116038\n",
      "train loss:0.7297539759791768\n",
      "train loss:0.8938420310723459\n",
      "train loss:0.8422387926449776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.7878317634154967\n",
      "train loss:0.8575655926864182\n",
      "train loss:0.8711347598821859\n",
      "train loss:0.7782146403153449\n",
      "train loss:0.9068590747692944\n",
      "train loss:0.8668133108988968\n",
      "train loss:1.0111118281610265\n",
      "train loss:0.8269858525175424\n",
      "train loss:0.8273846858527593\n",
      "train loss:0.6226231556308298\n",
      "train loss:0.8075768453617589\n",
      "train loss:0.7866866879995835\n",
      "train loss:0.9332175926940809\n",
      "train loss:0.7895667984712191\n",
      "train loss:0.840388334951411\n",
      "train loss:1.0288971510232023\n",
      "train loss:0.8406335730946646\n",
      "train loss:0.922921664185143\n",
      "train loss:0.782161599954496\n",
      "train loss:0.8003473887651823\n",
      "train loss:0.9041638579308026\n",
      "train loss:0.7079539440260748\n",
      "train loss:0.7989647988121181\n",
      "train loss:0.8447081282505944\n",
      "train loss:0.8525587955111983\n",
      "train loss:0.9177424263661572\n",
      "train loss:0.9383617555520926\n",
      "train loss:0.9069883477867587\n",
      "train loss:0.9479230432393831\n",
      "train loss:0.7512995098827124\n",
      "train loss:0.8807552620716744\n",
      "train loss:0.863001156220169\n",
      "train loss:1.0453237573248544\n",
      "train loss:0.9686041220440791\n",
      "train loss:0.795076656062663\n",
      "train loss:0.986885980496369\n",
      "train loss:0.9516457339177568\n",
      "train loss:0.9381411722577434\n",
      "train loss:0.9609190982124344\n",
      "train loss:0.7935726676904884\n",
      "train loss:0.9442117114834875\n",
      "train loss:0.8659906689068271\n",
      "train loss:0.8627951649232578\n",
      "train loss:0.8207525964397449\n",
      "train loss:0.8396107643760449\n",
      "train loss:0.8885631424994332\n",
      "train loss:0.7887870080427619\n",
      "train loss:0.6874850210472917\n",
      "train loss:0.8227604831092328\n",
      "train loss:0.8188374076862308\n",
      "train loss:0.8527640705177985\n",
      "train loss:0.9436623003541613\n",
      "train loss:0.8729459057445872\n",
      "train loss:0.9437097087052537\n",
      "train loss:0.7769466538146139\n",
      "train loss:0.8250638417354712\n",
      "train loss:0.9943054998265982\n",
      "train loss:0.8409804997405596\n",
      "train loss:0.8940498273253543\n",
      "train loss:0.8439672841918856\n",
      "train loss:0.7308222874761825\n",
      "train loss:0.8867455323241722\n",
      "train loss:0.8727555817653645\n",
      "train loss:0.9908279542507927\n",
      "train loss:0.9351392039636645\n",
      "train loss:0.9145769579213904\n",
      "train loss:0.9173519798841354\n",
      "train loss:0.8210450392038154\n",
      "train loss:0.9780035610361136\n",
      "train loss:0.9893201810492558\n",
      "train loss:0.8156152773241299\n",
      "train loss:0.9115546130822375\n",
      "train loss:0.8515288632461285\n",
      "train loss:0.8789591528455248\n",
      "train loss:0.9245493783158197\n",
      "train loss:0.7771669982833623\n",
      "train loss:0.9005528759041839\n",
      "train loss:0.7953728920152727\n",
      "train loss:0.8051454931188823\n",
      "train loss:0.9056084640108548\n",
      "train loss:1.0211828729603598\n",
      "train loss:0.9314938575127651\n",
      "train loss:0.897699189635022\n",
      "train loss:0.8049490764662628\n",
      "train loss:0.9046066294348472\n",
      "train loss:0.7015093612475947\n",
      "train loss:0.9259793931586602\n",
      "train loss:0.8451608717321416\n",
      "train loss:0.7360468777956776\n",
      "train loss:0.9702476348301464\n",
      "train loss:0.8561642519935853\n",
      "train loss:0.8678187560651098\n",
      "train loss:1.0250775090153308\n",
      "train loss:1.0138305388388071\n",
      "train loss:0.9309581400059715\n",
      "train loss:0.7570172640182936\n",
      "train loss:1.0097729080396372\n",
      "train loss:0.9607314475189433\n",
      "train loss:0.8268169515040634\n",
      "train loss:0.7033984531261538\n",
      "train loss:0.9583304489980965\n",
      "train loss:0.9290485194113407\n",
      "train loss:0.9444769665124555\n",
      "train loss:0.8455913338528314\n",
      "train loss:0.9196198360170638\n",
      "train loss:0.9049482182605657\n",
      "train loss:0.9937718730802861\n",
      "train loss:1.0369526148070758\n",
      "train loss:0.8618307330712769\n",
      "train loss:0.9182757289888314\n",
      "train loss:0.9336929472892274\n",
      "train loss:0.7985437092134027\n",
      "train loss:0.9953206261032183\n",
      "train loss:0.7999993336820684\n",
      "train loss:0.8578367923820766\n",
      "train loss:0.7984087493065072\n",
      "train loss:0.9629585340104935\n",
      "train loss:1.1425634377672769\n",
      "train loss:0.9661224166257603\n",
      "train loss:0.9126539108670427\n",
      "train loss:0.8331366226306733\n",
      "train loss:0.7170707296449712\n",
      "train loss:0.9249182925659308\n",
      "train loss:0.832423380991803\n",
      "train loss:0.7317515104272269\n",
      "train loss:0.8765968942582378\n",
      "train loss:0.7395207033677152\n",
      "train loss:0.9027977072466572\n",
      "train loss:0.8247206993568686\n",
      "train loss:0.8446799432329439\n",
      "train loss:0.7814396326200793\n",
      "train loss:0.8558018994697228\n",
      "train loss:0.9954208020444554\n",
      "train loss:0.7049200411394843\n",
      "train loss:0.9686041095070606\n",
      "train loss:0.8839604874578562\n",
      "train loss:0.9500110804739426\n",
      "train loss:1.039287203740017\n",
      "train loss:0.8140290610383769\n",
      "train loss:0.8551207063348845\n",
      "train loss:0.845973539660407\n",
      "train loss:0.7707482604142052\n",
      "train loss:1.0005756271820099\n",
      "train loss:0.8871376533296729\n",
      "train loss:0.7669821640236805\n",
      "train loss:0.819242128622439\n",
      "train loss:1.0020073834317398\n",
      "train loss:0.7852932626201102\n",
      "train loss:1.014649254218082\n",
      "train loss:0.7931393485674922\n",
      "train loss:0.7747134770937616\n",
      "train loss:0.9137705918185991\n",
      "train loss:0.7117861613545874\n",
      "train loss:0.8595868560187013\n",
      "train loss:0.9144762721887776\n",
      "train loss:0.9345824910891186\n",
      "train loss:1.054451447682835\n",
      "train loss:0.8455612670302783\n",
      "train loss:0.7120362273221142\n",
      "train loss:0.8743018358849152\n",
      "train loss:0.8691637039410793\n",
      "train loss:0.736954494371838\n",
      "train loss:0.7894702520929071\n",
      "train loss:0.8388467622948003\n",
      "train loss:0.9078340777757429\n",
      "train loss:0.7205514097588379\n",
      "train loss:0.8704518633951597\n",
      "train loss:0.9356781570486339\n",
      "train loss:0.9587688194557034\n",
      "train loss:0.9182142518953039\n",
      "train loss:0.8560854116346931\n",
      "train loss:0.9434106732253479\n",
      "train loss:0.6977727724382905\n",
      "train loss:0.9784463877340785\n",
      "train loss:0.849461665940251\n",
      "train loss:0.9290957471481675\n",
      "train loss:0.8785725743495187\n",
      "train loss:0.7740296927810421\n",
      "train loss:0.8660097543816121\n",
      "train loss:0.8816344921391587\n",
      "train loss:0.9941627170246581\n",
      "train loss:0.8152766798089124\n",
      "train loss:1.010675637764534\n",
      "train loss:0.8536843592649562\n",
      "train loss:0.8859768908206226\n",
      "train loss:0.8303237811894172\n",
      "train loss:0.8699821331971387\n",
      "train loss:0.8031410146653328\n",
      "train loss:0.9610776747206913\n",
      "train loss:0.7558171275316391\n",
      "train loss:0.9364608489311665\n",
      "train loss:0.8060649038480362\n",
      "train loss:0.8106438172724195\n",
      "train loss:0.948341309960812\n",
      "train loss:1.037512995225677\n",
      "train loss:0.6691610288412833\n",
      "train loss:0.7996118083333735\n",
      "train loss:0.9550767206564569\n",
      "train loss:0.8840000287836063\n",
      "train loss:0.8978067840610094\n",
      "train loss:0.7279262901811693\n",
      "train loss:0.681059080788616\n",
      "train loss:0.9305732040285963\n",
      "train loss:1.0226938309638895\n",
      "train loss:0.8430306179416002\n",
      "train loss:0.8421628683826278\n",
      "train loss:0.8174663904774623\n",
      "train loss:1.0607004156088096\n",
      "train loss:0.7880186180414712\n",
      "train loss:0.76178810155825\n",
      "train loss:0.6331214524053671\n",
      "train loss:0.8470637994744967\n",
      "train loss:0.7243799074828036\n",
      "train loss:0.8421713903015096\n",
      "train loss:0.7780008357927808\n",
      "train loss:0.7211984504914513\n",
      "train loss:0.9508700898130175\n",
      "train loss:0.746436965834474\n",
      "train loss:0.9054495739784055\n",
      "train loss:0.8948915803859587\n",
      "train loss:0.9683754864856643\n",
      "train loss:0.8507413513207733\n",
      "train loss:0.9096609467882405\n",
      "train loss:0.9669185949245499\n",
      "train loss:0.7910214832148574\n",
      "train loss:1.0870820433363233\n",
      "train loss:0.8672808097069131\n",
      "train loss:1.0245884957717137\n",
      "train loss:0.8001466339620671\n",
      "train loss:0.8995109473379523\n",
      "train loss:0.8844561253209706\n",
      "train loss:0.8156535700406671\n",
      "train loss:0.7330244549118521\n",
      "train loss:0.8725117657955225\n",
      "train loss:0.8803734161192238\n",
      "train loss:0.7804763429306638\n",
      "train loss:0.7556040816585288\n",
      "train loss:0.6616312248069686\n",
      "train loss:0.7051515988614772\n",
      "train loss:0.8285823439010508\n",
      "train loss:1.0262986277987993\n",
      "train loss:0.8122353875042088\n",
      "train loss:0.7699885657630101\n",
      "train loss:0.9038096977808145\n",
      "train loss:0.8693746367743881\n",
      "train loss:0.8388009125031337\n",
      "train loss:0.8625165073145977\n",
      "train loss:0.8353750395886115\n",
      "train loss:0.835162230026611\n",
      "train loss:0.7483703028538862\n",
      "train loss:0.9432131824489081\n",
      "train loss:0.923190212227326\n",
      "train loss:0.9750334851735174\n",
      "train loss:0.8064322589032037\n",
      "train loss:0.8354023422232774\n",
      "train loss:0.9953491690107704\n",
      "train loss:0.9846087925495928\n",
      "train loss:0.9395732411496774\n",
      "train loss:0.787311269601852\n",
      "train loss:0.969761215727666\n",
      "train loss:0.7273860618862529\n",
      "train loss:0.8367582117755613\n",
      "train loss:0.8889619922047801\n",
      "train loss:0.970046675586137\n",
      "train loss:0.7757179028162737\n",
      "train loss:0.8362869711971953\n",
      "train loss:0.8633269165785366\n",
      "train loss:0.760869783223127\n",
      "train loss:0.8781021487346776\n",
      "train loss:0.8212774187991223\n",
      "train loss:0.8384136994829673\n",
      "train loss:0.7393001720705799\n",
      "train loss:0.8290592667287606\n",
      "train loss:0.7801206179711666\n",
      "train loss:0.8756968376091104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:1.030350787366428\n",
      "train loss:0.9092950274133571\n",
      "train loss:0.8971304827248378\n",
      "train loss:0.8050879839461512\n",
      "train loss:0.8187987382424619\n",
      "train loss:0.806680104271765\n",
      "train loss:0.9127257862659657\n",
      "train loss:0.8516483241473739\n",
      "train loss:0.8092966050811039\n",
      "train loss:0.7147082629568914\n",
      "train loss:0.7992943664686933\n",
      "train loss:0.9597442105713566\n",
      "train loss:0.7525962493131161\n",
      "train loss:0.8298624039017359\n",
      "train loss:0.7819752072127667\n",
      "train loss:0.8599857718131426\n",
      "train loss:0.8124419778810088\n",
      "train loss:0.9007320559745033\n",
      "train loss:0.7182270773961545\n",
      "train loss:0.8978437010548016\n",
      "train loss:0.7546423920933152\n",
      "train loss:0.78989871698175\n",
      "train loss:0.9774907584187514\n",
      "train loss:0.803384216841221\n",
      "train loss:0.9438192848842837\n",
      "train loss:0.9405804141266365\n",
      "train loss:0.8976609785467343\n",
      "train loss:0.7731527286425611\n",
      "train loss:0.8850393633886309\n",
      "train loss:0.8227438192666358\n",
      "train loss:0.9880355093078776\n",
      "train loss:0.8108930931474935\n",
      "train loss:0.8226923771264297\n",
      "train loss:0.6901234767252693\n",
      "train loss:0.7684575472024108\n",
      "train loss:0.8963294533673669\n",
      "train loss:0.8280932469225051\n",
      "train loss:0.8008175421125319\n",
      "train loss:0.8087130202962524\n",
      "train loss:0.7663909825969576\n",
      "train loss:0.8985091819319261\n",
      "train loss:0.9016682585810161\n",
      "train loss:0.721632264421059\n",
      "train loss:0.9143581739516128\n",
      "train loss:0.8588110209438409\n",
      "train loss:0.758071991658684\n",
      "train loss:0.8749604433977771\n",
      "train loss:0.8963888640395902\n",
      "train loss:1.0568699684898721\n",
      "train loss:0.9057420503258392\n",
      "train loss:0.9950296628439415\n",
      "train loss:0.8255258255194488\n",
      "train loss:0.7594643355978243\n",
      "train loss:0.705434725459854\n",
      "train loss:0.819102743487341\n",
      "train loss:0.8933759918202455\n",
      "train loss:0.8523588644016844\n",
      "train loss:0.8467472385904807\n",
      "train loss:0.8477855372433258\n",
      "train loss:0.8080824454490068\n",
      "train loss:0.8805165787648526\n",
      "train loss:0.8456719720778874\n",
      "train loss:0.8515524415258932\n",
      "train loss:0.8419603613320409\n",
      "train loss:0.7248423342347224\n",
      "train loss:0.8481182718478318\n",
      "train loss:0.8503424254235195\n",
      "train loss:0.9282270092265392\n",
      "train loss:0.8483381277749318\n",
      "train loss:0.8870107075537536\n",
      "train loss:0.8938780398429459\n",
      "train loss:0.9139257882869236\n",
      "train loss:0.7773672523075916\n",
      "train loss:0.9031082711738607\n",
      "train loss:0.9085959757278174\n",
      "train loss:0.7857287966054255\n",
      "train loss:0.8887645619894683\n",
      "train loss:0.7872249587710252\n",
      "train loss:0.8927909751368663\n",
      "train loss:0.7922146038011377\n",
      "train loss:0.94485655700842\n",
      "train loss:0.8741373085471288\n",
      "train loss:0.7845388290112143\n",
      "train loss:0.9134263308793754\n",
      "train loss:0.8440408613937278\n",
      "train loss:0.9690158286005137\n",
      "train loss:0.9423949831986006\n",
      "train loss:1.007859240048568\n",
      "train loss:0.8521827855466598\n",
      "train loss:0.7815014084610294\n",
      "train loss:0.9611543857834945\n",
      "train loss:0.7790129741098838\n",
      "train loss:0.892109364507416\n",
      "train loss:0.9844604585114116\n",
      "train loss:0.9372213588864072\n",
      "train loss:0.9147657904475701\n",
      "train loss:0.8022603548163992\n",
      "train loss:0.9834496748482574\n",
      "train loss:0.7399309987348412\n",
      "train loss:0.7835482405280269\n",
      "train loss:0.9584179029263972\n",
      "train loss:0.9029285469615667\n",
      "train loss:0.8625030288036665\n",
      "train loss:0.9347240228082012\n",
      "train loss:0.8726027068187874\n",
      "train loss:0.8824858884388358\n",
      "train loss:0.8530084283807834\n",
      "train loss:0.7760362395172519\n",
      "train loss:0.9292312266453219\n",
      "=== epoch:19, train acc:0.998, test acc:0.99 ===\n",
      "train loss:0.9723267625775178\n",
      "train loss:0.8293376649914285\n",
      "train loss:0.8722206398703869\n",
      "train loss:0.8561377331109051\n",
      "train loss:0.9024449868878501\n",
      "train loss:0.9115734224542901\n",
      "train loss:0.8981003595759433\n",
      "train loss:0.8174032996610356\n",
      "train loss:0.9295680626662453\n",
      "train loss:0.8268869384182521\n",
      "train loss:0.9013521834192195\n",
      "train loss:0.7883799379031767\n",
      "train loss:0.9083389774197684\n",
      "train loss:0.8671978259082462\n",
      "train loss:0.8384721618070146\n",
      "train loss:1.0010798858250514\n",
      "train loss:0.8956213843002945\n",
      "train loss:0.8699856950025224\n",
      "train loss:0.8446559331483168\n",
      "train loss:0.813222731733657\n",
      "train loss:0.8634779125598447\n",
      "train loss:0.8989933118056225\n",
      "train loss:0.8105699392674995\n",
      "train loss:0.8161202041282495\n",
      "train loss:0.9291809248584001\n",
      "train loss:0.9834774944963826\n",
      "train loss:0.8834989130598311\n",
      "train loss:0.8112220215528891\n",
      "train loss:0.9990911566534889\n",
      "train loss:0.969018033432681\n",
      "train loss:0.8047857560340151\n",
      "train loss:0.8535126500894309\n",
      "train loss:0.8703259995028363\n",
      "train loss:0.6978398831388047\n",
      "train loss:0.8677505256423603\n",
      "train loss:0.8995765742169946\n",
      "train loss:0.7748069322427941\n",
      "train loss:0.9141204781631329\n",
      "train loss:0.7941995608606232\n",
      "train loss:0.9334940060965374\n",
      "train loss:0.8408104404384789\n",
      "train loss:0.8137676760757354\n",
      "train loss:0.787557081413363\n",
      "train loss:0.8475298360452383\n",
      "train loss:0.9620360095180502\n",
      "train loss:0.865882160292395\n",
      "train loss:0.9063416645532741\n",
      "train loss:0.765031901184257\n",
      "train loss:0.6370928511361247\n",
      "train loss:0.774112021259112\n",
      "train loss:0.7580030788660683\n",
      "train loss:0.8141130992641927\n",
      "train loss:0.882547400635343\n",
      "train loss:0.782894024979672\n",
      "train loss:0.7538308638663105\n",
      "train loss:1.0663653507045052\n",
      "train loss:0.9138092942612087\n",
      "train loss:0.7720448104162958\n",
      "train loss:0.7715790636892282\n",
      "train loss:0.8475443621030055\n",
      "train loss:0.795810410207728\n",
      "train loss:0.919078787591317\n",
      "train loss:0.9050787964831265\n",
      "train loss:0.7827695547287528\n",
      "train loss:0.8292058793267016\n",
      "train loss:0.875161375485616\n",
      "train loss:0.876125636256666\n",
      "train loss:0.7544630568393831\n",
      "train loss:0.97834062669766\n",
      "train loss:0.8143258802575244\n",
      "train loss:0.9771995364428875\n",
      "train loss:0.8663931719635615\n",
      "train loss:0.9877923409673528\n",
      "train loss:0.98298270553724\n",
      "train loss:0.7583066361899047\n",
      "train loss:0.8911588234411292\n",
      "train loss:0.820567244059515\n",
      "train loss:1.041983129658064\n",
      "train loss:0.7650725837668781\n",
      "train loss:1.0363119473933036\n",
      "train loss:0.9650858408508138\n",
      "train loss:0.8417216366012076\n",
      "train loss:0.9364567533890535\n",
      "train loss:0.9855452053288575\n",
      "train loss:0.9538604680197325\n",
      "train loss:0.7571918113894935\n",
      "train loss:0.7870140770228367\n",
      "train loss:0.7601711444226856\n",
      "train loss:0.8338109796829865\n",
      "train loss:0.88517479170849\n",
      "train loss:0.8373680979702458\n",
      "train loss:0.803487481213028\n",
      "train loss:0.7740561566160293\n",
      "train loss:0.8257166460944583\n",
      "train loss:1.0311133988874677\n",
      "train loss:0.9082604581651349\n",
      "train loss:0.7982521963496693\n",
      "train loss:0.9617189170168611\n",
      "train loss:0.7497950686027042\n",
      "train loss:0.8405765996164107\n",
      "train loss:0.8871459655719791\n",
      "train loss:0.8511998990297341\n",
      "train loss:0.8369255233637068\n",
      "train loss:0.876285095440315\n",
      "train loss:0.9159472609881898\n",
      "train loss:0.7866823961239833\n",
      "train loss:0.856475544336963\n",
      "train loss:0.8259307710238504\n",
      "train loss:0.8723792674489801\n",
      "train loss:0.8782478960766075\n",
      "train loss:0.7442279517708758\n",
      "train loss:1.0545144387442287\n",
      "train loss:0.9097062629703468\n",
      "train loss:0.7969867305623732\n",
      "train loss:0.7514179363259648\n",
      "train loss:0.7393981485958215\n",
      "train loss:0.7024757805394026\n",
      "train loss:0.8329249696123964\n",
      "train loss:0.7557332858997046\n",
      "train loss:0.9214810060002737\n",
      "train loss:0.8176516951147224\n",
      "train loss:0.9220094457838871\n",
      "train loss:0.8618718736485943\n",
      "train loss:0.8703213965278189\n",
      "train loss:0.8653493943133144\n",
      "train loss:0.8406189028633898\n",
      "train loss:0.9125638397976259\n",
      "train loss:1.0549757175547305\n",
      "train loss:0.858646935781\n",
      "train loss:0.7723689763584909\n",
      "train loss:0.8549529500307093\n",
      "train loss:0.8937979855589729\n",
      "train loss:0.8505523293701868\n",
      "train loss:0.8047483290315145\n",
      "train loss:1.061041002641756\n",
      "train loss:0.8887675307883444\n",
      "train loss:0.911578917137187\n",
      "train loss:0.9222857825721239\n",
      "train loss:0.8653454719096838\n",
      "train loss:0.8450841590898314\n",
      "train loss:0.779619827772653\n",
      "train loss:0.723899616315034\n",
      "train loss:0.9853192054642684\n",
      "train loss:0.9725958223443514\n",
      "train loss:0.8500321815805012\n",
      "train loss:0.7651041699130359\n",
      "train loss:0.756600539691808\n",
      "train loss:0.9571349202090386\n",
      "train loss:0.8117133195095906\n",
      "train loss:0.716202018396745\n",
      "train loss:0.9423029029494013\n",
      "train loss:1.0864293306837431\n",
      "train loss:0.7725118415453115\n",
      "train loss:0.641496153488716\n",
      "train loss:0.7935681373030289\n",
      "train loss:0.8071105215996944\n",
      "train loss:0.8862669687701502\n",
      "train loss:0.755722675867218\n",
      "train loss:0.8804542864596379\n",
      "train loss:0.976150453295208\n",
      "train loss:0.7670092416480362\n",
      "train loss:0.6817428636051733\n",
      "train loss:0.88866497497274\n",
      "train loss:1.0945207823774634\n",
      "train loss:0.8626971361602669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.8490432286592831\n",
      "train loss:0.8390133016197067\n",
      "train loss:0.9195739833263239\n",
      "train loss:0.8285495776400296\n",
      "train loss:0.8730553387470111\n",
      "train loss:0.8287474545918105\n",
      "train loss:0.9240926811309111\n",
      "train loss:0.8229313639123343\n",
      "train loss:0.796858077015772\n",
      "train loss:0.8445440765177797\n",
      "train loss:0.8675656608365171\n",
      "train loss:0.7621912662954898\n",
      "train loss:0.8966886416275633\n",
      "train loss:0.8608342552758146\n",
      "train loss:0.894574618359378\n",
      "train loss:0.7684170717642929\n",
      "train loss:0.9862683448921935\n",
      "train loss:0.8871145807808531\n",
      "train loss:0.9052620681106113\n",
      "train loss:0.8098736930543118\n",
      "train loss:0.9685086535322398\n",
      "train loss:0.8670910759959566\n",
      "train loss:0.7843825985617673\n",
      "train loss:0.9496517649528653\n",
      "train loss:0.9478773467215382\n",
      "train loss:0.924808799062169\n",
      "train loss:0.7338301209512954\n",
      "train loss:0.9545796760494346\n",
      "train loss:0.7515620869968526\n",
      "train loss:0.7894633747379988\n",
      "train loss:0.7350160975646799\n",
      "train loss:0.9981026842705082\n",
      "train loss:0.8385033637560444\n",
      "train loss:0.7798703053329775\n",
      "train loss:0.8976162587669114\n",
      "train loss:0.8581043555144943\n",
      "train loss:0.8678932110721027\n",
      "train loss:0.9623548863349488\n",
      "train loss:0.866686197776142\n",
      "train loss:0.7469329432709424\n",
      "train loss:0.7791479811438039\n",
      "train loss:0.9937448581533491\n",
      "train loss:0.932743061645832\n",
      "train loss:0.8715490914150152\n",
      "train loss:0.6991472895589179\n",
      "train loss:0.8933677185184753\n",
      "train loss:1.0406701793723117\n",
      "train loss:0.8220552496946409\n",
      "train loss:0.7365159160264845\n",
      "train loss:0.7798114376556\n",
      "train loss:0.8146811027463197\n",
      "train loss:0.9252334198396167\n",
      "train loss:1.0190937014872552\n",
      "train loss:1.0151100052830742\n",
      "train loss:0.854729415416112\n",
      "train loss:0.7618516868216123\n",
      "train loss:0.8768041249546578\n",
      "train loss:0.8528872562878647\n",
      "train loss:0.8524681676619109\n",
      "train loss:0.863437025487831\n",
      "train loss:0.7367215280930007\n",
      "train loss:0.9738258076513193\n",
      "train loss:0.7857061540762517\n",
      "train loss:0.7548555720229807\n",
      "train loss:0.8199173871646522\n",
      "train loss:0.8807337422183766\n",
      "train loss:0.8389807743116917\n",
      "train loss:0.9902262835749751\n",
      "train loss:0.9231315564926567\n",
      "train loss:0.9213802919413525\n",
      "train loss:0.7364107224581927\n",
      "train loss:1.0243525215946645\n",
      "train loss:0.8263836970331897\n",
      "train loss:0.860798160744978\n",
      "train loss:1.0148673872012872\n",
      "train loss:0.7898749302425563\n",
      "train loss:0.7812693031312317\n",
      "train loss:0.8964891361452216\n",
      "train loss:0.7563499582471529\n",
      "train loss:0.7743048024555763\n",
      "train loss:0.8272992752643137\n",
      "train loss:0.8648330907565803\n",
      "train loss:0.672822231562489\n",
      "train loss:0.7514572486800395\n",
      "train loss:0.752071534591009\n",
      "train loss:0.8037486635139941\n",
      "train loss:0.8023402901833246\n",
      "train loss:0.753023895442933\n",
      "train loss:0.9813186325928186\n",
      "train loss:0.7908968355759207\n",
      "train loss:0.8155868374298042\n",
      "train loss:0.8216089177744305\n",
      "train loss:0.8029742716397489\n",
      "train loss:0.8439286426672504\n",
      "train loss:0.7314114739832369\n",
      "train loss:0.6775110752910456\n",
      "train loss:0.8632301954727296\n",
      "train loss:0.8197224202269893\n",
      "train loss:0.821166032370466\n",
      "train loss:0.8612951071327656\n",
      "train loss:0.8320854651843597\n",
      "train loss:0.9053822983986276\n",
      "train loss:0.9003355338893497\n",
      "train loss:0.7284299708249378\n",
      "train loss:0.7157108203190016\n",
      "train loss:0.9083927669015266\n",
      "train loss:0.7723796500213571\n",
      "train loss:0.80108840399802\n",
      "train loss:0.8351831136707345\n",
      "train loss:0.8079803541846948\n",
      "train loss:0.8544208378284128\n",
      "train loss:0.8754636753737063\n",
      "train loss:0.9407702678270566\n",
      "train loss:0.9217203872326531\n",
      "train loss:0.8678147396848356\n",
      "train loss:0.808181250656058\n",
      "train loss:0.7987359786368871\n",
      "train loss:0.8336479857856425\n",
      "train loss:0.950046626569661\n",
      "train loss:0.686090615749119\n",
      "train loss:0.7599905685843394\n",
      "train loss:0.7798095912023939\n",
      "train loss:0.7979620237064453\n",
      "train loss:0.8481477363728608\n",
      "train loss:0.9244046885860854\n",
      "train loss:0.8141281607768945\n",
      "train loss:0.9897501664995246\n",
      "train loss:0.846657983891627\n",
      "train loss:0.8846397103270262\n",
      "train loss:0.8922484440997099\n",
      "train loss:0.8128434922350161\n",
      "train loss:0.7443049155914891\n",
      "train loss:0.96974418771919\n",
      "train loss:0.8890921177748352\n",
      "train loss:0.7583649178804862\n",
      "train loss:0.8641319474490982\n",
      "train loss:0.997646323381642\n",
      "train loss:0.7253026943939053\n",
      "train loss:0.9836965832270856\n",
      "train loss:0.8434303423721775\n",
      "train loss:0.9077118545791023\n",
      "train loss:1.0400850620078892\n",
      "train loss:0.743004209857084\n",
      "train loss:0.8666212350653483\n",
      "train loss:0.7388662355394312\n",
      "train loss:0.9550120023009747\n",
      "train loss:0.8968132558073268\n",
      "train loss:0.8439972820508812\n",
      "train loss:0.9715999755424022\n",
      "train loss:0.855353051494435\n",
      "train loss:1.0088341388394548\n",
      "train loss:0.8774729066338672\n",
      "train loss:0.8502932399826265\n",
      "train loss:1.002365193736322\n",
      "train loss:0.80547672365172\n",
      "train loss:0.8614322617104235\n",
      "train loss:1.0899370447155468\n",
      "train loss:0.7445435924673071\n",
      "train loss:0.9814346772126253\n",
      "train loss:0.9960508227040008\n",
      "train loss:0.7035030628442164\n",
      "train loss:0.7689260789640145\n",
      "train loss:0.7024063287206596\n",
      "train loss:0.7383686765771768\n",
      "train loss:1.0933456701988415\n",
      "train loss:0.8917725140722312\n",
      "train loss:0.8598932529088593\n",
      "train loss:0.9810279235533492\n",
      "train loss:0.8338234764698309\n",
      "train loss:0.7316817968498293\n",
      "train loss:0.7384120033077589\n",
      "train loss:0.7843045676267498\n",
      "train loss:0.7964835399468465\n",
      "train loss:0.8086874637615787\n",
      "train loss:0.815877850151225\n",
      "train loss:0.7985459584507235\n",
      "train loss:0.971868283213733\n",
      "train loss:1.0110307528135936\n",
      "train loss:0.8688175149037414\n",
      "train loss:0.9911079090705929\n",
      "train loss:0.7744140898196576\n",
      "train loss:0.8638177053934192\n",
      "train loss:0.9993230622976577\n",
      "train loss:0.8421766287785144\n",
      "train loss:0.8497634666053057\n",
      "train loss:0.7791543379371378\n",
      "train loss:0.7886731254774478\n",
      "train loss:0.9831262775774394\n",
      "train loss:0.8946256369236381\n",
      "train loss:0.9776054227656963\n",
      "train loss:0.6798490238185977\n",
      "train loss:0.7658899250326856\n",
      "train loss:0.8985648964198372\n",
      "train loss:0.8568274799720637\n",
      "train loss:0.8531261686689189\n",
      "train loss:0.8759191566263937\n",
      "train loss:0.9051838562829111\n",
      "train loss:0.9836047098178647\n",
      "train loss:0.7599313360727704\n",
      "train loss:0.7939351908314634\n",
      "train loss:1.0620668764877133\n",
      "train loss:0.723808630128073\n",
      "train loss:0.8127597714340165\n",
      "train loss:0.811795451337438\n",
      "train loss:0.7162468322662798\n",
      "train loss:1.0225457194638972\n",
      "train loss:0.9187500955735115\n",
      "train loss:0.9224473583771138\n",
      "train loss:0.9032932656368294\n",
      "train loss:0.6483180616952134\n",
      "train loss:0.9430970112641244\n",
      "train loss:0.843841103494411\n",
      "train loss:0.9120250893823464\n",
      "train loss:0.9520798360428187\n",
      "train loss:0.7932613192441115\n",
      "train loss:0.7907570340641951\n",
      "train loss:1.0053823892786504\n",
      "train loss:0.7917095442030603\n",
      "train loss:0.7915647098558967\n",
      "train loss:0.8651918043909042\n",
      "train loss:0.9545115921359993\n",
      "train loss:0.9194810859368628\n",
      "train loss:0.8951295215750598\n",
      "train loss:0.8327505885265741\n",
      "train loss:1.0665099388576715\n",
      "train loss:0.7553807102885511\n",
      "train loss:0.9878820022305157\n",
      "train loss:0.797312770933685\n",
      "train loss:0.9484339940302275\n",
      "train loss:0.9260138349363732\n",
      "train loss:0.8737448171788497\n",
      "train loss:0.8714597623887496\n",
      "train loss:0.8801914367794855\n",
      "train loss:0.8355470514640263\n",
      "train loss:0.8632908553272789\n",
      "train loss:0.8503453974124049\n",
      "train loss:0.9020466250885485\n",
      "train loss:0.861015590427288\n",
      "train loss:0.7912212150446972\n",
      "train loss:0.8716282341916392\n",
      "train loss:0.9478142998074377\n",
      "train loss:0.8968500619370973\n",
      "train loss:0.7582406868352612\n",
      "train loss:0.8532505522966215\n",
      "train loss:0.952706403808424\n",
      "train loss:0.7607402474811694\n",
      "train loss:0.7888392010747625\n",
      "train loss:0.9790062201501537\n",
      "train loss:0.9704341857495724\n",
      "train loss:0.8672345410499359\n",
      "train loss:0.8226044956583138\n",
      "train loss:0.8690193426062166\n",
      "train loss:0.7448465462418009\n",
      "train loss:0.8906699928899706\n",
      "train loss:0.8437176473479368\n",
      "train loss:0.9108357135753892\n",
      "train loss:0.7031595669444676\n",
      "train loss:0.7793478150916197\n",
      "train loss:0.7921520665475907\n",
      "train loss:0.8075190956786389\n",
      "train loss:0.823367550524853\n",
      "train loss:1.0556258179349547\n",
      "train loss:0.7931726443396926\n",
      "train loss:0.7826491935641533\n",
      "train loss:0.9659187517975263\n",
      "train loss:0.6948047516792615\n",
      "train loss:0.8913909662418402\n",
      "train loss:0.7893897352069146\n",
      "train loss:0.9177579320875666\n",
      "train loss:0.8870039390601377\n",
      "train loss:0.9002246217984933\n",
      "train loss:0.7174330038751604\n",
      "train loss:0.803454176595777\n",
      "train loss:0.9790132858970602\n",
      "train loss:0.9056461987541979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.7343530507456151\n",
      "train loss:0.7438764211643707\n",
      "train loss:0.8103334940094975\n",
      "train loss:0.9027338087972856\n",
      "train loss:0.7722716567218613\n",
      "train loss:0.7825203431409504\n",
      "train loss:0.9433812804547829\n",
      "train loss:0.728274570294059\n",
      "train loss:0.8792023357674811\n",
      "train loss:0.9328390125611805\n",
      "train loss:0.9766640536863097\n",
      "train loss:0.8089709769999054\n",
      "train loss:0.8315936475993481\n",
      "train loss:0.7288656252758955\n",
      "train loss:0.9626350548439616\n",
      "train loss:0.8434632134173491\n",
      "train loss:0.8245397226654455\n",
      "train loss:0.909548625851708\n",
      "train loss:0.8624327917337391\n",
      "train loss:0.6676488683187424\n",
      "train loss:0.9294323107292247\n",
      "train loss:0.7729560282809261\n",
      "train loss:0.7765368514660591\n",
      "train loss:0.8369727255806086\n",
      "train loss:0.8532874697348789\n",
      "train loss:0.6775490020932964\n",
      "train loss:0.9478444510293496\n",
      "train loss:0.8549939024311567\n",
      "train loss:0.7312659329595934\n",
      "train loss:0.7500292511266267\n",
      "train loss:0.879342570290204\n",
      "train loss:0.9625958117397382\n",
      "train loss:0.8693879931549712\n",
      "train loss:0.9423392996382637\n",
      "train loss:0.7213140249326593\n",
      "train loss:0.8558787186320888\n",
      "train loss:0.7996397346128604\n",
      "train loss:0.9062805717893524\n",
      "train loss:0.9290384297763427\n",
      "train loss:0.9880565946720172\n",
      "train loss:0.9376759779110881\n",
      "train loss:0.9534021477825153\n",
      "train loss:0.8937799457931852\n",
      "train loss:1.0332430197471363\n",
      "train loss:0.8852893600831311\n",
      "train loss:0.790127178129961\n",
      "train loss:0.9402912281894507\n",
      "train loss:0.7695852281420328\n",
      "train loss:1.0151711232941267\n",
      "train loss:0.6958983120805528\n",
      "train loss:0.8049469506837436\n",
      "train loss:0.6437059824292035\n",
      "train loss:0.9889645094136857\n",
      "train loss:0.9399179093624821\n",
      "train loss:0.880877595837213\n",
      "train loss:0.7948251590880606\n",
      "train loss:0.7702188576854487\n",
      "train loss:0.835844152394388\n",
      "train loss:1.058032203065533\n",
      "train loss:0.8182165179446299\n",
      "train loss:1.0379057159273462\n",
      "train loss:0.7338735148800271\n",
      "train loss:0.8754976417746556\n",
      "train loss:0.7965742488601079\n",
      "train loss:0.8025744010101289\n",
      "train loss:0.789535148741873\n",
      "train loss:0.8704975827575805\n",
      "train loss:0.9298683953542338\n",
      "train loss:0.8467882678616719\n",
      "train loss:1.027117265374391\n",
      "train loss:0.8953287624273584\n",
      "train loss:0.8775361189290568\n",
      "train loss:0.8221556484228043\n",
      "train loss:0.8573407109477619\n",
      "train loss:0.9025416789040218\n",
      "train loss:0.995530083080058\n",
      "train loss:0.7696996292555491\n",
      "train loss:0.7168271216696194\n",
      "train loss:0.8215857470733094\n",
      "train loss:0.9079890098585207\n",
      "train loss:0.7444510770374443\n",
      "train loss:0.7488299979693642\n",
      "train loss:0.9579893241924878\n",
      "train loss:0.864631945197422\n",
      "train loss:0.9271912071834314\n",
      "train loss:0.8143131958516419\n",
      "train loss:0.9386099732784767\n",
      "train loss:1.0207653641219787\n",
      "train loss:0.9478893970093328\n",
      "train loss:0.6727858148688125\n",
      "train loss:0.9035499037407164\n",
      "train loss:0.9325998709002541\n",
      "train loss:0.9226502433050453\n",
      "train loss:0.7900121872223714\n",
      "train loss:0.7944092959071212\n",
      "train loss:0.8052054856265185\n",
      "train loss:0.7568809236362349\n",
      "train loss:0.8432984999011395\n",
      "train loss:0.8074662154647152\n",
      "train loss:0.810365470677918\n",
      "train loss:0.9177501332525029\n",
      "train loss:0.8130892811847648\n",
      "train loss:1.093484478959063\n",
      "train loss:0.8455255163272155\n",
      "train loss:0.702577374901098\n",
      "train loss:0.7389697569817532\n",
      "train loss:0.8890737130072215\n",
      "train loss:0.7091084297794982\n",
      "train loss:0.8953592015747115\n",
      "train loss:0.8783954148047283\n",
      "train loss:0.809721798715665\n",
      "train loss:0.8518020829005816\n",
      "train loss:0.805658837184026\n",
      "train loss:0.9077247009924879\n",
      "train loss:0.9510978844757283\n",
      "train loss:0.9212419153414204\n",
      "train loss:1.121438645169019\n",
      "train loss:0.7549904826081643\n",
      "train loss:0.8991820864489241\n",
      "train loss:0.7626235901949083\n",
      "train loss:0.98893796305263\n",
      "train loss:0.7781749747220758\n",
      "train loss:0.9486900723195555\n",
      "train loss:0.8630438220997877\n",
      "train loss:0.9007854460424514\n",
      "train loss:0.8535983834289823\n",
      "train loss:0.7801559719574017\n",
      "train loss:0.8637838393212897\n",
      "train loss:0.8290292992865608\n",
      "train loss:0.7749932616869528\n",
      "train loss:0.8875070231183737\n",
      "train loss:0.7561101757701846\n",
      "train loss:0.8767629785004274\n",
      "train loss:1.0491628775567292\n",
      "train loss:0.8491727086131204\n",
      "train loss:0.7641298481558038\n",
      "train loss:0.8267711621091175\n",
      "train loss:0.7805999791148339\n",
      "train loss:0.8700860089201824\n",
      "train loss:0.8291516778001476\n",
      "train loss:0.8599709258695261\n",
      "train loss:0.9683183385327422\n",
      "train loss:0.9371579501112539\n",
      "train loss:0.834135226485595\n",
      "train loss:0.8791592635617147\n",
      "train loss:0.9038323524895554\n",
      "train loss:0.9486484710666222\n",
      "train loss:0.7981521788411722\n",
      "train loss:0.7948543761065332\n",
      "train loss:0.8207739666362761\n",
      "train loss:0.8419875598891963\n",
      "train loss:0.8686857459063948\n",
      "train loss:0.7278569568871852\n",
      "train loss:0.9704866005579142\n",
      "train loss:0.9593319172921647\n",
      "train loss:0.8886467315245956\n",
      "train loss:0.8898552989699503\n",
      "train loss:0.8743019365582192\n",
      "train loss:0.8828897495011533\n",
      "train loss:0.9203111527802972\n",
      "=== epoch:20, train acc:0.999, test acc:0.991 ===\n",
      "train loss:0.8117280936881002\n",
      "train loss:0.8703653745575004\n",
      "train loss:0.9230069427864532\n",
      "train loss:0.8917178742326035\n",
      "train loss:0.7665443292652651\n",
      "train loss:0.847003117535271\n",
      "train loss:0.8648338586982197\n",
      "train loss:0.9161051578455977\n",
      "train loss:0.9813904406641036\n",
      "train loss:0.8986090929903946\n",
      "train loss:0.8788276553953057\n",
      "train loss:0.8849893175054069\n",
      "train loss:1.05680453682836\n",
      "train loss:1.0167300170055378\n",
      "train loss:0.8435254390849068\n",
      "train loss:0.7952383457044049\n",
      "train loss:0.757446646867275\n",
      "train loss:0.89182066934617\n",
      "train loss:0.7575297870468545\n",
      "train loss:0.8223354214515176\n",
      "train loss:0.9977002176347195\n",
      "train loss:0.9300366585426726\n",
      "train loss:0.8625061529223848\n",
      "train loss:0.8666461891456748\n",
      "train loss:0.7684214797281705\n",
      "train loss:0.8249362706260925\n",
      "train loss:0.6895361449221827\n",
      "train loss:0.8766097701435897\n",
      "train loss:0.9243670810634668\n",
      "train loss:1.0163205995123064\n",
      "train loss:0.7041054286860257\n",
      "train loss:1.0167424987990765\n",
      "train loss:0.7926513151619909\n",
      "train loss:0.8655153530970826\n",
      "train loss:0.8434610343256108\n",
      "train loss:0.9760003350151465\n",
      "train loss:0.8275839799663526\n",
      "train loss:0.8208086110676972\n",
      "train loss:0.9143885065285923\n",
      "train loss:0.6669181170033925\n",
      "train loss:0.8766383131568509\n",
      "train loss:0.9554016529795032\n",
      "train loss:1.0736602276291924\n",
      "train loss:0.9597712850433756\n",
      "train loss:0.8900533328339394\n",
      "train loss:1.098392123867818\n",
      "train loss:0.924220478053189\n",
      "train loss:0.8282317438613573\n",
      "train loss:0.8740313393140192\n",
      "train loss:0.8867517056122887\n",
      "train loss:0.9702070546684061\n",
      "train loss:0.9540888039435589\n",
      "train loss:0.7375378606694548\n",
      "train loss:0.8828032938444993\n",
      "train loss:0.9381395731362043\n",
      "train loss:0.8421295335273378\n",
      "train loss:0.7364666947961414\n",
      "train loss:0.745052468753688\n",
      "train loss:0.8004862446738106\n",
      "train loss:0.7569810698776963\n",
      "train loss:0.8204235341435517\n",
      "train loss:0.8299843038970414\n",
      "train loss:1.0224587839369386\n",
      "train loss:0.6914798048518324\n",
      "train loss:0.7355574861993149\n",
      "train loss:0.8986249269540753\n",
      "train loss:0.8244020213887161\n",
      "train loss:0.89738558943426\n",
      "train loss:1.0408881107506707\n",
      "train loss:0.8491452458841111\n",
      "train loss:0.9092582187340692\n",
      "train loss:0.8992518667284493\n",
      "train loss:0.7738626136962106\n",
      "train loss:0.6905367754068465\n",
      "train loss:0.7549142042573007\n",
      "train loss:0.8066018293341518\n",
      "train loss:0.7213932450324835\n",
      "train loss:0.8809897964135169\n",
      "train loss:0.8048419267487703\n",
      "train loss:0.9238706032446035\n",
      "train loss:0.8083856932163862\n",
      "train loss:1.0296305507268406\n",
      "train loss:0.9104180485136588\n",
      "train loss:0.9266331739742345\n",
      "train loss:0.904724935096647\n",
      "train loss:0.7879598781821252\n",
      "train loss:0.8773188034678807\n",
      "train loss:0.8090657214995207\n",
      "train loss:0.8844437800189785\n",
      "train loss:0.9445014430838231\n",
      "train loss:1.0056921671987873\n",
      "train loss:0.7555940455052769\n",
      "train loss:0.9027633687539083\n",
      "train loss:0.9648370986953886\n",
      "train loss:1.042433815366105\n",
      "train loss:0.9152672157114635\n",
      "train loss:0.8345948951420634\n",
      "train loss:0.7634265470442512\n",
      "train loss:0.949817502134229\n",
      "train loss:0.7583197056191929\n",
      "train loss:0.8615193135313732\n",
      "train loss:0.767035954305162\n",
      "train loss:0.9268473136369474\n",
      "train loss:0.84579925896344\n",
      "train loss:0.9254137155936\n",
      "train loss:0.9346398962731831\n",
      "train loss:1.0553282373166142\n",
      "train loss:0.9128697935469277\n",
      "train loss:0.8441362309122661\n",
      "train loss:0.7798463761483138\n",
      "train loss:0.9275992575012896\n",
      "train loss:0.7209602778459275\n",
      "train loss:0.8213429240524316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.7995331329659214\n",
      "train loss:0.7852145828618114\n",
      "train loss:0.8717196630274587\n",
      "train loss:0.8822427065738389\n",
      "train loss:0.7904723443549916\n",
      "train loss:0.9299612171863871\n",
      "train loss:0.9225658462045413\n",
      "train loss:0.888982387439504\n",
      "train loss:0.9299497676596701\n",
      "train loss:0.8863924309291555\n",
      "train loss:0.9047120411221262\n",
      "train loss:0.7882364553824681\n",
      "train loss:0.8932884454849135\n",
      "train loss:0.8597696919388318\n",
      "train loss:0.8609784827170169\n",
      "train loss:0.9777713372822767\n",
      "train loss:0.8001550590639913\n",
      "train loss:0.7606826238508959\n",
      "train loss:0.7962538566542946\n",
      "train loss:0.7033482669680078\n",
      "train loss:0.9107885141389248\n",
      "train loss:0.7485777538635334\n",
      "train loss:0.8547059919269933\n",
      "train loss:0.8931961333694656\n",
      "train loss:0.7609851811325916\n",
      "train loss:0.9853107785658266\n",
      "train loss:0.9302890126127322\n",
      "train loss:0.9159335227443577\n",
      "train loss:0.7998432110630028\n",
      "train loss:0.9783915981520902\n",
      "train loss:0.7910019557020402\n",
      "train loss:0.883995891149625\n",
      "train loss:0.8591242904280295\n",
      "train loss:1.095233564637138\n",
      "train loss:1.0101398066508258\n",
      "train loss:1.0044129325555857\n",
      "train loss:0.866278773245071\n",
      "train loss:0.8591619980968304\n",
      "train loss:0.7852516389336954\n",
      "train loss:0.9451211582400822\n",
      "train loss:0.8471213366138667\n",
      "train loss:0.8928773777079094\n",
      "train loss:1.0183597271019171\n",
      "train loss:0.8867366710768865\n",
      "train loss:0.8779651506968476\n",
      "train loss:0.8573476744468299\n",
      "train loss:0.8418762104663948\n",
      "train loss:0.8505081173370037\n",
      "train loss:0.8712060714779573\n",
      "train loss:0.7492701882239204\n",
      "train loss:0.7703172762859478\n",
      "train loss:0.7590844987996909\n",
      "train loss:0.9835649772120822\n",
      "train loss:0.9004247610454774\n",
      "train loss:0.7882676772577889\n",
      "train loss:0.924040290896057\n",
      "train loss:0.7401779801255768\n",
      "train loss:0.7646878625576147\n",
      "train loss:0.782905297382717\n",
      "train loss:0.7838575479242408\n",
      "train loss:0.8069276923202824\n",
      "train loss:0.9400406106698577\n",
      "train loss:0.8169132965187795\n",
      "train loss:0.8484166850535638\n",
      "train loss:0.8155887205581439\n",
      "train loss:0.8059389377399911\n",
      "train loss:0.715572444687774\n",
      "train loss:0.7350608548395587\n",
      "train loss:0.7415327996708366\n",
      "train loss:0.7820686713067044\n",
      "train loss:0.7948052597053197\n",
      "train loss:0.7556436606851332\n",
      "train loss:0.8151762117614034\n",
      "train loss:0.9826003541187366\n",
      "train loss:0.9519386824895076\n",
      "train loss:0.8228062636602139\n",
      "train loss:0.9428975205231928\n",
      "train loss:0.8627589964552363\n",
      "train loss:0.8871410452842234\n",
      "train loss:0.7254264298648977\n",
      "train loss:0.9133584672889653\n",
      "train loss:0.9448291332026124\n",
      "train loss:0.843871959961153\n",
      "train loss:0.7147458775914107\n",
      "train loss:0.9611782044882795\n",
      "train loss:0.851595211829717\n",
      "train loss:0.8699367342958516\n",
      "train loss:0.75316993716805\n",
      "train loss:0.8525923218231216\n",
      "train loss:0.7498699111182328\n",
      "train loss:0.8087100650902321\n",
      "train loss:0.8808156663520283\n",
      "train loss:0.8016434682040626\n",
      "train loss:0.803176021534404\n",
      "train loss:0.8731695521980645\n",
      "train loss:0.8203208050663432\n",
      "train loss:0.7484740556847552\n",
      "train loss:0.807206716598076\n",
      "train loss:1.0881558752100804\n",
      "train loss:0.9767574877901842\n",
      "train loss:0.7999797704235894\n",
      "train loss:0.8937566053995124\n",
      "train loss:0.9311704204792534\n",
      "train loss:0.8940925921765163\n",
      "train loss:0.8644775344135498\n",
      "train loss:0.8929503559350455\n",
      "train loss:0.965791431483477\n",
      "train loss:0.9481305663373337\n",
      "train loss:0.9900549674231711\n",
      "train loss:0.7960418624456825\n",
      "train loss:0.7854699592898694\n",
      "train loss:0.8064029277466206\n",
      "train loss:0.8595338276533002\n",
      "train loss:0.8652876460558471\n",
      "train loss:0.8755375622068376\n",
      "train loss:1.0288112315909574\n",
      "train loss:1.0479423709808797\n",
      "train loss:0.9543974665770097\n",
      "train loss:0.8077768892177588\n",
      "train loss:0.9121370748820911\n",
      "train loss:0.7895214208628193\n",
      "train loss:0.8919511146663389\n",
      "train loss:0.8774773421674488\n",
      "train loss:0.8453031229029294\n",
      "train loss:0.8116048432749491\n",
      "train loss:0.9064453648421182\n",
      "train loss:0.7991971952405271\n",
      "train loss:0.8821193505671726\n",
      "train loss:0.8399436047363951\n",
      "train loss:0.7810602762532423\n",
      "train loss:0.8303973640932321\n",
      "train loss:0.7839083308592113\n",
      "train loss:0.6566063717425215\n",
      "train loss:0.8032114689283059\n",
      "train loss:0.7617923849062948\n",
      "train loss:0.9590987540839911\n",
      "train loss:0.8181631556266553\n",
      "train loss:0.9086182074653731\n",
      "train loss:0.8056701281499783\n",
      "train loss:0.7993619485535287\n",
      "train loss:0.8667420425948008\n",
      "train loss:0.8860872748345678\n",
      "train loss:0.990814932256259\n",
      "train loss:0.7796694211525761\n",
      "train loss:0.895827202943714\n",
      "train loss:0.7968136224150004\n",
      "train loss:0.8562779657119595\n",
      "train loss:1.0135512335663153\n",
      "train loss:0.9789396737367548\n",
      "train loss:0.9181024359435449\n",
      "train loss:0.7744186485785799\n",
      "train loss:0.7815239248115594\n",
      "train loss:0.9451900674606064\n",
      "train loss:0.8943025488126524\n",
      "train loss:0.9827563279370249\n",
      "train loss:0.879352921567115\n",
      "train loss:0.9020933615352746\n",
      "train loss:0.8235517326421735\n",
      "train loss:0.9376396832861086\n",
      "train loss:0.7845251973276653\n",
      "train loss:0.8496408261685522\n",
      "train loss:0.8025354954069343\n",
      "train loss:1.0249582730406315\n",
      "train loss:0.7986440235552815\n",
      "train loss:0.921903553278086\n",
      "train loss:0.7312490741026911\n",
      "train loss:0.8549366026142026\n",
      "train loss:0.7401267825642267\n",
      "train loss:0.9429127234103097\n",
      "train loss:0.9433368972351343\n",
      "train loss:0.7358793099160255\n",
      "train loss:0.8770324259339164\n",
      "train loss:0.8794882240688476\n",
      "train loss:0.906297230178134\n",
      "train loss:0.7593134197658123\n",
      "train loss:0.853407808011577\n",
      "train loss:0.7801077442549567\n",
      "train loss:0.925865665889695\n",
      "train loss:0.839284690790283\n",
      "train loss:0.7026837386830226\n",
      "train loss:0.881055453410942\n",
      "train loss:0.8795769486950902\n",
      "train loss:0.8522217139062525\n",
      "train loss:0.9404017256895671\n",
      "train loss:0.727020268544445\n",
      "train loss:0.8584470727828013\n",
      "train loss:0.9892676840781536\n",
      "train loss:0.8877786318583489\n",
      "train loss:0.7848443435449366\n",
      "train loss:0.8454882387196466\n",
      "train loss:0.8168089585270185\n",
      "train loss:0.6969827264022925\n",
      "train loss:1.0539528856849298\n",
      "train loss:0.7521300875943439\n",
      "train loss:0.8372125864203533\n",
      "train loss:0.7478191047023374\n",
      "train loss:0.8197319660485844\n",
      "train loss:0.8194291686853029\n",
      "train loss:0.9309086238515861\n",
      "train loss:0.8446041516737803\n",
      "train loss:0.8472991816500535\n",
      "train loss:0.9724452059208468\n",
      "train loss:0.8639361896264037\n",
      "train loss:0.9282370345756646\n",
      "train loss:0.7287539592844428\n",
      "train loss:0.8613449949330153\n",
      "train loss:0.8799187420453642\n",
      "train loss:0.8579280565116107\n",
      "train loss:0.7973102522413366\n",
      "train loss:0.7845434236294142\n",
      "train loss:0.861811968213984\n",
      "train loss:0.9146797757626716\n",
      "train loss:0.7926580905025341\n",
      "train loss:0.803433783513561\n",
      "train loss:0.9026743784162994\n",
      "train loss:0.8645991782255733\n",
      "train loss:0.7192317717708887\n",
      "train loss:0.8337683781009977\n",
      "train loss:0.8943441031009743\n",
      "train loss:0.6882340788913232\n",
      "train loss:0.9977730298313741\n",
      "train loss:0.9407483285519629\n",
      "train loss:0.801105673875011\n",
      "train loss:0.8357723875312376\n",
      "train loss:0.9962732843564427\n",
      "train loss:0.9703570929179939\n",
      "train loss:0.949074650056551\n",
      "train loss:0.9029302733052138\n",
      "train loss:0.8310357127663085\n",
      "train loss:0.818997175883744\n",
      "train loss:0.9366659959416839\n",
      "train loss:0.8741399935843164\n",
      "train loss:0.9462856269974051\n",
      "train loss:0.786965418874462\n",
      "train loss:0.8832161947707821\n",
      "train loss:0.8224209516416349\n",
      "train loss:0.9284971339815796\n",
      "train loss:0.7999134107221062\n",
      "train loss:0.8271949385874977\n",
      "train loss:0.9598828432337121\n",
      "train loss:0.8286436745831323\n",
      "train loss:0.8241648186124799\n",
      "train loss:0.742204800114556\n",
      "train loss:0.7196979446859371\n",
      "train loss:0.698700673008195\n",
      "train loss:0.8661045157287969\n",
      "train loss:0.7006401154712578\n",
      "train loss:0.9596845904856817\n",
      "train loss:0.8033275916450932\n",
      "train loss:0.9809981638187242\n",
      "train loss:0.7476361201338555\n",
      "train loss:0.8743973635446369\n",
      "train loss:0.8388749286629787\n",
      "train loss:0.7701027137486577\n",
      "train loss:0.7907684761296347\n",
      "train loss:0.8162898491202703\n",
      "train loss:0.82768995912129\n",
      "train loss:0.7847455495338754\n",
      "train loss:0.8491193881371774\n",
      "train loss:0.875228290565488\n",
      "train loss:0.9475508412228807\n",
      "train loss:0.9028254053688782\n",
      "train loss:0.7762203438204311\n",
      "train loss:0.8562583832766758\n",
      "train loss:0.9339354623582653\n",
      "train loss:0.9590476201730033\n",
      "train loss:0.8648428079728848\n",
      "train loss:0.8824163290387159\n",
      "train loss:0.8275744860784958\n",
      "train loss:0.9658028853316419\n",
      "train loss:0.9016817432973023\n",
      "train loss:0.7572704569556484\n",
      "train loss:0.9976397902164728\n",
      "train loss:0.7932340062533885\n",
      "train loss:0.7942767141529182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.7697076682092314\n",
      "train loss:0.951856694312813\n",
      "train loss:1.003973135009129\n",
      "train loss:0.9169550675895927\n",
      "train loss:1.0821824669560802\n",
      "train loss:0.8508528646831667\n",
      "train loss:0.7335108473415292\n",
      "train loss:0.7574670117624805\n",
      "train loss:0.7533838645233542\n",
      "train loss:0.8727749490574503\n",
      "train loss:0.7688884228141979\n",
      "train loss:1.0639939268210785\n",
      "train loss:0.8475815173922561\n",
      "train loss:0.7403164730002594\n",
      "train loss:0.7746651427680407\n",
      "train loss:0.7579585739635405\n",
      "train loss:0.8269046571943548\n",
      "train loss:0.8344344091145175\n",
      "train loss:0.9289222878984323\n",
      "train loss:0.9623520789007387\n",
      "train loss:1.0507878149875658\n",
      "train loss:1.0444902960316507\n",
      "train loss:0.9025022437142854\n",
      "train loss:0.9357371872005723\n",
      "train loss:0.9538204310528701\n",
      "train loss:0.8136627654925406\n",
      "train loss:0.8164192061666503\n",
      "train loss:0.779908576726896\n",
      "train loss:0.8132055202684871\n",
      "train loss:1.019304537322837\n",
      "train loss:0.9058285445461169\n",
      "train loss:0.8490353569522598\n",
      "train loss:0.9573711960977745\n",
      "train loss:0.9152946021601623\n",
      "train loss:0.9691483459074759\n",
      "train loss:0.8168903679965978\n",
      "train loss:0.8961676541264479\n",
      "train loss:1.0349964983830653\n",
      "train loss:0.9079351923357634\n",
      "train loss:0.6692070143524264\n",
      "train loss:0.6902351325660591\n",
      "train loss:0.9933096012830964\n",
      "train loss:0.7175450293048109\n",
      "train loss:0.7921452510187121\n",
      "train loss:0.8371549908958172\n",
      "train loss:0.9131156583251012\n",
      "train loss:0.9036295184548895\n",
      "train loss:0.8529240235223824\n",
      "train loss:0.8371001745803666\n",
      "train loss:0.8218155569504634\n",
      "train loss:0.7563660832294694\n",
      "train loss:0.9435250481347611\n",
      "train loss:0.7402067152448731\n",
      "train loss:0.8629024065292384\n",
      "train loss:0.9427574017557372\n",
      "train loss:0.857211133369524\n",
      "train loss:0.9542924808147183\n",
      "train loss:0.8928720812720359\n",
      "train loss:0.8568713873589094\n",
      "train loss:1.019902878263938\n",
      "train loss:0.8101449183660406\n",
      "train loss:1.016576057447177\n",
      "train loss:0.9191439299654554\n",
      "train loss:0.7031078344337388\n",
      "train loss:0.8451141654958805\n",
      "train loss:0.8256637708871214\n",
      "train loss:0.872218626390993\n",
      "train loss:0.8444098760623118\n",
      "train loss:0.9135319724049963\n",
      "train loss:0.7574324699918527\n",
      "train loss:0.8140621318252756\n",
      "train loss:0.8669073518603975\n",
      "train loss:0.85484491205219\n",
      "train loss:0.8171025229836121\n",
      "train loss:0.9793452593478501\n",
      "train loss:0.8569922991219612\n",
      "train loss:0.9074523018183271\n",
      "train loss:0.8758192120797592\n",
      "train loss:1.0012757787463096\n",
      "train loss:0.8122972606685588\n",
      "train loss:0.8922564349094917\n",
      "train loss:0.7393637857802432\n",
      "train loss:0.9269749404852428\n",
      "train loss:0.6811150600109115\n",
      "train loss:0.6930025464813951\n",
      "train loss:0.8729620904007472\n",
      "train loss:0.7116080161269009\n",
      "train loss:0.7978558648440897\n",
      "train loss:0.8172832944604097\n",
      "train loss:0.8666807122574225\n",
      "train loss:0.8306096145165225\n",
      "train loss:0.9593279478501647\n",
      "train loss:0.8565161411304711\n",
      "train loss:0.9092238600350728\n",
      "train loss:0.8971721612824298\n",
      "train loss:0.935932883486409\n",
      "train loss:0.9759619829190223\n",
      "train loss:0.7521830683939686\n",
      "train loss:0.8010450457760296\n",
      "train loss:0.7649384524382579\n",
      "train loss:0.8912479199609343\n",
      "train loss:0.799315151922046\n",
      "train loss:0.8930103353396374\n",
      "train loss:0.9426309128848862\n",
      "train loss:0.7411676759352737\n",
      "train loss:0.8729161920659871\n",
      "train loss:0.9186451641989235\n",
      "train loss:0.8279244611887627\n",
      "train loss:0.9284087063805484\n",
      "train loss:0.8319666792908209\n",
      "train loss:0.8136577346901877\n",
      "train loss:0.8232632044512981\n",
      "train loss:0.8083012250244518\n",
      "train loss:0.8442152395015964\n",
      "train loss:0.9055352948237945\n",
      "train loss:0.7619957743222312\n",
      "train loss:0.9627388424024477\n",
      "train loss:0.7724526687605929\n",
      "train loss:0.9236209057367972\n",
      "train loss:0.9512431898223426\n",
      "train loss:0.9061649555849078\n",
      "train loss:0.8606440303566205\n",
      "train loss:0.7905362977453226\n",
      "train loss:0.9441948481457074\n",
      "train loss:0.8880157294340723\n",
      "train loss:0.7030499078904878\n",
      "train loss:0.8618821547797261\n",
      "train loss:0.9574180390993908\n",
      "train loss:0.8097842253817581\n",
      "train loss:0.8559858041632529\n",
      "train loss:0.8145557830306427\n",
      "train loss:0.800338372310692\n",
      "train loss:0.9027988882563229\n",
      "train loss:0.862855247509997\n",
      "train loss:0.7977799157468266\n",
      "train loss:0.8905877632185151\n",
      "train loss:0.8139755587622317\n",
      "train loss:0.8458131073782128\n",
      "train loss:0.9211335388979662\n",
      "train loss:0.7954154955661872\n",
      "train loss:0.7067541773542125\n",
      "train loss:0.761575177390094\n",
      "train loss:0.757678267981201\n",
      "train loss:0.7165756250068217\n",
      "train loss:1.016169744078046\n",
      "train loss:0.6956073004249973\n",
      "train loss:0.818846151352226\n",
      "train loss:0.80420210529361\n",
      "train loss:0.8142386266945372\n",
      "train loss:0.9516637180238418\n",
      "train loss:0.9530708442998939\n",
      "train loss:0.8532792106503051\n",
      "train loss:1.1323918590946378\n",
      "train loss:0.772277437970736\n",
      "train loss:0.7554736886864271\n",
      "train loss:0.7990864732034539\n",
      "train loss:0.8631616265758644\n",
      "train loss:0.8460464673643241\n",
      "train loss:0.9175259411648643\n",
      "train loss:0.7963305855249775\n",
      "train loss:0.7787061027881715\n",
      "train loss:0.8243597303918768\n",
      "train loss:0.9199538412092123\n",
      "train loss:0.6996868917996534\n",
      "train loss:0.7338611759200078\n",
      "train loss:0.7695217680074405\n",
      "train loss:0.7026569685633117\n",
      "train loss:0.8044622867804675\n",
      "train loss:0.924833614453703\n",
      "train loss:0.9371770455090292\n",
      "train loss:0.7920228036754893\n",
      "train loss:0.9788709591252733\n",
      "train loss:0.9375779430632659\n",
      "train loss:0.9324628207014559\n",
      "train loss:0.7673809715023822\n",
      "train loss:0.819487829494107\n",
      "train loss:0.8618611139912224\n",
      "train loss:0.9090986875027783\n",
      "train loss:0.789302983155058\n",
      "train loss:0.8866367650290233\n",
      "train loss:0.8386498090355806\n",
      "train loss:0.96915238599625\n",
      "train loss:0.7831900650389058\n",
      "train loss:0.808553487387013\n",
      "train loss:0.950052701436631\n",
      "train loss:0.9124003311585465\n",
      "train loss:0.6845643300415506\n",
      "train loss:0.7332979499391569\n",
      "train loss:0.862464986146748\n",
      "train loss:0.9040767521966738\n",
      "train loss:0.9992040191094042\n",
      "train loss:0.6665631544293212\n",
      "train loss:0.8963867730600392\n",
      "train loss:0.7796613732130026\n",
      "train loss:0.8303718436286073\n",
      "train loss:0.8234341501656375\n",
      "train loss:0.8881901354107111\n",
      "train loss:0.8201674875615756\n",
      "train loss:1.1051586964447357\n",
      "train loss:0.9936154500269447\n",
      "train loss:0.772556183742382\n",
      "train loss:0.8959772549782492\n",
      "train loss:0.8146174499254633\n",
      "train loss:0.7554960520859899\n",
      "train loss:0.7873223539676557\n",
      "train loss:0.8903575901710046\n",
      "train loss:0.888042229643778\n",
      "train loss:0.8578575186459001\n",
      "train loss:0.851932682398047\n",
      "train loss:0.9444059105896955\n",
      "train loss:0.8976185991470738\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.9946\n",
      "Save Network Parameters!\n"
     ]
    }
   ],
   "source": [
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "network = DeepConvNet()\n",
    "trainer = Trainer(\n",
    "    network, x_train, t_train, x_test, t_test, epochs=20, mini_batch_size=100,\n",
    "    optimizer='Adam', optimizer_param={'lr': 0.001}, evaluate_sample_num_per_epoch=1000\n",
    ")\n",
    "trainer.train()\n",
    "\n",
    "network.save_params('deep_convnet_params.pkl')\n",
    "print('Save Network Parameters!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 36694.244163,
   "end_time": "2022-06-01T15:52:45.852922",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-06-01T05:41:11.608759",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
